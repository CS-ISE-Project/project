--
-- PostgreSQL database dump
--

-- Dumped from database version 14.9
-- Dumped by pg_dump version 16.1

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

--
-- Data for Name: articles; Type: TABLE DATA; Schema: public; Owner: iseproject
--

COPY public.articles (id, url, publication_date, title, authors, institutes, keywords, abstract, content, "references") FROM stdin;
1	https://drive.google.com/file/d/1sdjDXIw9KF6QbrueN9BttDvgz-_LCPEj/view?usp=drive_link	2008-09-10	AI Model for Computer games based on Case Based Reasoning and AI Planning	['Vlado Menkovski', 'Dimitrios Metafas']	['Athens Information Technology']	['Game AI', 'Case Based Reasoning', 'AI Planning', 'Game Trees']	Making efficient AI models for games with imperfect information can be a particular challenge. Considering the large number of possible moves and the incorporated uncertainties building game trees for these games becomes very difficult due to the exponential growth of the number of nodes at each level. This effort is focused on presenting a method of combined Case Based Reasoning (CBR) with AI Planning which drastically reduces the size of game trees. Instead of looking at all possible combinations we can focus only on the moves that lead us to specific strategies in effect discarding meaningless moves. These strategies are selected by finding similarities to cases in the CBR database. The strategies are formed by a set of desired goals. The AI planning is responsible for creating a plan to reach these goals. The plan is basically a set of moves that brings the player to this goal. By following these steps and not regarding the vast number of other possible moves the model develops Game Trees which grows slower so they can be built with more feature moves restricted by the same amount of memory.	introduction the goal of this effort is to explore a model for design and implementation of an ai agent for turn based this model provides for building more capable computer opponents that rely on strategies that closely resemble human approach in solving problems opposed to classical computational centric heuristics in game in this manner the computational resources can be focused on more sensible strategies for the game with the advancement in computer hardware increasingly more computing power is left for executing ai algorithms in in the past ai in games was mainly a cheating set of instructions that simulated the increasing difficulty in the game environment so that the player had the illusion of real improvement in available memory and processing power allows implementation of more intelligent algorithms for building the game environment as well as direct interaction with the human in this particular research the emphasis is put on the interaction between the ai agent and a computer player in the realm of the game it is particularly focused on turn based games that have the elements of uncertainty like dice or concealed at the beginning a description of game ai algorithms are such as game trees and the following section describes an approach of using ai planning to improve building game trees in games with imperfect information where game trees tend to be very large with high growth section discusses another approach that provides a significant reduction to the number of considered moves in order to find the favorable strategy of the ai this approach uses ai planning techniques and case base reasoning to plan for different scenarios in predetermined strategies which would be analogous to human player experience in the particular the cbr database illustrates a set of past experiences for the ai problem and the ai planning illustrates the procedure to deal with the given situation in the in the next two sections implementations and evaluations of both approaches are the ai planning approach is implemented with the game and the combined ai planning and cbr approach is implemented with a model for the monopoly the last part contains conclusions and future work game trees and minimax game trees are common model for evaluating how different combinations of moves from the player and his opponents will affect the future position of the player and eventually the end result of the an algorithm that decides on the next move by evaluating the results from the built game tree is minimax minimax assumes that the player at hand will always choose the best possible move for in other words the player will try to select the move that maximizes the result of the evaluation function over the game so basically the player at hand needs to choose the best move overall while taking into account that the next will try to do the same minimax tries to maximize the minimum minimax can be applied to multiple permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first to copy or to post on servers or to redistribute to requires prior specific permission a september copyright acm interactive and adaptable media international conference on digital interactive media in entertainment and arts levels of nodes on the game where the leaves bring the final known game the minimax theorem for every game there is a mixed strategy for each such that the expected payoff for both is the same value v when the players use these v is the best payoff each can expect to receive from a play of the that these mixed strategies are the optimal strategies for the two this theorem was established by john von who is quoted as saying far as i can there could be no theory of games without that theorem i thought there was nothing worth publishing until the minimax theorem was a simple example of minimax can be observed by building a game tree of the the game is a simple game which can end by the first player the second player wining or a there are nine positions for each of the players in which at each turn the player puts x or o if the player has three adjacent signs in a column or the two diagonals he or she this game has limited number of position and it is well suited for building the whole game the leaves of this tree will be final positions in the a heuristics evaluation function will also need to be written to evaluate the value of each node along the ai planning for building game trees ai planning ai planning also referred as automated planning and scheduling is a branch of artificial intelligence that focuses on finding strategies or sequences of actions that reach a predefined goal typical execution of ai planning algorithms is by intelligent autonomous robots and unmanned opposed to classical control or classification ai planning results with complex solutions that are derived from multidimensional ai planning algorithms are also common in the video game they solve broad range of problems from path finding to action a typical planner takes three a description of the initial state of the a description of the desired and a set of possible some efforts for incorporating planning techniques for building game trees have also shown similar to the approach explored in this in addition cased based reasoning techniques are also gathering popularity in developing strategies based in prior knowledge about the problems in the one of the benefits from hierarchical task network planning is the possibility to build game trees based on htn this method is described in the following game trees with ai planning an adaptation of the htn planning can be used to build much smaller and more efficient game this idea has already been implemented in the bridge baron a computer program for the game of contact bridge computer programs based on game tree search techniques are now as good as or better than humans in many games like chess and checkers but there are some difficulties in building a game tree for games that have imperfect information and added uncertainty like card or games with the main problem is the enormous number of possibilities that the player can choose from in making his in addition some of the moves are accompanied with probabilities based on the random elements in the the number of possible moves exponentially grows with each move so the depth of the search has to be very limited to accommodate for the memory the basic idea behind using htn for building game trees is that the htn provides the means of expressing high level goals and describing strategies how to reach those these goals may be decomposed in goals at lower level called this approach closely resembles the way a human player usually addresses a complex it is also good for domains where classical search for solution is not feasible due to the vastness of the problem domain or hierarchical task networks the hierarchical task or is an approach to automated planning in which the dependency among actions can be given in the form of networks a simple task network just a task network for is an acyclic digraph in which u is the node e is the edge and each node contains a task the edges of define a partial ordering of if the partial ordering is then we say that is totally in which case can be written as a sequence of tasks figure simple hierarchical task network a simple task network method is a of its precondition and a task the name of the method lets us refer unambiguously to substitution instances of the without having to write the preconditions and effects the task tells what kind of task can be applied if the preconditions are the preconditions specify the conditions that the current state needs to satisfy in order for the method to be and the network defines the specific subtasks to accomplish in order to accomplish the a method is relevant for a task if the current state satisfies the preconditions of a method that implements that this task can be then substituted with the instance of the the substitution is basically giving the method network as a solution for the if there is a task and the distance to home is and there exists a method and this method has a precondition that the distance is less than then a substation to the task can be made with this method figure htn method buy milk go to purchase go to walk if dimea international conference on digital interactive media in entertainment and arts if the distance is larger than another meth to be substituted figure htn method an stn planning domain is a set of operatio methods a stn planning problem is a state the task network w called initial task stn a plan is a soluti problem if there is a way to decompose w into π and each decomposition is applicable in the ap the the algorithm that is capable to networks into plans is called or h cases where one does not want to use a forwa htn planning is generalization of s gives the planning procedure more freedom construct the task in order to provide this a bookke is needed to represent constraints that the plann not yet the bookkeeping is done by unenforced constraints explicitly in the task netw the htn generalizes the definition of a a task network is the pair w task nodes and c is a set of eac specifies a requirement that must be satisfied by a solution to a planning the definition of a method in htn also definition used in stn a htn pla and the s constraints form the task the htn plan identical to stn planning domains except they u instead of stn compared to classical planners the prim htn planners is their sophisticated knowledge r reasoning they can represent and planning with a good guide they can solve classical planning p magnitude more quickly than classical or neoc the primary disadvantage of htn is the nee author to write not only a set of planning opera of htn planning in building game for a htn planning algorithm to be adap trees we need to define the domain of h which is the domain of the thi a knowledge representation of the rules of the environments and possible strategies of game pla in this domain the game rules as well as kn tackle specific task are the implem tree building with htn is called tign implementation uses a procedure simila but adapted to build up a game walk hod instance needs ons o and a set of uple of the initial k network and the ion for a planning π if π is executable ppropriate state of decompose these omposition however there are stn planning that m about how to eeping mechanism ning algorithm has y representing the a task network in where is a set of h constraint in c y every plan that is o generalizes the an is a of subtasks and the nning domains are use htn methods mary advantage of representation and solve a variety of d set of htns to problems orders of classical ed of the domain ators but also a set trees ted to build game htn methods and is is in some sense e the game nown strategies to mentation of game this ar to tree rather than a the branches of the game tree rep the applies all met state of the world to produce new continues recursively until there are n have not already been applied to th in the task network generated by tignu actions will occur is determined by th by listing the actions in the order network can be into a gam case based reasoning in case based reasoning reasoning is a artificial intelligence both as problems and as a basis for standalone reasoning is a paradigm solving and learning that has became applied subfield of ai of recent yea intuition that problems tend to i are often similar to previously en that past solutions may be of cbr is particularly applicable to probl even when the domain is n for a deep domain systems have been the most successfu to determine a fault or diagnostic or to determine whether or repair is necessary given a set of past s figure game tree built fr figure htn to game tr to present moves generated by thods applicable to a given w states of the world and no applicable methods that he appropriate state of the the order in which the e they will the task me tree n game strategies well established subfield of a mean for addressing ai ai m for combining one of the most successful cbr is based on the it means that new problems ncountered problems f use in the current situation lems where earlier cases are not understood well enough diagnosis or classification ul areas of an illness from observed r not a certain treatment or olved cases rom htn ree algorithm interactive and adaptable media international conference on digital interactive media in entertainment and arts central tasks that all cbr methods have to deal with are identify the current problem find a past case similar to the new use that case to suggest a solution to the current evaluate the proposed and update the system by learning from this how this is what part of the process that is what type of problems that drives the varies while the underlying ideas of cbr can be applied consistently across application the specific implementation of the cbr methods particular retrieval and similarity is highly customized to the application at cbr and games many different implementations of cbr exist in cbr technology is nicely suited for recognizing complex situations much easier and more elegant than traditional parameter comparison or function there are especially evident cases in real time strategies where different attack and defense of global strategies are nicely defined by cbr datasets and later used in the running also intelligent bots behavior is also another typical depending on the number of enemy bots the layout of the terrain and position of human players the cbr system finds the closest cbr case and employs that strategy against the human players which in prior evaluation was proved to be highly game trees with ai planning in order to show the expressive power of ai planning in defining strategies for and the use of these plans to build game trees i implemented an algorithm that builds game trees for the the game tree of shows possible games of which are won by x first are won by o and the rest are draw all these games can be derived from building a complete game even though it is possible to build a complete game tree of it is definitely not an optimal many of the moves in this tree would be symmetrical and also there are a many moves that would be illogical or at least a bad strategy to even so what strategy should x first choose in order to win the there are few positions that lead to certain these positions involve simultaneous attack on two positions so the other player could not basically the only trick in figure winning strategy positions position leads to victory if the two of the three top bottom left corner and bottom right corner are free position lead to victory if two of the three top right bottom right corner and bottom middle are free and in the third position if the two of middle top and middle left are available the position is a certain there are many different arrangements of the tokens that give equivalent positions as these three by using planning we do not need to consider all possible layouts but just consider these three similar to what a human would the game starts from an empty the two relevant strategies that would lead to these positions are to take one corner or to take the center figure two starting moves the center position as we can see in the simulation results lead to a bigger number of victorious endings but it is also a straight forward strategy with obvious defense at this point we need to consider the moves of the if we take the left branch the opponent moves can be a a corner or a middle we also need to differentiate with a move to a corner adjacent with our like top left or bottom right or across the center to bottom right figure opponent response to corner move in cases one and we have a clear path to executing strategy so we need to capture the diagonally opposite and as for the third case the best way to go is to capture the center and go for strategy or depending of the next figure move after corner opening the first move leads to certain o will have to go to the center and x will achieve strategy the second move is a possible way to strategy if o makes a mistake in the next so x goes to the opposite for the third case since o is playing a valid strategy the only move that leaves a possible mistake from o would be to take the center and wait for o to go to the middle and then achieve strategy or which will be a symmetric situation to the one that we will find if we branched with the figure opponent response to center move if we go back to the second branch a possible way for the second player to engage is corner or the first dimea international conference on digital interactive media in entertainment and arts move is a valid strategy for o and can be mee corner move from x to try a mistake from o in the same as in the third case above from the pre another move would be go to the middle wh achieves strategy or figure move after cent the fist move will lead to win if o moves draw if it goes for the corners in t has to block the lower left corner which leave middle left or corner left which are strategy and to sum the strategies for the first corner strategy for the then for the ce the corners with the particularly the one oppo if the center is empty for the second strate we go for the opposite after this point w opponent or try to implement strategies or plan take center center empty plan take corner all corners empty plan take corner after center we have center take corner oppos opponent has plan take diagonal corner we have a the opponent ha the corner opposite to the one we have is plan block the opponent has tree tokens in a r agonal plan win we have two tokens in a colu nd the third place is free plan tie if all places are a hierarchical task network top level task is play this is a can be derived tie or sear search for plan is derived to both plan and pla plan which later leads to a call for the oppon recursive call to figure ht et with a opposite the future exactly evious and here x eventually ter opening to the middle or a the second case o es x to go for the d we have center or enter we try to get osite to the one o egy we go for it or we either block the r which lead to site to the one the as the and or di mn or a a complex task and rch for the an or plan and move and a tn this htn when executed will re game by creating nodes from them with branches with the move of t tree for the game over whi this set up with plans with ta for which considers all pos player with only of w and where the second opponent w reduction over the possible g these reductions can be very use computing capabilities but also we pr that planning can be very efficient if d trees by applying reasoning very further improvements to the gam the opponents moves are also planned all the meaningless and symmetrical m game ai in monopoly overview of the ai imp the ai agent is responsible for players in the the core principle a game tree with all the sensible move make from the current point of time minimax algorithm the agent selects t would bring the computer player mo with the highest building that would be big enough to consider is obstructed by the vastness of poss with all the possible random landings nodes of the game tree exponentially tackle this problem the ai agents discussed case based re the technologies are employed first the agent searches the cbr datab largest similarity with the current state associated with a playing th that the planner needs to build plans f consecutive player moves that bring th way only moves that are part of that str being a small fraction of the overall po edges of the game tree at each level dec at each level of the game tree the of a single after the strateg considered the response to those strate by the the move of the probability distribution of the dice as a more general strategy needs moves sin the expertise of the this ge more plausible moves than the focused after covering all opponents t deducting a feature move of the com cbr selected plan after strategies and reaching a reasonable s into account the memory limits an probabilities that the move is possible the dice the building of the game tre algorithm searches the game tree favorable move for the ai player usi the process is repeated each time the a esult with plans for possible m each position and linking the player we create a game ich we can run the minimax arget strategies creates a tree ssible moves for the second which x wins are draw this is a significant ames with a complete game eful for devices with limited rove a very important point designing meaningful game similar to human player me tree are also possible if in other words if we drop moves of the plementation the moves of the artificial e of the ai agent is building es that all the players would e then using the the move that in the future ost favorable game position a game tree in this game sufficient number of moves sible moves in combination of the the number of y grows at each to incorporates two already easoning and ai in the following base to find the case with the e of the this case is he strategy consists of goal and the plans consist of he player to that this rategy are those ossible moves the number of creases e model considers the moves gies of the ai player are egies needs to be considered depends of the well as the strategy of the s to be implemented for the nce we cannot be aware of eneral strategy would bring d strategy of the ai the agent comes back to mputer player by using the creating several loops of size of a game tree taking nd the rapidly decreasing e due to the distribution of ee then the minimax and decides on the most ing the minimax ai player is interactive and adaptable media international conference on digital interactive media in entertainment and arts auctioning and trading game moves are always accompanied by return of investment calculations in making the these calculations represent adaptation of the more general planning associated with the cases in the cbr these adaptations are necessary due to the fact that the cases do not identically correspond to the situation on the in addition calculating the game position value of each node of the game tree is done by heuristic functions that incorporate economic calculations of net present and strategic layout and so for example railroads in monopoly are known to be strategically effective because they bring constant income even though the income can be smaller than building on other details on the cbr implementation the implementation of the cbr is by using the is an framework in java for building cbr systems that is an evolution of previous work on knowledge intensive cbr for this implementation we need to look into three particular classes of the the for a implementation the standardcbrapplication interface needs to be the cbr cycle executed accepts an instance of this class represents a cbr query to the cbr the description component of represents the description of the case that will be looked up in the all cases and case solutions are implementing the casecomponent the platform connects to the cbr database via a connector each connector implements all the necessary methods for accessing the retrieval of storing and deletion of this implementation uses a custom xml structure for holding the cbr since the game will not update the cbr database only read a xml solution satisfies the the xml file to a certain extent is similar to the xml representation of the we are interested in finding one cbrcase that is the most similar case to the situation in the game at the time of the this procedure is done in the cycle method of the the cbr comparison is done by nearest neighbor search offers implementations for nn search algorithms of simple these implementations are called local for complex attributes like in our case global customized similarity mechanisms need to be the monopolydescription class is basically a serialization of the it holds all the information about the state of the the their amount of cash figure class diagram of the monopoly case component models on the other hand the monopolysolution class holds the three particular attributes that are needed for the the planning state and the game is implemented by using the controller software development the controller is responsible for implementing the game rules and handling all of the events in the game like roll of input commands for auctioning and etc from the the view layer is responsible for displaying the board and all of the input widgets on to the game and the models are data structures representing the game state figure class diagram of the monopoly models complex similarity representation in cbr the similarity measurement part of the nearest neighbor algorithm is implemented by implementing the localsimiralrityfunction and the globalsimiralityfunction a local similarity function is applied to simple attributes by the nn and a global similarity function is applied to compound in the case of our implementation the attributes of the monopolydescription are compound attributes describing the state of the number of amount of cash for every player and since monopolydescription is a custom casecomponent a global similarity function needs to be implemented to accurately find the distance between different cbr the similarity mechanism is inseparable core element of the cbr this mechanism represents how the cbr decides which strategy is best suited for the particular situation by dimea international conference on digital interactive media in entertainment and arts calculating the distance or similarity to other cases in the for the monopoly implementation we need to consider several basic monopoly is based on investing in properties and receiving revenues from those one of the basic strategies of the game is to build a set of properties that will bring constant income larger than the one of the so in time the opponents will have to declare but on the other hand over investment can lead to too stretched resources with low income that will eventually drove the player to to decide on these two we need a clear separation into two groups of cases in the cbr the first group of cases will represent a situation on the board where the player has significant income per loop formed of one or more color group maybe some buildings on them and so it is important to note that in this case the player is better situated than his opponents so he only needs to survive long enough to win the in the other group of cases either the opponent is not well positioned on the board or its opponents are better in this case further investments are necessary to improve the situation so the player can have a chance of winning in the long these metrics can be owning color valuing groups of evaluating the other opponents as and considering the amount of as it is obvious in monopoly the number of streets is not as nearly as important as the combination of streets the player it is also important to note that one cbr case does not hold only a single strategy in but its solution can have multiple different strategic for example one cbr case might simultaneously say buy this land to form a color group but also trade some other unimportant property to increase cash the cases do not represent all possible combinations of board they are only representation of typical game the cbr case solutions do not give exact instructions in general but rather strategic for example one cbr solution might say trade the streets that you only have one of each for the ones that you have two of that color then the planner based on the situation on the board needs to decompose this high level task to a low level like offer for and offer the exact amounts and actual streets are left to the planer to the monopoly cbr database is currently in development on a monopoly clone game called the cases are architected based on human player experience and there is a plan of making a number of slightly different strategies that differ on the style of playing and then running simulation tests that would determine the particular validity of each database as well as validity of certain segments of the strategy or even particular cases in the the actual execution of the strategies will not differ from strategy to strategy since the plan execution is more related to the structure and rules of the game than to the actual playing details on the planning implementation for the purpose of planning this implementation uses a modification of the the java simple hierarchical ordered planner is a domain independent htn planning system uses ordered task decomposition in reducing the htn to list of primitive tasks which form the an ordered task decomposition planner is an htn planner that plans for tasks in the same order that they will be this reduces the complexity of reasoning by removing a great deal of uncertainty about the which makes it easy to incorporate substantial expressive power into the planning in addition to the usual htn methods and the planners can make use of can do mixed and can do external function in order for the planer to generate plans it needs tree crucial state and the domain defines all the functionalities that the particular domain these are simple and complex the complex tasks also called methods create the hierarchy with the fact that they can be evaluated by simple tasks of other complex this is how a hierarchical structure of tasks is the problem reduction is done by reducing the high level complex tasks to simpler until all the tasks are the list of primitive tasks forms the the state represents the state of the it is a simple database of facts that represent the state of the the state is necessary to determine the way the problems or tasks are reduced to their primitive the reduction is done by satisfying different prerequisites set in the these prerequisites are defined in the the tasks are high level tasks or methods defined in the the planner based on the state and the goals selects one or more high level tasks that need to be reduced to plans figure diagram of a planner the plans then generate the game the number of moves generated by the plans is just a fraction of the possible moves at that this reduces the game tree providing the opportunity to generate smaller and deeper game trees and making more efficient decisions in conclusion even though the results from the cbr database are not complete at this time partial strategies are implemented as cases and recognized during game play by the cbr these smaller local strategies coupled with more global higher level strategies that are particularly important at the beginning of the game would form a complete cbr database and represent a knowledge engineered style of playing of the ai the ai planning approach is a proven method by the toe experiment and is suitable for implementing the strategies associated with the cbr this approach in general benefits from both cbr as well as ai planning and comprises an elegant even though ai planning can be enough as a single technology for some simpler problems like the complexity of monopoly would mean that the planner would have to incorporate core planner tasks plan state interactive and adaptable media international conference on digital interactive media in entertainment and arts large and complex domain and a very big state the cbr application helps reduce this complexity by focusing the planning on smaller domain of the basically the cbr reduces the overall goal of the play the to smaller more concrete goals suitable to the particular state of the thus reducing the need for global planning strategies and complex planning furthermore this symbiosis of technologies gives way for more precise and finely tuned strategies which can be difficult to include into global plan for the whole one simple example for the monopoly game would be sometimes better to stay in jail because rolling double increases the probability of landing on some field ten or twelve steps from the that can be of great importance to the rest of the these and similar small local strategies can be easily recognized by similar cases in the cbr in other words the system is flexible enough so that new strategies can be incorporated easily missing strategies can be also recognized by the distance metrics as well as wrong assumptions in the strategies can be easily one other important property of the system is that is highly the game its self can be diversely different depending on the configuration of the even though the platform is restricted to monopoly type of changing the layout and values of the fields effectively brings completely different properties of the in addition the cbr database represents the entire experience of the ai it can be filled with rich set of strategies or even configured with different flavors of difficulties of this of course coupled with the domain of the planner which can differ from a case to a case as future work further exploration of this technology would go towards complete implementation of an ai aware agent for initial results from the local cases with more specific strategies show cbr as a capable tool for representing expertise in playing the completing the more general strategies and coupling them with the planning domain will give precise results on the benefits from this there is also need for exploring the planning of strategies of this task is to some extent different because we cannot always expect the opponent to select the best move we in the example all possible moves of the opponent were taken into if we used the same planner for the opponent only tie games would result from the game in other words mistakes of the players also need to be the cbr platform brings other functionalities well worth of exploring as the revision stage of the platform is basically capable of fine tuning strategies or even developing new strategies for the a well written underlying ai planning model with a capable feedback of the game tree evaluation back to the cbr revision capability can be an interesting concept in automatic experience acquisition for the ai there are also many other fields were combined cbr and planning approach can be incorporated into a problem this combination is analogous in a big extent to a human way of people in addition to logic of reasoning in situations with lack of information rely to planning strategies and prior exactly the intuition behind cbr ai planning acknowledgments we would like to thank sofia tsekeridou for her involvement in the valuable discussions we had on the topic of	['[1] Minimax. Wikipedia. [Online] [Cited: April 23, 2008.] http://en.wikipedia.org/wiki/Minimax. ', '[2] Von Neumann, J: Zur theorie der gesellschaftsspiele Math. Annalen. 100 (1928) 295-320 ', '[3] Automated Planning. Wikipedia. [Online] [Cited: April 23, 2008.] http://en.wikipedia.org/wiki/Automated_planning. ', '[4] Sanchez-Ruiz, Antonio, et al. Game AI for a Turn-based Strategy Game with Plan Adaptation and Ontology-based retrieval. ', '[5] K. Erol, J. Hendler, and D. Nau (1994). Semantics for hierarchical task-network planning. Technical Report TR-94- 31, UMIACS. ', '[6] Smith, S. J. J. and Dana S. Nau, T. A. Throp. A Planning approach decrarer play in contract bridge. Computational Intelligence. 1996, Vol. 12, 1. ', '[7] One Jump Ahead: Challenging Human Supremacy in Checkers. J.Schaeffer. s.l. : Springer-Verlag, 1997. ', '[8] IBM. How Deep Blue works. [Online] 1997. [Cited: April 23, 2008.] http://www.research.ibm.com/deepblue/meet/html/d.3.2.html ', '[9] Ghallab, Malik, Nau, Dana and Traverso, Paolo. Automated Planning theory and practice. s.l. : Morgan Kaufmann Publishers, May 2004. ISBN 1-55860-856-7. ', '[10] Case Based Reasoning. Experiences, Lessons and Future. Leake, David. s.l. : AAAI Press. MIT Press., 1997. ', '[11] Applying case-based reasoning: techniques for enterprise systems. Watson, I. San Francisco, CA, USA : Morgan Kaufmann Publishers Inc., 1998. ', '[12] Plaza, A. Aamodt and E. Case-based reasoning: Foundational issues, methodological. AI Communications. 1994, 7(i). ', '[13] Tic-tac-toe. Wikipedia. [Online] [Cited: April 23, 2008.] http://en.wikipedia.org/wiki/Tic-tac-toe. ', '[14] Díaz-Agudo, B. and González-Calero, P. A. An architecture for knowledge intensive CBR systems. Advances in Case-Based Reasoning – (EWCBR00). New York : Springer-Verlag, Berlin Heidelberg, 2000. ', '[15] Ilghami, Okhtay and Nau, Dana S. A General Approach to Synthesize Problem-Specific Planners. 2003. 302 DIMEA 2008 3rd International Conference on Digital Interactive Media in Entertainment and Arts']
2	https://drive.google.com/file/d/1YJCgV7h1q7FZOHjHriaooh1yHCFJjTb6/view?usp=drive_link	2023-03-27	The Programmers Assistant: Conversational Interaction with a Large Language Model for Software Development	['Steven I. Ross', 'Fernando Martinez', 'Stephanie Houde', 'Michael Muller', 'Justin D. Weisz']	['IBM Research AI Cambridge, MA, USA', 'IBM Argentina La Plata, Buenos Aires, Argentina', 'IBM Research AI Yorktown Heights, NY, USA']	['code-fluent large language models', 'foundation models', 'conversational interaction', 'human-centered AI']	Large language models (LLMs) have recently been applied in software engineering to perform tasks such as translating code between programming languages, generating code from natural language, and autocompleting code as it is being written. When used within development tools, these systems typically treat each model invocation independently from all previous invocations, and only a specific limited functionality is exposed within the user interface. This approach to user interaction misses an opportunity for users to more deeply engage with the model by having the context of their previous interactions, as well as the context of their code, inform the models responses. We developed a prototype system – the Programmers Assistant – in order to explore the utility of conversational interactions grounded in code, as well as software engineers receptiveness to the idea of conversing with, rather than invoking, a code-fluent LLM. Through an evaluation with 42 participants with varied levels of programming experience, we found that our system was capable of conducting extended, multi-turn discussions, and that it enabled additional knowledge and capabilities beyond code generation to emerge from the LLM. Despite skeptical initial expectations for conversational programming assistance, participants were impressed by the breadth of the assistant's capabilities, the quality of its responses, and its potential for improving their productivity. Our work demonstrates the unique potential of conversational interactions with LLMs for co-creative processes like software development.	introduction software development is a highly skilled task that requires and creativity many techniques have been developed to enhance the productivity of software such as advanced code repositories knowledge repositories sites and pair programming practices collaborative software engineering is especially given that professional software development is rarely a solo activity and relevant knowledge and expertise are typically distributed widely within an organization many efforts have focused on incorporating collaborative technologies into software development environments the pioneering work of rich and waters on the programmers apprentice presented a novel concept of a knowledgeable automated assistant in an artificial collaborative partner that could help software engineers with writing designing software and creating requirements at the ai technologies and computing resources were not sufficient to fully implement their in the intervening an increase in computational the availability of large corpora of language and code and the development of deep neural networks have made new approaches to achieving their goals worth models leveraging the transformer architecture have been developed to perform software engineering such as translating code between languages generating documentation for code and generating unit tests for code talamadupula and allamanis et for recently developed foundation models large language models that can be adapted to multiple tasks and which exhibit emergent behaviors for which they have not been explicitly trained have also proven to be capable with source iui march australia ross et while the intent of training llms such as and was to give them mastery of natural it quickly became apparent that the presence of code in their training corpora had given them the ability to generate code based on natural language descriptions the codex model was then produced by tuning on a large corpus of source code leading to the development of copilot a tool that helps software engineers by autocompleting code as it is being experimentation with copilot has shown its ability to perform additional such as explaining generating and translating code between languages although autocompletion interfaces are useful and valuable when the system can discern the there are many instances where that is for the developer may have a good idea of what they want to but may be unclear on what or even algorithms to they may even have general programming questions that need to be answered before they are able to write any in this we seek to understand whether modern ments in foundation models large language models that have been on source code data are sufficient to support a conversational agent that can act as an assistant in the software development we developed the assistant to explore the capabilities that conversational interaction could enable and the extent to which users would find tional assistance with programming tasks desirable and we hypothesize that a conversational system may provide a flexible and natural means for interacting with a conversational interaction could enable users to pursue their tions in a multiple exchange dialog observed by barke et that allows them to ask questions and refine their a conversational programming assistant could ask the user clarifying or disambiguating questions to help it arrive at the best it could also provide multiple types of assistance to the user beyond simply generating code such as engaging in general discussion of programming topics or ing users improve their programming skills observed in other studies of automating technologies our paper makes the following contributions to the iui we provide empirical evidence that a conversational gramming assistant based on a foundation model provides valuable assistance to software engineers in a myriad of by answering general gramming by generating by enabling the model to exhibit emergent and by enabling users to ask questions that depend upon their conversational and code we show how different interaction models direct and search provide complementary types of support to software engineers with tradeoffs tween the focus and the relevance of port to their code the provenance of that and their ability to ask we motivate the need to further understand how to design ai systems that enhance the joint mance of the related work we discuss three areas of related work that have either motivated our study of conversational programming assistance or provided the technical foundations for we begin by briefly summarizing rich and visionary work on the tice followed by summarizing work on foundation models and evaluations of how these models pact software we discuss conversational interaction and how it might be employed to provide more flexible and sophisticated assistance to software the apprentice our work is inspired by the vision laid out by rich and waters which describes an artificial agent that can act as an intelligent sistant for software engineers by providing catching and handling routine details throughout the software development the apprentice relied on a knowledge base of which are structured versions of what are known today as software design patterns it used a brid reasoning system capable of reasoning based on frames and a plan along with general purpose logical although natural language interaction was the original prototype implementation ultimately used a stylized command we view our work as a conceptual successor to the as it enables the natural language interaction that the apprentice foundation models and evaluations of programming assistance generative models based on the transformer architecture have recently been applied to the domain of software fluent large language models are capable of generating code from natural language descriptions translating code from one guage to another generating unit tests and even ating documentation for code these models are probabilistic and as do not always produce perfect results code that is free of syntax or logical weisz et found that software engineers are still interested in using such models in their and that the imperfect outputs of these models can even help them produce code via collaboration new tools based on llms are actively being github is described as ai pair it is optimized for the code autocompletion use given a starting snippet such as a or partial copilot completes the copilot is based on the openai codex model a billion parameter sion of on code samples from million public software repositories on empirical evaluations of the assistant iui march australia this model have shown although the quality of its outputs is quite those outputs may still be problematic echoing the results from weisz et evaluations of lot have found that it increases feelings of productivity and that almost a third of its proposed code completions were accepted by in a contrasting vaithilingam et found that while most participants expressed a preference to use copilot in their daily it did not necessarily improve their task completion times or success in a study by kalliamvakou developers working with copilot were able to implement a web server in javascript faster than developers who did not use a grounded theory analysis of how programmers interact with copilot found that their interactions varied depending upon whether they were accelerating tasks that they already knew how to do or if they were exploring solutions to problems that they were less sure autocompletion was effective when developers were operating in and relied on the model to produce short completions that could be verified in the interaction was more developers would communicate with copilot by typing comments and seeing what copilot generated in they would modify their comments to explore other ways of prompting a the comments used to prompt the model would be deleted after the relevant code was indicating that their value was largely in driving a yet context dialog with the model to coerce it to produce the desired results through an iterative refinement in this we fully commit to a conversational style of interaction with a llm and assess the value it provides to conversational interaction and analysis conversational using natural language to act with technology has had a long research history starting in the with approaches like eliza and continuing to today with large language based conversational systems such as meena and bot these systems are intended to address the problem of with a goal of realistically engaging in but not particularly in a or chatbots are typically built with frameworks such as the microsoft bot google and ibm watson they operate using dialogue trees and use natural language processing to detect conversational intents and extract contextual this structure enables the creation of special but fairly limited and conversational there have been several recent attempts to investigate sational programming kuttal et conducted a wizard of oz study in which a pair programmer was replaced with a conversational and they found that can act as fective pair programming the pact system is a chatbot that assists programmers adjusting to new programming pact is structured as a discrete system based on a neural machine translation but it maintain a conversational conversation conversation is a form of interaction between people that enables robust conversation analysis is a method for understanding the natural structure of human conversational it catalogs different patterns of conversational acts and how they are utilized by interlocutors in order to attain a wide variety of conversation ysis has been adapted to describe patterns of interactions between humans and artificial conversational agents in order to aid in the design of chatbots we apply techniques from conversation analysis in our study of conversational programming the assistant in order to explore conversational programming we created a functional prototype system called the our shown in figure combines a code editor with a chat the code editor was implemented using the microsoft monaco embedded in a react the chat user interface was implemented using the to drive the conversational we employed codex model accessed through its web we developed our prototype as a lightweight coding ment in order to examine the user experience of interacting with a conversational our work was exploratory in and thus we did not have specific design goals for the prototype beyond integrating a code editor with a we also did not attempt to target the prototype for a specific class of users novices or or use cases writing code learning a new programming as we wanted any value provided by conversational assistance to emerge from our user we also did not implement the ability to run or debug code in our prototype as we wanted to explore the nature of the conversational tion rather than having users focus extensively on the production of working when designing how users would interact with the we decided that it should be available on demand and not monitor the work in progress or give unsolicited suggestions or in keeping with the conversational agent interaction model proposed by ross et this approach was supported by feedback from prospective users who were cerned about the assistant providing criticism of unfinished efforts in progress or distracting them while they we force initiative onto the user and only have the assistant respond to their in this the assistant can provide help when requested without undesirable interruptions that can distract or interfere with the when a user interacts with the we keep track of their selection state in the code if a user sends a message to the assistant without any code selected in the then that message with the prior conversational is passed directly to the if a user sends a message to the assistant with new code iui march australia ross et selected in the editor code that previously selected when they sent their last then that code is appended to the message before being communicated to the the model may produce multiple types of responses to a we treat each type of response differently in the responses that do not contain code are always rendered in the chat ui responses containing short code snippets are rendered inline in the chat ui responses containing longer code snippets show the code in a window with a proxy entry in the chat transcript that allows users to display the code window after it has been text in the response remains in the chat the assistant never directly modifies the contents of the source any code the user desires to transfer from the chat takes place via figure shows a screenshot of a sample in which the user asks a question that results in an inline then requests an explanation of some code in the and then quests further figure shows an example conversation that resulted in the generation of a longer code shown in a popup this example shows how the assistant produced an incomplete followed by criticism from the user regarding the missing and resulting in an apology and the generation of a complete supporting conversational interaction we enabled codex to conduct a conversational interaction by ing it with a conversational transcript and a request to produce the next conversational the prompt establishes a pattern of conversation between a user and a programming assistant named it provides several examples of socrates responding to eral coding generating code in response to a and accepting code as it establishes a convention for delimiting code in the making it easy to parse for display in the it also establishes an interaction style for the directing it to be and and to present its sponses in a because of the possibility that the model might produce erroneous answers or incorrect code discussed in weisz et we felt it was important that the assistant convey a sense of uncertainty to encourage users to not accept its results uncritically to avoid as observed in moroz et study of copilot and discussed more ally in ashktorab et as well as automation bias we present the full text of the prompt used for the assistant in appendix architecture ui design the assistant communicates with the codex api via a proxy server that forwards requests from the react the proxy also access to conform to the and it logs ui events from the client and ui use of responses was encoded into the llm output token probabilities from the llm were not utilized to influence the in a to address inconsistencies in the style or formatting of code generated by the proxy server reformats all code segments using the black code formatter before transmitting them to the client the client maintains the transcript of the ongoing each time the user sends a message in the the client constructs a new prompt for the model by concatenating the initial the chat and the new and makes a quest for the model to complete the this completion request also specifies a stop sequence of tokens to prevent the model from generating both sides of the conversation what the model thinks the next utterance might be after the given the limitation on context length tokens for both the prompt and model we silently older exchanges in the chat transcript when constructing the prompt to ensure that our completion request remains within the entire conversational history remains visible to the user in the the client ui provides a loose coupling between the source code editor and the chat users can hide the chat pane when they wish to focus solely on their and with it when they desire code selected in the editor is included in the conversation in order to couple the code context with the buttons are provided in the ui to copy code responses from the assistant to the handling model limitations while developing the and in early pilot we experienced some quirks and shortcomings of the model and our approach to using it for conversational one limitation stemmed from the fact that the model sometimes duced incorrect responses code with syntax incomplete responses code that was missing irrelevant sponses responses not related to the or stantial responses because of the probabilistic nature of model the model would times produce a more correct or appropriate we added the ability for users to either by asking in the chat or by clicking a button in the ui this feature removes the last response from the context presented to the model and then the model with an increased although it is possible for transformer models such as codex to produce multiple possible responses to a single we only request a single response in order to speed up response time as well as to preserve the token budget for conversational the feature provides an alternate way to produce a wider variety of during pilot we noticed that the assistant sometimes happened to generate the same response to unrelated in these the assistant tended to get in a pattern of repeating the same response and was unable to resume normal to avoid this we automatically execute a is a parameter in a generative model that specifies the amount of variation in the generation higher temperatures result in greater variability in the the assistant iui march australia a b h g f e c d figure the the user interface provides a code editor on the left and a chat pane on the right the button allows users to ask the assistant to generate an alternate response to the most recent the button resets the conversational context for the but maintains the chat transcript in the in this we show the assistant introduce itself to the user the user asks a general programming question for which the assistant provides an inline code response the user then asks a question about code selected in the editor followed by a series of operation in the background when we see identical consecutive responses from the we noticed that the accumulation of conversational text sometimes resulted in the assistant becoming fixated on some portion of the earlier for it might respond to a question with portions of the prompt or of earlier and become less responsive to newer to address this we introduced a accessible via the chat or by clicking a button in the ui that resets the context to the original forgetting the rest of the conversational we preserve the chat transcript in the but delineate the break in the memory with an annotation in the chat these annotations are added both for and sample conversation we provide a real sample conversation with the assistant in listing this conversation begins with the assistant greeting the user the user asks a general python programming question to which the assistant responds with a remark and a code snippet the user next asks a question that depends on their previous question and the response to which the assistant provides another code snippet satisfying the the user then switches topics and asks the assistant to write a fibonacci function and the assistant again responds with a remark will give it a line and a block of the user then asks how the function works and the assistant provides an adequate description iui march australia ross et figure code long code responses are presented in a window with a button to copy the code and close the this code can be from the chat transcript by clicking the proxy icon the user asks the assistant to the function in a different way again leveraging the ability to ask the assistant produces an alternative implementation that conforms to the request the user follows up with a question that depends on multiple past utterances and sponses in the chat transcript and the assistant produces a relevant response the conversation closes with the user thanking the assistant and the assistant acknowledging their gratitude listing a conversation with the code presented by the assistant is listed in bold my name is socrates your programming what can i help you with how do i get a list of the keys in a python i think you would do something like what if i just wanted to iterate over i think you would do something like for key in write a function that returns the nth value in the fibonacci i will give it a def if n return elif n return return how does this the fibonacci sequence is defined by the recurrence relation this function implements that recurrence can this be done without the assistant iui march australia i think how about def for i in return which version is i think the recursive version is more elegant but the iterative version is more you empirical study of conversational programming assistance we conducted an empirical user study of the tant to assess whether conversational assistance provides value in a software engineering our inquiry focused on the user experience and value of conversational interactions grounded in we therefore designed a qualitative study to investigate tudes toward a conversational programming do people enjoy interacting what kinds of questions do they and how does the experience compare to other forms of gramming support such as searching the we note that prior studies conducted quantitative examinations of the use of llms in code our study is akin to weisz et qualitative examination of software attitudes toward working with models that may fail to produce working code to address our we deployed the tant within our organization a global technology company and invited people to try it out and give us feedback on their we invited people with varying levels of programming skill in order to obtain a wide range of feedback on the kinds of use cases for which the tool could provide tasks we set up the assistant as a playground environment that participants could try out with a few sample programming we created a tutorial to orient participants to the its and how to interact with we also created four programming challenges focused on writing ing and writing tests for we designed these challenges to expose participants to a broad range of the for each of these we explicitly did not evaluate metrics such as the the quality of their or the time taken to produce as the focus of our study was to understand the utility of conversational we selected python as the language used for the tutorial and challenges because of its general popularity and the fact that it was by our underlying llm all participants were first introduced to the assistant through a the tutorial walked each historical we note that our study was completed before the public release of chatgpt which has subsequently demonstrated the application of conversational assistance for programming tasks participant through sample interactions to give them a feeling for what the assistant could do and how to interact with the tutorial demonstrated how to ask how to request code to be and how to evaluate existing it did not cally cover how to generate documentation or unit tutorial instructions were provided within the code we include the specific text used for the tutorial in appendix programming after completing the ticipants unlocked four programming two of the lenges involved coding problems a queue class and writing code to create a scatterplot of data in a csv one involved umenting a given function implementation of a graph search and one involved writing unit tests for a given tion the greatest common divisor of two although the assistant was visible and available for we provided no specific requirement that it actually be used to complete the after participants completed their solution to a they submitted it by clicking a button in the the code editor used in the assistant was not a ide and did not provide syntax checking or the ability to or debug due to these participants were asked to submit their solutions when they felt they had completed the challenge to their own participants to recruit participants for our we posted internal ments in various communications channels focused on software our advertisements stated that we were evaluating a conversational programming but were kept deliberately vague in order to minimize the impact on expectations of the our advertisement yielded a pool of potential in order to recruit a diverse we used a screening survey that asked about their job their familiarity with and recency of use of and their availability to participate in our we accepted participants into the study on a rolling selecting participants to capture a range of programming experiences and ensure balanced gender we conducted periodic views to determine whether we were learning something new from each participant or if we had reached the point of saturation we stopped collecting data after running participants as we were no longer observing any new behaviors or gleaning any new the assistant implementation and configuration were held constant over the course of the no changes to the ui design or llm prompt were our participants had the following job software software data machine learning systems test business and gender variant and preferred not to python participants had years of python had had less than and were not familiar with iui march australia ross et recency of python participants had written python code within the past within the past within the past and had not written python code within the past we provide full demographic information for individual pants in appendix procedure participants completed the study on their own independently and without each participant was provided with a web link to a survey that described the nature of the study and the tasks that they would be expected to they were then directed to the assistant to complete the tutorial and the four programming when participants indicated they were finished with the they were directed to a final complete sessions generally required about an hour of though some participants spread their effort across a longer period of time and across multiple participants were compensated for their time at a rate equivalent to us measures we collected a variety of data in our study from three we employed three surveys in the a study survey to collect demographic a survey to gauge expectations of the conversational user and a survey to assess actual user we describe these survey questions in the relevant context of our and we provide a complete listing of all survey instruments in appendix event the assistant was instrumented to collect data on the event logs vided timestamped records of interaction including conversational the use of the and and use of conversation from the event we extracted versational transcripts between each participant and the results data analysis we collected a wealth of data in our survey responses from three surveys per containing written ments in survey and instances of different types of ui including conversational in the event we also for each counts or durations for different metrics from the event in our we deliberately exclude the portion of our data collected during the tutorial we exclude this data because that activity was guided by the tutorial not by our own our final sample consists of did not enforce that participants actually complete all of the all participants but one did submit solutions to all of the refer to a followed by the as a conversational including conversational exchanges in the event no survey data was our primary analysis of this data is as our pants provided us with a rich source of interesting feedback and insights in their where we supplement this data with quantitative data from the survey and the event as well as chat transcript data from the versation in this we triangulate across our three data using the survey data as a when we quote either from their qualitative survey responses or the conversational we reproduce their words exactly as including cal and potential trigger and we only make minor clarifying edits where delineated by square in order to set the context for our we first describe how we used reflexive thematic analysis to analyze responses to the survey we then describe our analysis of the conversation logs and our development of a coding guide based on conversation analysis and moore and natural conversation framework thematic analysis of qualitative survey we ducted a reflexive thematic analysis to analyze the responses to our seven survey we followed the process described by braun and clarke in which researchers immerse themselves in the generate codes for material that seems and then iteratively group and refine codes through collaborative discussion in order to identify four authors performed on the survey through these codes were grouped and consolidated into a single which were then to the data by two after another round of these authors identified a set of some themes had clear parallels to quantitative survey questions or event log and thus represented clear instances where we were able to gulate across data other themes surprised we structure our presentation of the results based on these grouped into three different aspects of the user expectations and utility of conversational and patterns of interaction and mental conversation analysis via the natural conversation in order to understand the content and structure of the conversations that took place between our participants and the we turned to the natural conversation framework we developed a codebook for the event beginning with different categories of utterances from the nine ncf categories expression of welfare and welfare report appeared twice in our book to distinguish cases in which the utterance was made by the human participant the other ncf categories were split to provide nuanced detail about the for we distinguished three different kinds of ncf depending upon whether they were stated as requests for action commands of action a function or expressions of desire we also added additional the assistant iui march australia interlocutor orientation codes human social expression of self small welfare welfare report task asks asserts capability command of expression of fies request for requests requests explanation meta ui chat context copy erroneous includes includes extraneous missing paste pasted code in spelling start try again assistant appears claims grants request grants request offers provided wrong requests requests response includes spews garbage table event log our codebook contained unique applied separately to participant utterances and assistant responses codes in bold were applied to both participant and assistant human codes were classified as demonstrating either a social or task orientation to the codes to identify such as utterances that included utterances that referenced selected utterances that plicitly or explicitly referenced earlier portions of the or ui activities such as and invocations of and we classified a subset of the codes based on whether they represented a task or social orientation toward the we list our codes in table but note that not all of them ended up being relevant to our when coding conversational we applied individual codes at the level of each conversational we allowed multiple codes to be applied to each utterance to account for utterances that performed multiple functions greeting and in order to ensure consistency in how our codebook was two authors coded a sample of the conversational achieving a satisfactory level of reliability 𝛼 where agreement was conservatively defined as having all of the same codes applied to both utterances in a conversational expectations and experience pilot testing of the assistant suggested that software engineers would be skeptical of a conversational programming assistant and its ability to provide useful our study revealed for most their actual experience after using the tool was better than they had participants were surprised at the quality of the responses and they appreciated how its integration with the code editor reduced the amount of context switching they needed to do in the some participants struggled with the code selection although others appreciated the ability to ask questions related to selected all of our participants engaged with the assistant while working on the despite there being no requirement to do participants submitted solutions to all four and one only mitted solutions for one of the four participants spent an average of minutes engaged with the as measured by the amount of time the assistant window was in participants made an average of utterances to the on of their utterances contained a code the average latency per was seconds we saw a rate of acceptance of generated where we considered code to be accepted if the participant performed a copy immediately after the code was this acceptance rate is much higher than the acceptance rate reported for copilot we believe one reason we observed a higher acceptance rate is because completion suggestions are generated whereas the suggestions are generated upon when copying generated code from the participants most often copied the entirety of the generated and only in of cases did they copy a smaller portion of user experience expectations changed prior to running our we had reason to believe that participants would be skeptical of a conversational programming before veloping the we showed potential users mockups of a program editor with an integrated chatbot these prototypes elicited uniformly negative people told us about their frustrating experiences with conventional chatbots and raised doubts about the and value of a conversational programming this skepticism vated us to develop the assistant in order to evaluate whether the conversational as powered by a would be better than people had during pilot we received feedback that the assistant provided a much better conversational experience compared to previous experiences with in designing our we felt it important to first gauge expectations of a conversational interaction around and then measure their experience after the time includes additional time added by our proxy server to ensure our mance to the api rate iui march australia ross et we developed a short inventory of six scale items to measure user experience of code the scale was administered once before participants were exposed to the assistant after they had been briefed that they would interact with an ai and once after completing the programming the items were presented with the appropriate do you expect you find the will be easy to will understand your will provide high quality will help you to write better will help you to write code more will be enjoyable to each item was rated on a scale of not at all a little somewhat a great deal a factor analysis revealed the items on this scale measured a single which we identify as user experience 𝛼 we computed two scores of user experience for each a ux score computed as the average of their six expectation scale and a ux score computed as the average of their six experience scale we found that participants had lower initial expectations for their experience with a conversational programming assistant task ux m of than their experience actually was ux m of a paired sample shows that this difference was 𝑝 𝑑 measured another participants had ux ratings that were higher than their task demonstrating a significant shift in attitudes toward conversational programming the ux ratings alone fail to capture anced expectations of the assistant and the reasons for their shifted attitudes after using participants expressed a variety of tions of the assistant before using including that it would be easy to use and produce correct responses understand the problem and what is being asked of it not interfere with their flow state produce imperfect or questionable puts improve with feedback provide generic and unhelpful answers or only answer basic questions and produce responses quickly expected be frustrated very quickly and that what think would be relatively common questions would be responded to with unhelpful have very good experiences with i think need to spend more time in reviewing and fixing the suggestions than in writing the code myself from had a more balanced that do some tasks really but others will not be as after interacting with the many ticipants commented on how the experience was better than they because it to be able to handle complex and a great felt it was and who were both initially reported having a positive for absolutely exceeded all my in scale items were modeled from scales published in weisz et table ai that measured constructs including ease of use response quality the production of code and the ability to write code more rapidly we added additional items to cover the constructs of request understanding and and we cast all items on a scale of all aspects that i could have imagined and provided a more quantitative was emphatic in their was blown away how well it allowing me to structure how i want the code to look and work and just giving me the thing i asked many participants described a sense of surprise in their was surprised by how well it understood their was surprised at how well the programmer assistant was able to understand my requests and generate good it understood major concepts and was able to explain it to me in a clear and it was also able to understand and write functional it even was able to help me review my i was also surprised at how well it could understand the context of what i was asking in questions when i did not specify exactly what i was talking but rather referencing our prior conversation does that was surprised that they liked the conversational interaction when they expected that they i like the chatbot interaction and that i would prefer something like the tool seen in those demos but after using the chatbot seeing the easy to it derstands i felt it like a i like this kind of quality of in order to gauge the quality of responses produced by the we examined the requests made by participants in the for the vast majority the assistant produced a correct sponse request in other the response was incorrect provided wrong correct but incomplete grants request or the assistant understand claimed ignorance of the subject claims or produced another type of response appears spews participants also reported experiencing this variability in the quality of the some participants described how the assistant provided and ity that were felt it was to see the quality of the and even explored the capabilities outside the scope of the challenges and found that it could handle those as was surprising the quality of the code and the ability to answer all my questions although i think the challenges may be biased towards what the assistant is able to it was a great experience because i asked many other things and it was able to answer of the assistant and some participants did run into for documentation ation did not perform very questioned the accuracy of the knowledge encoded in the the model need to be it said latest python version is but google says in some participants needed to ask their question multiple the assistant iui march australia times to get a good need to ask many times if you want to get an answer and also a detailed was annoying when i asked it to try again and it would give me the same struggled seem to handle multiple sentences perhaps offered the most scathing makes mistakes often enough to be not very despite the production of other participants felt that the assistant was still reported minor tweaks were normally needed to correct any described how the assistant able to completely solve their but provided a useful was only one hickup i noticed where when i asked it to memoize fibonacci it but it dropped the building blocks on my lap for me to finish so that was that was like minutes of effort on my ui design participants made many comments on our specific ui design and the affordances provided not in our the integration between the chat pane and the code editor was with a interface between the code pane and the assistant that it really prior research by brandt et has shown how keeping developers focused in their ide improves and our participants expressed similar allows me to stay in one browser and hinted at how the interface might preserve their flow state by me from getting distracted when looking into an issue in another some aspects of our user interface were confusing to such as the mechanism for selecting code to be included in the conversational was a little confusing doing the selection part for it to tell me what a function it gave me code that was insanely easy to copy and other participants appreciated the code selection such as enjoyed the code selection and found that very easy to in the event we identified instances in which a participant unintentionally included selected code in the conversation when it needed extraneous instances in which a code selection was omitted when it was needed to provide context for the question and instances in which a participant code directly into the chat rather than selecting it in the editor code in although these cases represent a small fraction of the instances in which a code selection was required and included in the conversation their presence does indicate that more attention is needed to the interaction design of code another issue regarded the awareness of the and the feature was only used by who used it a total of times over the course of the some participants used it specifically when they got an answer which they saw as clearly while others used it to get a variety of possible answers before the feature was used even by participants who used it a total of despite our effort to surface these conversational features in the ui via shortcut they may not have been sufficiently noticeable or button is not so often times i forgot it by at least one participant was successful with these some point it had issue with challenge and i had to start just asking was not enough and i was getting always the same and not starting again solved the utility of conversational assistance our next set of themes concerns the utility provided by tional programming participants felt the assistant was highly valuable and desired to use it in their own they felt it would be most helpful for smaller or but able to provide a wide variety of types of the fact that the interaction model was conversational and grounded in code were valuable as was the ability for the assistant to bolster learning about programming topics through that participants did question whether they could trust and rely upon the echoing a similar theme discussed in weisz et value appropriate participants rated the value of the assistant highly of many participants asked questions such i have it in my editor or made comments would enjoy using it in the would love to be able have access to it for my and love to use this tool as part of my usual programming workflow if i some of the reasons why participants found it valuable are because it me remember how to do things in certain languages that normally i would just and helps me to avoid silly syntax errors and can when i cannot remember exact names and required we did not observe any differences in value ratings based on familiarity with or recency of using participants described a wide variety of tasks for which they felt the assistant would be these tasks included and tasks such as for chunks of or for participants also felt the assistant was useful for containable novel and coding several kinds of task assistance were reported as being such as explaining code implementing business logic in a ui understanding what code does and recalling language method and arguments felt that the assistant was helpful when recognizing a specific well known algorithm but not things you make participants also made recommendations for how to increase the value of the would blow me away though is if able to help with what i do most often which is to refactor and iterate on an existing and all desired more information on the data sources used to produce the requested to the assistant examine your code and make proactive suggestions for improving it in the requested the iui march australia ross et but cautioned would need to be taken to avoid becoming an annoyance or disrupting the flow of a coding in the we probed participants on how certain changes to the assistant would either or result in no change to its over of participants felt that the assistant would be more valuable if it operated in a proactive either by making improvement suggestions in the chat or as comments directly in the of participants felt that having more buttons in the ui for common features such as explaining or documenting code would make the tool more conversational interactions grounded in one of the challenges in interpreting comments about the utility of the assistant was in disentangling the extent to which value was derived from the quality of the underlying model versus the integration of conversation in a code participants felt that the chat interaction was of participants felt that eliminating the conversational interaction and making the assistant behave more like web search would crease its our analysis of the conversation transcripts revealed that of the utterances from ipants required historical conversational context context in order to be correctly we observe that participants did rely on conversational context in their in the of participants rated the importance of the ability to ask questions as being or great several participants specifically commented on the value of this conversational absolutely loved how you can straight up ask questions to the assistant without having to reiterate the original expressed a similar think the conversational context was someone just in communicating that a running conversation where my context is provided a similar tool was so helpful at answering questions i had about the code in the context of the code i am working i was also impressed with how well it was able to remember the context of our especially when i asked vague in some participants identified how a conversational interaction grounded in code was i think to the dev context could be very in of utterances included a relevant code selection showing that participants valued this contrasting with these felt that interacting with the assistant conversationally was and they employed a more direct really like the i converse with it like a chat i often told it what to do this as opposed to asking it what to do do i document this talking to it the way that was suggested in the tutorial seemed overly despite these individual differences in interaction envisioned that both interaction styles could be supported in the think both options should people should be able to input their queries like a search bar and also give their question as if in learning one specific benefit of the assistant identified by participants is its ability to help people improve their programming skills and reinforce knowledge for it can help users how to do things in certain such when i am using a language i used in a the assistant can also serve as an memory such as when use a lot of libraries that i always remember all of the matter how good as a you remember all the api of hundreds of libs or new learn new dev lang and new felt the assistant perfect for programmers of all and felt it could help them rapidly improve their python have wanted to learn the main concern how much time spent learning is needed before i could actually get some value out of learning i have a feeling this would cut that time down from weeks to a day or also identified the fact because the interactions with the assistant are it forces people to learn how to communicate to others about their conversation aspect promotes proper which would really stand to benefit budding programmers if they want to learn how to explain cepts more fluently in the future to their suggested that on programming assistance might have a detrimental effect to definitely a huge time but on it may cause new developers to skip learning the reference material themselves and discovering new things and sparking new many participants raised questions about whether they could trust the responses provided by the asked this question most the code be other participants raised similar such wondering how it validates if it can be trusted to always give a working and lack of source and context may raise doubts in the mind of the these issues of trust were exacerbated by the fact that the assistant did not allow participants to actually run their because of this participants had to rely on their own knowledge to judge the correctness of the is no way to evaluate if the sistant is giving you the right advise or not other than your own and had to trust that it was correct use my own prior the assistant iui march australia described the potential consequences of allowing the tant to write code for only thing that made me nervous was that it could have introduced a bug that immediately and given i write the i could have easily glossed over a mistake when reviewing especially if it is also the one writing the test despite our efforts to make the assistant respond in we did observe participants sometimes uncritically accept generated results that were clearly wrong or we did find behavioral evidence for listing building trust through explanations and tions what is a unit a unit test is a test of a single function or it is typically written by the programmer who wrote the def while b a return a how would i write a unit test for this i think you would do something like def assert assert assert assert what is a euclid function the euclid function is a function that computes the greatest common divisor of two is this a good unit test for a euclid function i believe that it is a good unit test for a euclid why it seems to me that it tests the edge cases of a and b being equal a being greater than and b being greater than thanks socrates this was helpful always happy to one way to address trust issues is for the assistant to provide further explanations and justifications that can calibrate a confidence in the such explanations could be requested though most participants did not attempt to do one participant did ask for such and we show a summary of their transcript in listing in this asked for a definition of a unit test an nation of the code being tested and justifications of the quality of the unit test we observe that the assistant is capable of producing explanations and justifications when patterns of interaction and mental models participants interacted with the assistant in a variety of ways with two main patterns of usage standing invoking the tant to solve the entire programming and breaking the challenge down into a set of smaller tasks and invoking the help for there were no clear differences in how participants with differing python experience approached the mental models of the assistant also although participants strongly saw the role of the assistant as being a their behaviors revealed that in many they actually treated it as a social in participants ascribed various mental capacities to the such as having the ability to and participants felt the assistant changed the nature of their work for some it enabled them to focus on the aspects of development because the assistant handled details or provided partial solutions for them to build many participants felt the assistant sped up their work and helped them remain focused on their participants drew comparisons between the assistant with other forms of programming support such as copilot and web they felt that the conversational style of interaction enabled them to discover emergent behaviors from the model that were unavailable from focus on code they also felt that the examples provided by the assistant were more readily usable within their own code compared to browsing for answers within search speeding up the coding some participants advocated for a anced approach to the design of programming assistance tools by incorporating multiple modes of interaction rather than fixating on a single interaction styles and assistant we observed that ticipants interacted with the assistant in strikingly different some participants would present the entire lenge description to the assistant and then work with the results it other participants approached the programming lenges in a piecemeal breaking them apart into a set of smaller then invoking the assistant to aid with each experience with python was not a determinant of how pants approached the programming but it did seem to impact how participants interacted with the less enced participants tended to ask the assistant basic questions such is a unit not familiar with and do i document a year of more rienced participants made detailed requests about specific python libraries or such a pandas dataframe with two columns and please use matplotlib to draw me a years of and a kutta algorithm for solving an ode with adaptive time years of another difference we observed in how people interacted with the assistant stemmed from their view on the role it played in their iui march australia ross et collaborative some such as treated it more as a tool by issuing commands rather than asking as quoted they converse with it like a chat described their interaction style found myself wanting to type search queries into not treating it as a person but as a search in anticipation that participants would have different tions to the assistant and its we asked a question on the task survey about the different kinds of roles the assistant might these roles generally fell into one of two a tool orientation a reference a content a problem and a social orientation a a an a participants rated the extent to which they viewed the assistant in each of these roles on a point scale of not at all a little somewhat or a great deal tool content generator reference guide collaborator problem solver advisor coach reviewer colleague role percentage of participants rating not at all a little somewhat a great deal figure role participants overwhelmingly felt that the role was of a tool orientation rather than a social the chart shows ratings distributions across different roles the assistant might sorted by the percentage of participants who rated the extent of that role as great the leftmost role is of a with of participants rating it as great following tool are content generator reference guide collaborator problem solver advisor coach reviewer and colleague we show ratings of the role in figure despite the fact that their attitudes toward the assistant ingly reflected a tool their behaviors reveal that many participants actually treated the assistant as a social scribed how felt it like a and told the could not have solved without your to which the assistant glad i could the literature on computers as social agents helps us interpret this result as it demonstrates how computers are often treated like people conversational agents can exacerbate this as they likely have been trained on amples of social they can also respond as social in the conversation we identified participants who acted with the assistant in a fashion social orientation codes in table twenty participants made at least one an extreme form of this action style can be seen in a snippet from transcript the participants with a social orientation did not generally differ in their role ratings from other except that they rated the assistant as more likely to be an advisor exact 𝑝 or a reviewer exact 𝑝 they did not differ in their ratings of the tool at least for some there seems to be a dissonance in their view of the role listing excerpt from interaction with the in which offers their thanks and thank been really nice to code with or to have you lol you i hope to see you on air soon i hope so congrats to you research you made a good glad you think sorry they made a good job you too thank see you next mental participants made a number of inferences about the assistant and its capacities for many participants talked about how the assistant possessed a level of of as well as and was amazed by the ability to a plain english request and interpret it ascribed intelligence to the was a lot smarter and trained i thought it one participant assumed that the assistant improving through another felt that the assistant was capable of understands the it can calculate the results of a function not all participants were convinced of the ability to questioned the wonder how far beyond boilerplate it can go and if it works for truly original impact of conversational assistance on work many participants discussed how the assistant shaped their work practices on the programming ticipants felt that the assistant me code and would up my because could focus on validating and improving the code it generated instead of having to write it all from remarked opens a whole new door for fast discussed how the assistant helpful in staying focused on the although for took time to get into tempo with the pointed out how the assistant would change the nature of their job could focus more on higher level aspects and therefore achieving better besides the the assistant iui march australia data science becomes a more level other participants discussed a work process in which the tant provided incomplete solutions the or draft of upon which they could aptly described this nice to copy well formulated challenges in natural language and have the code generator take its best stab at then edit to our hearts participants felt that human review of the responses was necessary because answers provided are generally not novel often look clunky and there may be some unnecessary basically the code would need to be also pointed out how code generator was good but you still have to really check discussed how they would turn to the assistant as a first source for and only if it able to help would they then turn to other support way i will use it i will first the assistant for most of my only in certain cases where assistant cant answer things i will turn up to official documentation or stack latency was a factor for interactive use of the assistant and participants noticed when the assistant took a long time to it took lot of like more than also felt response a little slow in chat mode i expect faster as discussed in section the assistant took an average of seconds to respond to a and participants did appreciate when the assistant produced rapid loved how quick it was able to pull up answers to questions i conversational interaction other interaction though our study was not intended to make comparative ations with the copilot we nonetheless asked participants whether they were familiar with and if to comment on how the two tools we also asked a similar question to compare the assistant with another popular form of programming searching the web a search engine like or a site like stack in discussing the differences tween these three we note that the primary differentiator is their interaction the interaction model for the assistant is clearly users ask questions in natural language and are provided with a response in natural language the interaction model of copilot is reminiscent of direct manipulation interfaces in which the actions in the user interface directly manipulate an object on the copilot automatically makes autocompletion suggestions as the user this completed code is directly placed in the source the work is contained entirely within the scope of the object on which they are working the source which is how direct manipulation interfaces in web users enter a separate search context a search engine accessed within a web type in a natural language and then forage amongst search results to identify relevant items of interest when a desirable item is users must translate it into their code environment via and possibly edit it to fit their existing we also note that the assistant and copilot both utilize the same underlying ai codex which means that the only difference between these tools is the user the extent to which codex was trained on data from related web sites is less but for the purposes of our we focus our discussion solely on the differences in their interaction participants reported various benefits and drawbacks of a versational interaction over a direct manipulation conversation very and much more natural using natural language with the in felt that use cases of assistant seem more many participants were surprised at the variety of tasks the assistant was capable of from writing unit tests and documentation to explaining what code did and even answering questions we note that the assistant utilizes the same underlying model as yet the tional interface was able to expose a wider variety of emergent behaviors from the multiple participants explored the limits of the knowledge and abilities beyond our programming for asked it questions about physics and ordinary differential equations as written by and was surprised by the of what it could asked it some physics and ode question and the though not included the key parts needed to write that probed the assistant on its knowledge of geography and was surprised when the assistant produced a correct asked something out of sw engineering domain and it replied also by correctly swering on my for some the ability to assess the sponse before committing to it by inserting code into their was a described how the paste boundary provided them with bit more control to ask specific questions about what i wanted and to assess before putting it in my other participants felt that the boundary was more think the main difference is the ability of copilot to suggest code while you what make it faster and easier to while using the you need to go to the ask the copy the an our comparison of direct and conversational action models is reminiscent of historical comparisons of and graphical user interfaces each modality was shown to have advantages and for interfaces can provide accessibility and productivity whereas graphical user interfaces provide greater discoverability some researchers explored ways to bridge the two interaction such as by developing gui wrappers for command line programs or by developing tools that converted gui activities into procedural descriptions our view is that similar bridges can be constructed between direct and conversational models of a interaction with an llm need not be constrained to a single interaction iui march australia ross et code rephrase the question if it was not understood by the and edit it to match your a large number of participants felt that the conversational action was faster than web search because of its ability to provide that can be exactly to your without having to through lots of to get what you in the assistant provided better that were more relevant to the and without having to through answers on your own or read or at many posts before finding the relevant despite these some participants felt that the assistant might not work well for specific and difficult problems on a bigger as compared to web felt that data the as as the other participants felt that the assistant lacked the and social that accompanies answers on like to see the different versions proposed on stack overflow and the commentary of what makes one tion better than another in a given some participants promoted a more balanced view that there a single mode of interaction superior to all felt that web search would be a fallback when the assistant failed to answer a described how search could be integrated with the conversational think both options should people should be able to input their queries like a search bar and also give their question as if in discussion value of conversational interaction we began our research by asking the question of whether temporary developments in llms could sufficiently support a conversational programming we believe that our work has demonstrated that they the assistant was viewed by our participants as a useful tool that provided real value so much so that many participants itly requested or expressed the desire to use it in their own how much of this value was derived from the model itself and its ability to produce responses to programming versus from ability to conduct extended conversational interactions grounded in their actual source we believe that both of these constituent aspects were many participants commented on their surprise and faction with the quality of the responses participants also valued the conversational interactions that they had with the in the event we saw dence that participants were leveraging conversational context to ask questions as well as leveraging code context by ing about their code selections many participants reported that they would find the tool less valuable if the sational interaction were removed sation seemed to provide unique value beyond other interaction models manipulation and because of its ness in the ui and its ability to surface emergent behaviors of the model we do not believe that these different interaction models are in competition and we agree with assessment that assistive tools can be built using a plethora of different interaction for use cases in which a model is known to produce results code autocompletion for a direct manipulation interface seems wholly appropriate as it would provide a erable and predictable way of invoking the model to produce a known type of direct manipulation interfaces may be less ideal for surfacing the emergent behaviors of a foundation model and thus natural language interaction may be more many popular such as and stable diffusion operate in a in which the user specifies a clicks a and gets our study demonstrates how the additional contextual layers of versational history and the provide additional value to the toward synergy the aim of ai is to people to and act in extraordinary by combining potent user experiences with embedded ai methods to support services that users building upon this rezwana and maher posit a creative interaction such as contribution and are the driving forces of the therefore the interaction model is a critical and essential component for effective they go on to note is relatively little research about interaction design in the which is reflected in a lack of focus on interaction design in many existing our study begins to address this while many systems examine casual tasks or experimental activities spoto and oleynik our focus was on the practice of our goal was to understand attitudes ward a conversational programming akin to wang et examination of data attitudes toward automated data science technologies we found despite an initial level of participants felt that a conversational assistant would provide value by improving their productivity further work is needed to assess the extent to which this type of assistance provides measurable productivity campero et conducted a survey of papers published in that examined the notion that a team can accomplish more by working together than either party could accomplish working they found mixed with no clear consensus emerging on how to design ai systems that can guarantee positive summarizing from their achieving substantial synergies among people and computers is harder than many people haps it new ways of configuring groups that include people and and perhaps it needs the assistant iui march australia more focused attention from researchers than it so we believe such evaluations of synergy should go beyond performance as implied by many of the uses cases listed by seeber et ai systems are often deployed in contexts that require longitudinal use such as product design game sign and engineering section we would expect that over time and through interaction with each teams would improve their performance through a mutual learning evidence for this process surfaced in our study when participants described how they could improve their programming skills by interacting with the assistant we assert that the learning should operate in both not only should people improve their programming but the model itself can also improve based on interactions with for when the assistant provides a code example to the and the user takes that example and edits those edits constitute feedback that can be used to further the in through longitudinal we believe that human and ai partners can create reciprocal representations of one another the human is likely to create a mental model of the and the ai may be engineered to develop a user model for each of its human users such a pair of models is often described as mutual theory of mind this type of capability raises the possibility of personalizing and adapting an assistant to the strengths and needs of individual with such an assistant that knows a user is learning a programming language could provide natural language tions alongside code whereas an assistant that knows a user is strongly skilled in a programming language might shorten or omit those users are likely to update their mental models of the ai with more we believe the space for exploring how these reciprocal models impact synergy is and we encourage additional work in this ai systems that are designed to combine and synergize the distinct skills of humans and ai models cannot ceed if they diminish the human skills upon which they ai systems develop new and plementary skills for both the human and ai constituents and we believe that mutual learning may address concerns that the wide deployment and use of ai systems will result in a of the workforce the design decisions that go into an interactive ai system have ethical our design attempts to augment the knowledge and skills by presenting help on couched in which leaves the user firmly in control and ultimately responsible for the work opportunities for future research our work highlights many interesting avenues for future ments that could be made to conversational assistants such as our as well as future centered research on conversational our work employed a model that was not cally designed to handle conversational the underlying llm for conversational such as what has been done with lamda is one opportunity to improve the another opportunity is to align the guage model to follow the desiderata proposed by askell et and described by ouyang et should help the user solve their honest fabricate information or mislead the and harmless should not cause or social harm to people or the glaese et propose a slightly different desiderata of instead of which may be more applicable to the software engineering as the ability to produce correct code and correct answers about code are both important properties of a conversational programming combining llms with approaches to establish ditional context for the such as alphacode has may also result in more capable these need not be limited to textual but could be conducted over priate semantic stores a knowledge and take advantage of explicit semantic reasoning resulting in an integration of symbolic and neural allowing for of the type shown in nye et could result in as well as better explanations and another avenue for improvement involves the prompt used to configure the assistant just as the prompt for each successive interaction is modified by the growth of the tional there is no requirement that the initial prompt be it too can be specialized to incorporate aspects of a user enabling the realization of a mutual theory of mind viding better ux affordances for visualizing and manipulating the active contexts code and conversation could provide users with more control over which information contributes to the generation of the our participants clearly indicated that they were interested in having an assistant that behaved more in contrast to our deliberate design of an assistant that never takes conversational a more proactive assistant would be able to interrupt or remind a user when necessary yet this characteristic raises many challenging how can we calibrate the threshold for such how can users tune the assistant to deliver only those interruptions that the they would find useful how can we help users to regain their prior context after dealing with an interruption should an assistant be used to persuade or nudge the user who should determine the and insistence of such persuasion attempts should users have the ability to moderate or defeat attempted or should those decisions be left to the we explored the different kinds of role orientations our participants had toward the assistant and found that participants varied in their views of it as a tool versus a social agent rator or we posit that effectiveness in working with an ai system may be influenced by their role and we encourage future research in this iui march australia ross et conclusion we developed a prototype the in order to assess the utility of a conversational assistant in a software engineering the assistant was implemented using a large language codex and was capable of generating both code and natural language responses to user we further used the prompting mechanism of the model to set up a conversational interaction in which the model uses the conversational plus the current in order to generate a in this users are able to ask questions in the chat that reference prior utterances and we incorporated the conversational assistant into a code editing enabling the conversation to be grounded in the context of the source we evaluated this system with participants with varied levels of programming and their quantitative and qualitative coupled with their usage of the demonstrated the and sometimes types of assistance it was able to many participants noted the high quality of the tional including the ability to produce explain answer general programming and even answer general knowledge participants felt this type of assistance would aid their and they drew meaningful contrasts between the conversational style of interaction with other tools that employ a direct manipulation or interaction our study motivates the use of conversational styles of action with large language models by showing how they enable emergent behaviors in a the assistant did not always generate perfect code or correct participants in our study had an overall positive perience working with it on a variety of programming we believe that our work takes us one step closer to realizing the vision of learning how to design systems that maximize the synergy in acknowledgments we would like to thank socrates for his tireless assistance during the user as well as for suggesting the title of this paper based on its	['[1] Rabe Abdalkareem, Emad Shihab, and Juergen Rilling. 2017. What Do Developers Use the Crowd For? A Study Using Stack Overflow. IEEE Software 34, 2 (2017), 53–60. https://doi.org/10.1109/MS.2017.31 ', '[2] Eleni Adamopoulou and Lefteris Moussiades. 2020. Chatbots: History, technol- ogy, and applications. Machine Learning with Applications 2 (2020), 100006. ', '[3] Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, and Quoc V. Le. 2020. Towards a Human-like Open-Domain Chatbot. ', '[4] Safinah Ali, Nisha Elizabeth Devasia, and Cynthia Breazeal. 2022. Escape! Bot: Social Robots as Creative Problem-Solving Partners. In Creativity and Cognition. 275–283. ', '[5] Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, and Charles Sutton. 2018. A survey of machine learning for big code and naturalness. ACM Computing Surveys (CSUR) 51, 4 (2018), 1–37. ', '[6] Irene Alvarado, Idan Gazit, and Amelia Wattenberger. 2022. GitHub Next | GitHub Copilot Labs. https://githubnext.com/projects/copilot-labs/ ', '[7] Hikari Ando, Rosanna Cousins, and Carolyn Young. 2014. Achieving saturation in thematic analysis: Development and refinement of a codebook. Comprehensive Psychology 3 (2014), 03–CP. ', '[8] Craig Anslow, Stuart Marshall, James Noble, and Robert Biddle. 2013. Sourcevis: Collaborative software visualization for co-located environments. In 2013 First IEEE Working Conference on Software Visualization (VISSOFT). IEEE, 1–10. ', '[9] Zahra Ashktorab, Michael Desmond, Josh Andres, Michael Muller, Naren- dra Nath Joshi, Michelle Brachman, Aabhas Sharma, Kristina Brimijoin, Qian Pan, Christine T Wolf, et al. 2021. AI-Assisted Human Labeling: Batching for Efficiency without Overreliance. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1 (2021), 1–27. ', '[10] Catherine A Ashworth. 1996. GUI Users have trouble using graphic conventions on novel tasks. In Conference Companion on Human Factors in Computing Systems. 75–76. ', '[11] Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et al. 2021. A general language assistant as a laboratory for alignment. arXiv preprint arXiv:2112.00861 (2021). ', '[12] Leif Azzopardi, Paul Thomas, and Nick Craswell. 2018. Measuring the utility of search engine result pages: an information foraging based measure. In The 41st International ACM SIGIR conference on research & development in information retrieval. 605–614. ', '[13] Shraddha Barke, Michael B James, and Nadia Polikarpova. 2022. Grounded Copilot: How Programmers Interact with Code-Generating Models. arXiv preprint arXiv:2206.15000 (2022). ', '[14] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. 2021. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258 (2021). ', '[15] Joel Brandt, Mira Dontcheva, Marcos Weskamp, and Scott R Klemmer. 2010. Example-centric programming: integrating web search into the development environment. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 513–522. ', '[16] Virginia Braun and Victoria Clarke. 2022. Common challenges in Thematic Analysis and how to avoid them. Retrieved August 11 2022 from https://youtu. be/tpWLsckpM78 ', '[17] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Ka- plan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 1877–1901. https://proceedings.neurips.cc/paper/2020/ file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf ', '[18] Sallyann Bryant, Pablo Romero, and Benedict" du Boulay. 2006. The Collabora- tive Nature of Pair Programming. In Extreme Programming and Agile Processes in Software Engineering, Pekka Abrahamsson, Michele Marchesi, and Giancarlo Succi (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 53–64. ', '[19] Andres Campero, Michelle Vaccaro, Jaeyoon Song, Haoran Wen, Abdullah Almaatouq, and Thomas W Malone. 2022. A Test for Evaluating Performance in Human-Computer Systems. arXiv preprint arXiv:2206.12390 (2022). ', '[20] Gaetano Cascini, Yukari Nagai, Georgi V Georgiev, Jader Zelaya, Niccolò Be- cattini, Jean-François Boujut, Hernan Casakin, Nathan Crilly, Elies Dekoninck, John Gero, et al. 2022. Perspectives on design creativity and innovation research: 10 years later. , 30 pages. ', '[21] Stephen Cass. 2022. Top Programming Languages 2022. IEEE Spectrum (23 Aug 2022). https://spectrum.ieee.org/top-programming-languages-2022 ', '[22] Cristina Catalan Aguirre, Nuria Gonzalez Castro, Carlos Delgado Kloos, Carlos Alario-Hoyos, and Pedro José Muñoz Merino. 2021. Conversational agent for supporting learners on a MOOC on programming with Java. (2021). ', '[23] Ana Paula Chaves and Marco Aurelio Gerosa. 2021. How should my chatbot interact? A survey on social characteristics in human–chatbot interaction design. International Journal of Human–Computer Interaction 37, 8 (2021), 729–758. ', '[24] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harrison Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sas- try, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, David W. Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William H. Guss, Alex Nichol, Igor Babuschkin, S. Arun Balaji, Shantanu Jain, Andrew Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew M. Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evalu- ating a Large Language Models Trained on Code. ', '[25] Li-Te Cheng, R.B. De Souza, Susanne Hupfer, John Patter- son, and Steven Ross. 2003. Building Collaboration into IDEs: Edit>Compile>Run>Debug>Collaborate? Queue 1, 9 (2003). 508', '[26] Carl Cook, Warwick Irwin, and Neville Churcher. 2005. A user evaluation of synchronous collaborative software engineering tools. In 12th Asia-Pacific Software Engineering Conference (APSEC05). IEEE, 6–pp. ', '[27] Claudio León de la Barra, Broderick Crawford, Ricardo Soto, Sanjay Misra, and Eric Monfroy. 2013. Agile Software Development: It Is about Knowledge Management and Creativity. In Computational Science and Its Applications – ICCSA 2013, Beniamino Murgante, Sanjay Misra, Maurizio Carlini, Carmelo M. Torre, Hong-Quang Nguyen, David Taniar, Bernady O. Apduhan, and Osvaldo Gervasi (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 98–113. ', '[28] Uri Dekel and Steven Ross. 2004. Eclipse as a platform for research on in- terruption management in software development. In Proceedings of the 2004 OOPSLA workshop on Eclipse Technology eXchange (Vancouver, British Columbia, Canada), Michael G. Burke (Ed.). ACM, 12–16. ', '[29] Bobbie Eicher, Kathryn Cunningham, Sydni Peterson Marissa Gonzales, and Ashok Goel. 2017. Toward mutual theory of mind as a foundation for co-creation. In International Conference on Computational Creativity, Co-Creation Workshop. ', '[30] Stephen M Fiore, Eduardo Salas, and Janis A Cannon-Bowers. 2001. Group dynamics and shared mental model development. How people evaluate others in organizations 234 (2001). ', '[31] Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. 1995. Design patterns: elements of reusable object-oriented software. Addison-Wesley. ', '[32] GitHub, Inc. 2022. GitHub copilot · your AI pair programmer. Retrieved August 5, 2022 from https://github.com/features/copilot/ ', '[33] Amelia Glaese, Nat McAleese, Maja Trębacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green, Soňa Mokrá, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel, William Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and Geoffrey Irving. 2022. Improving alignment of dialogue agents via targeted human judgements. https://arxiv.org/abs/2209.14375 ', '[34] Stephanie Glen. 2022. ChatGPT writes code, but wont replace devel- opers. TechTarget (14 12 2022). Retrieved 20-Jan-2023 from https: //www.techtarget.com/searchsoftwarequality/news/252528379/ChatGPT- writes-code-but-wont-replace-developers ', '[35] Samuel Holmes, Anne Moorhead, Raymond Bond, Huiru Zheng, Vivien Coates, and Mike McTear. 2018. WeightMentor: a new automated chatbot for weight loss maintenance. In Proceedings of the 32nd International BCS Human Computer Interaction Conference 32. 1–5. ', '[36] Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2020. Deep code comment generation with hybrid lexical and syntactical information. Empirical Software Engineering 25, 3 (2020), 2179–2217. ', '[37] Edwin L Hutchins, James D Hollan, and Donald A Norman. 1985. Direct manip- ulation interfaces. Human–computer interaction 1, 4 (1985), 311–338. ', '[38] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016. Summarizing source code using a neural attention model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2073–2083. ', '[39] Andreas Jedlitschka and Markus Nick. 2003. Software Engineering Knowledge Repositories. Springer Berlin Heidelberg, Berlin, Heidelberg, 55–80. ', '[40] Eirini Kalliamvakou. 2022. Research: Quantifying github copilots impact on developer productivity and happiness. https://github.blog/2022-09-07- research-quantifying-github-copilots-impact-on-developer-productivity- and-happiness/ ', '[41] Anna Kantosalo et al. 2019. Human-Computer Co-Creativity: Designing, Evalu- ating and Modelling Computational Collaborators for Poetry Writing. (2019). ', '[42] Sandeep Kaur Kuttal, Bali Ong, Kate Kwasny, and Peter Robe. 2021. Trade- Offs for Substituting a Human with an Agent in a Pair Programming Context: The Good, the Bad, and the Ugly. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI 21). Association for Computing Machinery, New York, NY, USA, Article 243, 20 pages. ', '[43] Lauramaria Laine. 2021. Exploring Advertising Creatives Attitudes Towards Human-AI Collaboration. (2021). ', '[44] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, and et al. 2022. Competition-level code generation with AlphaCode. https: //arxiv.org/abs/2203.07814 ', '[45] Yaosheng Lou and Qi Sun. 2021. Over-reliance on database: A case study of using web of science. Human Behavior and Emerging Technologies 3, 3 (2021), 454–459. ', '[46] David Lyell and Enrico Coiera. 2017. Automation bias and verification complex- ity: a systematic review. Journal of the American Medical Informatics Association 24, 2 (2017), 423–431. ', '[47] Wendy E Mackay and Anne-Laure Fayard. 1997. HCI, natural science and design: a framework for triangulation across disciplines. In Proceedings of the 2nd conference on Designing interactive systems: processes, practices, methods, and techniques. 223–234. ', '[48] John E Mathieu, Tonia S Heffner, Gerald F Goodwin, Eduardo Salas, and Janis A Cannon-Bowers. 2000. The influence of shared mental models on team process and performance. Journal of applied psychology 85, 2 (2000), 273. ', '[49] Cade Metz. 2022. Meet GPT-3. It Has Learned to Code (and Blog and Ar- gue). (Published 2020). https://www.nytimes.com/2020/11/24/science/artificial- intelligence-ai-gpt3.html ', '[50] Robert J. Moore and Raphael Arar. 2019. Conversational UX Design: A Practi- tioners Guide to the Natural Conversation Framework. Association for Computing Machinery, New York, NY, USA. ', '[51] Ekaterina A Moroz, Vladimir O Grizkevich, and Igor M Novozhilov. 2022. The Potential of Artificial Intelligence as a Method of Software Developers Produc- tivity Improvement. In 2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus). IEEE, 386–390. ', '[52] Michael Muller, Stevean Ross, Stephanie Houde, Mayank Agarwal, Fernando Martinez, John Richards, Kartik Talamadupula, and Justin D Weisz. 2022. Drink- ing Chai with Your (AI) Programming Partner: A Design Fiction about Gener- ative AI for Software Engineering. HAI-GEN Workshop at IUI 2022: 3rd Work- shop on Human-AI Co-Creation with Generative Models (2022). https://hai- gen.github.io/2022/ ', '[53] Sandra R Murillo and J Alfredo Sánchez. 2014. Empowering interfaces for system administrators: Keeping the command line in mind when designing GUIs. In Proceedings of the XV International Conference on Human Computer Interaction. 1–4. ', '[54] Elizabeth D Mynatt and Gerhard Weber. 1994. Nonvisual presentation of graph- ical user interfaces: contrasting two approaches. In Proceedings of the SIGCHI conference on Human factors in computing systems. 166–172. ', '[55] Alok Mysore and Philip J Guo. 2017. Torta: Generating mixed-media gui and command-line app tutorials using operating-system-wide activity tracing. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology. 703–714. ', '[56] C. Nass and Y. Moon. 2000. Machines and Mindlessness: Social Responses to Computers. Journal of Social Issues 56, 1 (2000), 81–103. ', '[57] Nhan Nguyen and Sarah Nadi. 2022. An Empirical Evaluation of GitHub Copi- lots Code Suggestions. In 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR). IEEE, 1–5. ', '[58] Martin Nordio, H Estler, Carlo A Furia, Bertrand Meyer, et al. 2011. Collaborative software development on the web. arXiv preprint arXiv:1105.0768 (2011). ', '[59] Maxwell Nye, Anders Andreassen, Guy Gur-Ari, Henryk Witold Michalewski, Ja- cob Austin, David Bieber, David Martin Dohan, Aitor Lewkowycz, Maarten Paul Bosma, David Luan, Charles Sutton, and Augustus Odena. 2021. Show Your Work: Scratchpads for Intermediate Computation with Language Models. https://arxiv.org/abs/2112.00114. ', '[60] OpenAI. 2022. ChatGPT: Optimizing Language Models for Dialogue. OpenAI Blog (30 11 2022). Retrieved 20-Jan-2023 from https://openai.com/blog/chatgpt/ ', '[61] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. https://arxiv. org/abs/2203.02155 ', '[62] Peter Pirolli and Stuart Card. 1999. Information foraging. Psychological review 106, 4 (1999), 643. ', '[63] Larry Press. 1990. Personal computing: Windows, DOS and the MAC. Commun. ACM 33, 11 (1990), 19–26. ', '[64] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language Models are Unsupervised Multitask Learners. ', '[65] Alvin Rajkomar, Jeffrey Dean, and Isaac Kohane. 2019. Machine learning in medicine. New England Journal of Medicine 380, 14 (2019), 1347–1358. ', '[66] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125 (2022). ', '[67] B. Reeves and C.I. Nass. 1996. The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places. CSLI Publications. ', '[68] Mawarny Md Rejab, James Noble, and George Allan. 2014. Distributing Expertise in Agile Software Development Projects. In 2014 Agile Conference. 33–36. ', '[69] Jeba Rezwana and Mary Lou Maher. 2021. COFI: A Framework for Modeling Interaction in Human-AI Co-Creative Systems.. In ICCC. 444–448. ', '[70] Charles H. Rich and Richard C. Waters. 1990. The Programmers Apprentice. Addison-Wesley Publishing Company, Reading, MA. ', '[71] Peter Robe and Sandeep Kaur Kuttal. 2022. Designing PairBuddyA Conver- sational Agent for Pair Programming. ACM Transactions on Computer-Human Interaction (TOCHI) 29, 4 (2022), 1–44. ', '[72] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. 2022. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recogni- tion. 10684–10695. 509', '[73] Steven Ross, Elizabeth Brownholtz, and Robert Armes. 2004. A Multiple- Application Conversational Agent. In Proceedings of the 9th International Con- ference on Intelligent User Interfaces (Funchal, Madeira, Portugal) (IUI 04). Asso- ciation for Computing Machinery, New York, NY, USA, 319–321. ', '[74] Steven Ross, Elizabeth Brownholtz, and Robert Armes. 2004. Voice User Interface Principles for a Conversational Agent. In Proceedings of the 9th International Conference on Intelligent User Interfaces (Funchal, Madeira, Portugal) (IUI 04). Association for Computing Machinery, New York, NY, USA, 364–365. ', '[75] Baptiste Roziere, Marie-Anne Lachaux, Lowik Chanussot, and Guillaume Lample. 2020. Unsupervised Translation of Programming Languages. In Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 20601–20611. ', '[76] Harvey Sacks. 1984. Notes on methodology. In Structures of Social Action: Studies in Conversation Analysis, John Heritage and J. Maxwell Atkinson (Eds.). Cambridge University Press, Cambridge, 2–27. ', '[77] Nithya Sambasivan and Rajesh Veeraraghavan. 2022. The Deskilling of Domain Expertise in AI Development. In CHI Conference on Human Factors in Computing Systems. 1–14. ', '[78] Harini Sampath, Alice Merrick, and Andrew Macvean. 2021. Accessibility of command line interfaces. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1–10. ', '[79] Matthias Scheutz, Scott A DeLoach, and Julie A Adams. 2017. A framework for developing and using shared mental models in human-agent teams. Journal of Cognitive Engineering and Decision Making 11, 3 (2017), 203–224. ', '[80] Isabella Seeber, Eva Bittner, Robert O Briggs, Triparna De Vreede, Gert-Jan De Vreede, Aaron Elkins, Ronald Maier, Alexander B Merz, Sarah Oeste-Reiß, Nils Randrup, et al. 2020. Machines as teammates: A research agenda on AI in team collaboration. Information & management 57, 2 (2020), 103174. ', '[81] Shilad Sen, Werner Geyer, Michael Muller, Marty Moore, Beth Brownholtz, Eric Wilcox, and David R Millen. 2006. FeedMe: a collaborative alert filtering system. In Proceedings of the 2006 20th anniversary conference on Computer supported cooperative work. 89–98. ', '[82] Ben Shneiderman. 2020. Human-centered artificial intelligence: Three fresh ideas. AIS Transactions on Human-Computer Interaction 12, 3 (2020), 109–124. ', '[83] Ben Shneiderman. 2022. Human-Centered AI. Oxford University Press. ', '[84] Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, et al. 2022. BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage. arXiv preprint arXiv:2208.03188 (2022). ', '[85] Michael Skirpan and Casey Fiesler. 2018. Ad empathy: A design fiction. In Proceedings of the 2018 ACM Conference on Supporting Groupwork. 267–273. ', '[86] Diomidis Spinellis. 2012. Git. IEEE Software 29, 3 (2012), 100–101. https: //doi.org/10.1109/MS.2012.61 ', '[87] Angie Spoto and Natalia Oleynik. 2017. Library of Mixed-Initiative Creative Interfaces. Retrieved 19-Jun-2021 from http://mici.codingconduct.cc/ ', '[88] Ayushi Srivastava, Shivani Kapania, Anupriya Tuli, and Pushpendra Singh. 2021. Actionable UI Design Guidelines for Smartphone Applications Inclusive of Low-Literate Users. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1 (2021), 1–30. ', '[89] Margaret-Anne Storey and Alexey Zagalsky. 2016. Disrupting developer produc- tivity one bot at a time. In Proceedings of the 2016 24th ACM SIGSOFT international symposium on foundations of software engineering. 928–931. ', '[90] Kartik Talamadupula. 2021. Applied AI matters: AI4Code: applying artificial intelligence to source code. AI Matters 7, 1 (2021), 18–20. ', '[91] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kul- shreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, and et al. 2022. LAMDA: Language models for dialog applications. https: //arxiv.org/abs/2201.08239 ', '[92] Michele Tufano, Dawn Drain, Alexey Svyatkovskiy, Shao Kun Deng, and Neel Sundaresan. 2020. Unit Test Case Generation with Transformers and Focal Context. arXiv preprint arXiv:2009.05617 (2020). ', '[93] Severi Uusitalo, Anna Kantosalo, Antti Salovaara, Tapio Takala, and Christian Guckelsberger. 2022. Co-creative Product Design with Interactive Evolutionary Algorithms: A Practice-Based Reflection. In International Conference on Compu- tational Intelligence in Music, Sound, Art and Design (Part of EvoStar). Springer, 292–307. ', '[94] Priyan Vaithilingam and Philip J Guo. 2019. Bespoke: Interactively synthesizing custom GUIs from command-line applications by demonstration. In Proceedings of the 32nd annual ACM symposium on user interface software and technology. 563–576. ', '[95] Priyan Vaithilingam, Tianyi Zhang, and Elena L. Glassman. 2022. Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems (New Orleans, LA, USA) (CHI EA 22). Association for Computing Machinery, New York, NY, USA, Article 332, 7 pages. https://doi.org/10.1145/3491101.3519665 ', '[96] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems, I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), Vol. 30. Curran Associates, Inc. https://proceedings.neurips.cc/paper/ 2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf ', '[97] Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and Philip S Yu. 2018. Improving automatic source code summarization via deep rein- forcement learning. In Proceedings of the 33rd ACM/IEEE international conference on automated software engineering. 397–407. ', '[98] April Yi Wang, Dakuo Wang, Jaimie Drozdal, Michael Muller, Soya Park, Justin D Weisz, Xuye Liu, Lingfei Wu, and Casey Dugan. 2022. Documentation Matters: Human-Centered AI System to Assist Data Science Code Documentation in Computational Notebooks. ACM Transactions on Computer-Human Interaction 29, 2 (2022), 1–33. ', '[99] Dakuo Wang, Justin D Weisz, Michael Muller, Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, and Alexander Gray. 2019. Human-AI collaboration in data science: Exploring data scientists perceptions of automated AI. Proceedings of the ACM on Human-Computer Interaction 3, CSCW (2019), 1–24. ', '[100] Qiaosi Wang, Koustuv Saha, Eric Gregori, David Joyner, and Ashok Goel. 2021. Towards mutual theory of mind in human-ai interaction: How language reflects what students perceive about a virtual teaching assistant. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1–14. ', '[101] Jeremy Warner and Philip J Guo. 2017. Codepilot: Scaffolding end-to-end collaborative software development for novice programmers. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. 1136–1141. ', '[102] Justin D Weisz, Michael Muller, Stephanie Houde, John Richards, Steven I Ross, Fernando Martinez, Mayank Agarwal, and Kartik Talamadupula. 2021. Per- fection Not Required? Human-AI Partnerships in Code Translation. In 26th International Conference on Intelligent User Interfaces. 402–412. ', '[103] Justin D Weisz, Michael Muller, Steven I Ross, Fernando Martinez, Stephanie Houde, Mayank Agarwal, Kartik Talamadupula, and John T Richards. 2022. Bet- ter together? an evaluation of ai-supported code translation. In 27th International Conference on Intelligent User Interfaces. 369–391. ', '[104] Joseph Weizenbaum. 1966. ELIZA a computer program for the study of natural language communication between man and machine. Commun. ACM 9 (1966), 36–45. ', '[105] Frank F Xu, Bogdan Vasilescu, and Graham Neubig. 2022. In-ide code generation from natural language: Promise and challenges. ACM Transactions on Software Engineering and Methodology (TOSEM) 31, 2 (2022), 1–47. ', '[106] Aditya Ankur Yadav, Ishan Garg, and Dr. Pratistha Mathur. 2019. PACT - Pro- gramming Assistant ChaTbot. In 2019 2nd International Conference on Intelligent Communication and Computational Techniques (ICCT). 131–136. ', '[107] Munazza Zaib, Quan Z. Sheng, and W. Zhang. 2020. A Short Survey of Pre- trained Language Models for Conversational AI-A New Age in NLP. Proceedings of the Australasian Computer Science Week Multiconference (2020). ', '[108] Elaine Zibrowski, Lisa Shepherd, Kamran Sedig, Richard Booth, Candace Gibson, et al. 2018. Easier and faster is not always better: grounded theory of the impact of large-scale system transformation on the clinical work of emergency medicine nurses and physicians. JMIR Human Factors 5, 4 (2018), e11013. ', '[109] Albert Ziegler, Eirini Kalliamvakou, X. Alice Li, Andrew Rice, Devon Rifkin, Shawn Simister, Ganesh Sittampalam, and Edward Aftandilian. 2022. Produc- tivity Assessment of Neural Code Completion. In Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming (San Diego, CA, USA) (MAPS 2022). Association for Computing Machinery, New York, NY, USA, 21–29. https://doi.org/10.1145/3520312.3534864 510']
3	https://drive.google.com/file/d/1chhlyFzskyccJ2OvrLXQW-ifMKreTe7B/view?usp=drive_link	\N	Fuzzy logic based MPPT control for a PV system using SEPIC converter	['Moulay Abdellah Alhachemi', 'Mohammed Habbab', 'Abdeldjebar Hazzab', 'Mansour Becahr', 'Hicham Gouabi']	['Laboratory of CAOSEE', 'École de Technologie Supérieure', 'Université Tahri Mohamed', 'Université Tahri Mohamed (ETS)', '1100 Notre-dame Bechar, Algeria', 'Bechar, Algeria', 'Montréal, Canada']	['Fuzzy logic controller (FLC)', 'Maximum power point tracker (MPPT)', 'Photovoltaic (PV)']	In this study, a novel single-ended primary inductor (SEPIC) converter-based fuzzy logic controller for maximum power point tracking is presented. By adding rules to the perturb and observing search strategy, the new controller enhances it while fuzzifying and removing its flaws. When compared to traditional maximum power point tracking techniques, fuzzy logic trackers enable an accurate and quick convergence to maximum power point under both steady-state and variable weather situations. The performance of the proposed maximum power point tracker is demonstrated in simulation.	introduction the energy sources are rapidly running while the electricity demand is increasing to solve this efficient and efficient electric power generation from renewable energy sources is required renewable energy is one of the forms of energy that society can rely on because it is and has no one type of power generation that uses renewable energy is the photovoltaic system to utilize less conventional the pv system must subsequently be linked to the either directly or via a backup battery since the power produced by pv systems depends on radiation and temperature the pv framework has destitute for the control of the pv there are different sorts of converters such as buck boost and due to its output a converter acts as a where it changes its output voltage agreeing to its duty unlike the customary the sepic converter includes a output and it uses an arrangement capacitor to separate input from output the buck and converters lose half of their input control due to input current arrangement for that the two types of converters should be excluded from maximum power the boost converter has a nonstop input but the output voltage is always bigger than the which may not accomplish maximum power exchange operation in a few such as when the maximum voltage is less than the input this paper presents a strategy for an mppt standalone pv the proposed mppt can abuse the preferences of the strategy and eliminate its output has been separated into five fuzzy as the proposed strategy continuously exchanges maximum power from pv it optimizes the number of pv modelign of pv system photovoltaic is the technique and study connected to devices that directly convert sunlight into electricity utilizing photovoltaic direct conversion of solar energy into dc electrical energy can be achieved by photovoltaic cells the photovoltaic panel is made up of numerous cells that are connected in series ns or shunt where it may be mimicked by a current source coupled in parallel with a diode as described by and depicted in figure circuit for a pv the following equations provide the output i iph id i iph akbt rsh iph photo current a ideality factor kb constant of boltzmann t cell temperature id current via a diode rs series resistance current of saturation q electronic charge rsh shunt resistance v cell voltage i current of cell the shunt resistance is typically orders of magnitude larger than the series resistance it is common for the shunt and series resistances of a solar cell can be neglected to simplify the the resulting ideal current characteristic of the solar cell is given by equation i iph sepic converter power electronics researchers are working hard to create dc converters with simpler designs and greater efficiency to maintain a constant output the suggested converter employs a converter the sepic converter is made up of a duty cycle switch a two inductors and two capacitors and and a load figure depicts the circuit diagram of a sepic a sepic is a converter sepic are converters that can output voltages that are larger or equal to the input the duty cycle of the control transistor affects the sepic output the sepic converter is two converters in a boost converter followed by a it has the advantages of having a output output voltage has the same polarity as the input using a series capacitor to couple energy from the input to the output makes it more responsive to and being able to shut down when the switch is turned the output voltage drops to accompanied by a significant transient discharge of simple circuit diagram of the sepic converter figure depicts the circuit when the power switch is switched on and off figures a and figure when the switch is the first is charged from the input voltage the second inductor absorbs energy from the first capacitor leaving the output capacitor to supply the load the switch turned the switch turned equivalent circuit diagram of the sepic converter when the switch is on and when the switch is turned the input inductor is charged from the and the second inductor is charged from the first no energy is supplied to the load capacitor during this the inductor current and capacitor voltage polarities are marked in this when the power switch is turned the energy stored in the inductor is the energy stored is transferred through the diode and supplies the energy to the load as shown in figure the second inductor is also connected to the load during this the output capacitor sees a pulse of current during the off making it inherently noisier than a buck the amount that the sepic converters increase or decrease the voltage depends primarily on the duty cycle and the parasitic elements in the the output of an ideal sepic converter vout d vin a sepic converter is to process the electricity from the pv this converter either increases or decreases the pv system voltage at the the proposed sepic converter operates in buck fuzzy logic control in the fuzzy logic maximum power point tracking the voltage and current at each instant k are measured to calculate the active the active power is then compared with the power at the previous instant to obtain the change in power the voltage at instant k is compared with the voltage at instant to obtain the voltage error the power error is then divided by the current error to obtain the error the error is then compared with the previous error to calculate the change in error the error and the change in error are then used as the crisp inputs to the fuzzy logic the flow chart for the fuzzy logic mppt algorithm is shown in figure in this the mamdani inference type membership and a rule base were used for the fuzzy logic the mamdani inference technique is efficient and straightforward in defining the fuzzy output and it is more popular among researchers than other inference techniques the or triangular membership function is used because it is simpler to split into low and high membership functions than other membership it has been observed that the triangular membership function has a faster response and less overshoot than other functions a rule base was used because it has been shown to perform well fuzzy logic maximum power point tracking flow the following are the fuzzy rules in table which are used for the desired mpp of converter the membership for input variables are shown in figure and the membership for output variable is shown in figure all the functions are defined on a normalized interval fuzzy logic rules for the negative negative positive positive nb ns ze ps pb nb ps nb nb nb ns ns ps ps ns ns ns ze ze ze ze ze ze ps ns ns ps ps ps pb ns nb pb pb ps membership for input membership for output simulation results the characteristics of the photovoltaic array that we use in this paper are given in table electrical data of photovoltaic variable value maximum power pmax w open circuit voltage voc v short circuit current isc a voltage at maximum power vmax v current at maximum power imax a table shows the sepic converter settings utilized in this the sepic converter is linked to the pv panel in the full and the duty cycle is regulated by the fuzzy logic the sepic converter variable value switching frequency khz load resistance ω inductance mh inductance mh capacitor µf capacitor µf the results are provided under standard test and it is shown in figure and power output at and using mppt and fuzzy logic to a sepic converter for a pv system result in considerable performance increased power higher decreased enhanced transient and resilience are examples of these conclusions this paper presents the design of an photovoltaic system with a fuzzy logic boost the proposed system was simulated in and tested under various weather the results showed that the fuzzy logic algorithm outperformed the conventional algorithms in terms of mppt accuracy and minimization of regardless of rapid changes in	['[1] G. Mahendran, and KV. Kandaswamy. Ant Colony Optimized Tuned DC-DC converter. International Journal of Computer Applications (0975–8887) 108.11 (2013): 45-50. ', '[2] J. Dunia, and BMM Mwinyiwiwa. Performance Comparison between ĆUK and SEPIC Converters for Maximum Power Point Tracking Using Incremental Conductance Technique in Solar Power Applications. International Journal of Electrical, Computer, Energetic, Electronic and Communication Engineering 7.12 (2013): 2510-2517. ', '[3] M. Cirrincione, M. Pucci, and G. Vitale, Growing Neural Gas (GNG)- Based Maximum Power Point Tracking for High-Performance Wind Generator With an Induction Machine. IEEE Transactions on Industry Applications 47.2 (2011): 861-872. ', '[4] M. Abdulkadir, AS. Samosir, S., and AHN. Yatim. Modeling and Simulation of a Solar Photovoltaic System, Its Dynamics and Transient Characteristics in LABVIEW." International Journal of Power Electronics and Drive System (IJPEDS) 3.2 (2013): 185-192. ', '[5] H. Bouzeria, C. Fetha, T. Bahi, I. Abadlia, Z. Layate, and S. Lekhchine. Fuzzy Logic Space Vector Direct Torque Control of PMSM for Photovoltaic Water Pumping System. Energy Procedia 74 (2015): 760- 771. ', '[6] YM. Chen, YC. Liu, SC. Hung, and CS. Cheng. Multi-Input Inverter for Grid-Connected Hybrid PV/Wind Power System. IEEE Transactions on Power Electronics 22.3 (2007): 742-750. ', '[7] S. Ganesh, J. Janani, and GB. Angel. A Maximum Power Point Tracker for PV Panels Using SEPIC Converter.International Journal of Electrical, Computer, Energetic, Electronic and Communication Engineering 8.2 (2014): 637-642. ', '[8] R. Vijayabalan, and S. Ravivarman. Z Source Inverter for Photovoltaic System with Fuzzy Logic Controller. International Journal of Power Electronics and Drive System (IJPEDS) 2.4 (2012): 371-379. ', '[9] A. Ramkumar, and SVS. Florence. "Analysis of Single Phase AC-DC SEPIC Converter using Closed Loop Techniques. International Journal of Advanced Research in Electrical, Electronics and Instrumentation Engineering 4.2 (2015): 193-201. ', '[10] G. Tadi, and P. Ramamurthyraju. Analysis of SEPIC for PV- Applications using PI Controller and Current Mode Control." International Journal for Scientific Research & Development 1.9 (2013): 175-180. ', '[11] J. Li, and H. Wang. A novel stand-alone PV generation system based on variable step size INC MPPT and SVPWM control." In Proceedings of the 2009 IEEE 6th International Power Electronics and Motion Control Conference, Wuhan, China, 17-20 May 2009. pp. 2155-2160. ', "[12] C. Wang. A Study of Membership Functions on Mamdani-Type Fuzzy Inference System for Industrial Decision-Making. Master's thesis, Lehigh University, Bethlehem, PA, USA, 2015. ", '[13] MA. Usta, Ö. Akyazi, and İH. Altaş. Design and performance of solar tracking system with fuzzy logic controller used different membership functions. In Proceedings of the 2011 7th International Conference on Electrical and Electronics Engineering (ELECO), Bursa, Turkey, 1-4 December 2011. pp. II-381-II-385.Mudi, R.K.; Pal, N.R. A robust self- tuning scheme for PI-and PD-type fuzzy controllers. IEEE Trans. Fuzzy Syst. 1999, 7, 2–16. ', '[14] RK. Mudi, and NR. Pal. A robust self-tuning scheme for PI- and PD- type fuzzy controllers. IEEE Transactions on Fuzzy Systems 7.1 (1999): 2-16. ', '[15] A. Shehata, H. Metered, and WAH. Oraby. Vibration control of active vehicle suspension system using fuzzy logic controller. In Vibration Engineering and Technology of Machinery, edited by W. A. Oraby, 389- 399. Springer, Berlin, Heidelberg, 2015.']
4	https://drive.google.com/file/d/1BcDiPKdRN7q55_ZqXncN-qXlaahO9xXi/view?usp=drive_link	2022-07-11	Numerical computing in engineering mathematics	['Firuz Kamalov', 'Ho-Hon Leung']	['Department of Electrical Engineering, Canadian University Dubai, Dubai, UAE', 'Department of Mathematical Sciences, United Arab Emirates University, Al Ain, UAE']	['engineering mathematics', 'numerical computing', 'education', 'Industry 4.0']	The rapid advances in technology over the last decade have significantly altered the nature of engineering knowledge and skills required in the modern industries. In response to the changing professional requirements, engineering institutions have updated their curriculum and pedagogical practices. However, most of the changes in the curriculum have been focused on the core engineering courses without much consideration for the auxiliary courses in mathematics and sciences. In this paper, we aim to propose a new, augmented mathematics curriculum aimed at meeting the requirements of the modern, technology-based engineering workplace. The proposed updates require minimal resources and can be seamlessly integrated into the existing curriculum.	introduction the industrial revolution has had a dramatic impact on the engineering the modern technologies such as artificial the internet of and advanced robotics have altered engineering systems and engineers are expected to be able to leverage these resources to produce their to meet the new professional engineering educational institutions have revised their the changes in the curricula include both updating the existing programs as well as introducing completely new given the rapid technological universities and colleges around the world are continuously adapting to the while a significant progress in modernizing the engineering curriculum has been there still remains room for catalyzed by the exponential increase in computational power and the modern industrial revolution has reshaped the skills and competencies required of the the changes in engineering curricula in response to industry have been modernizing the existing introduction of new and revising the pedagogical modernizing the existing programs involves introduction of new courses in the study plan related to emerging in existing courses can be updated with new fresh new programs in emerging technologies are also introduced by universities and many institutions now offer degrees in artificial intelligence and mechatronics which were not there years universities have revised their approaches to course and applied learning have become popular in the new engineering educational while significant effort has been made to revise the core engineering the auxiliary courses in mathematics and sciences received little the mathematics and sciences courses play a key role in the engineering given their the curriculum updates must also be extended to the auxiliary by implementing a comprehensive update of the engineering curriculum that includes both the core and auxiliary a more effective outcome can be the goal of this paper is to propose a modernized engineering mathematics curriculum in line with the broader efforts to update engineering education to adapt to industry the key feature of the new curriculum is the introduction numerical computing in the existing mathematics the latest industrial revolution has been driven largely by the dramatic increase in computational engineers must be to leverage the computing power in their since mathematics courses are usually taken at the beginning of the study it offers a natural avenue for introducing numerical computing to many problems in mathematics can be solved numerically making it natural to integrate numerical computing in mathematics by studying numerical computing in mathematics students will acquire the necessary theoretical and practical skills to apply in their specialized engineering this paper is structured as section provides an overview of the existing efforts to update the engineering curriculum in response to industry section discusses the current approaches to integrate scientific computing in mathematics in section we present our proposal for modernizing the mathematics curriculum to integrate numerical section concludes the paper with final engineering education and industry engineering departments in colleges and universities have made signiﬁcant changes in their curricula in response to the new environment created by the rapid advances in in the existing programs have been updated to include courses that target emerging completely new programs related to ai and mechatronics have also been adopted by innovations in the ﬁeld of engineering education continue to take place with new developments on the there exist several studies investigating the modern gineering curricula and evaluating their it is argued in that engineering educators must prepare their students to face three key the industrial and the authors ﬁnd that colleges and universities are responding to these challenges by emphasizing integration of theory and digital and online and the deﬁnition of professional in response to the needs of industry require interdisciplinary collaboration across several programs and interaction and integration of technologies plays a key role in this process terdisciplinary engineering education requires sound pedagogy and teaming experiences to encourage student in collaborative and interdisciplinary practice digital and online learning have become an important part of modern education including in the ﬁeld of information technologies play a vital role in delivering digital learning to colleges and universities have made signiﬁcant investments to improve their information and munication technology capacities in response to the needs of industry some sities have adopted the framework of education the new education framework consists of four main learning and students competencies are based on technological knowledge and skills for successful workplace while the learning methods are based on problem solving and in active and learning plays an important role in education other innovative approaches to learning such as based engineering education can help improve the learning process related to industry in addition to technological shifts must be taken into account in revising engineering the new generation of students has its unique worldview which needs to be considered by the in the new generation is signiﬁcantly affected by mobile devices and digital educational content must be tailored to the new student preferences to achieve effective learning outcomes innovative approaches such gamiﬁcation may help improve the learning process many universities have also introduced nontechnical updates to their engineering the most signiﬁcant nical update has been the introduction of entrepreneurship courses and experiences for a lot of attention has recently been given to equipping students with entrepreneurial students learn about entrepreneurship in their courses as well as through university university mathematics curriculum the mathematics curriculum changed very little in the current it remains a largely analytic where lutions are mainly obtained the current mathematics curriculum emphasizes theory over practical for when ﬁnding the extreme values of a approach is preferred over the gradient there are two key reasons for why analytical approaches are favored over numerical analytical solutions are reliable and an analytical solution is guaranteed to be mathematics courses are usually taught by pure mathematicians who have an inherent preference for analytical pure mathematics which is based on theorem proving is not amenable to numerical despite the popularity of analytical approaches to problem solving in there has been a growing push to grate computer algebra systems as part of the learning computer algebra systems such as matlab and mathematica are now routinely used in many mathematics the study by cretchley et found that engineering students were positive about the use of technology as a learning tool in mathematics the increased use of technology in class helped improve student focus and interest in student evaluations also indicated that they had a greater level of enjoyment towards the lectures due to the use of it is noteworthy that students chose not to rely too heavily on technology during the examinations despite the freedom to do the students found it extremely important to be competent with analytical mathematical skills as opposed to purely putational some revealed that they learn the subjects equally well without the help of scientiﬁc although the perception towards the use of computer is in general highly almost all students responded positively to matlab as an effective tool for computation and many used matlab for for they utilized it to check their handwritten mathematical steps in assignments and practice and others used it for exploration beyond the standard syllabus and the inﬂuence of computer technology on demic performance and learning experience has been tigated by several abdul majid et used matlab as an aid to teach calculus to engineering the software package was used for various course learning outcomes such as graphical display of mathematical identifying and predicting structural patterns in evaluating a series of complex indeﬁnite and cal approximations in applied the study showed a positive impact on academic performance in the ﬁnal the study concluded that the integration of scientiﬁc packages into engineering mathematics courses could be effective under certain other studies also found a positive impact from the use of scientiﬁc software packages on motivation in learning in a separate study by brake the authors investigated the use of matlab in engineering mathematics courses to increase student conﬁdence level and mathematical matlab was used to solve concrete engineering problems which require a deep understanding of underlying mathematical the study found generally positive student response to the use of software in their mathematics the results of the study must be considered carefully given the small sample size of the although the majority of the studies were based on the use of several other studies considered alternative mathematics software the study by kilicman et focused on the use of maple to help students understand both the theoretical and computational aspects of linear algebra for engineering in it was shown that the use of maple facilitates the understanding of computational pects of eigenvalues and it allows students more time to focus on the theoretical aspects and the underlying mathematical in a recent study by mezhennaya and pugachev the authors compared engineering perceptions regarding several mathematical mathematica and the study found that all the scientiﬁc packages considered can be used in under the condition that the policies for software usage are carefully the study found that many students lack experience on how to use the the students particularly struggled with matlab and mathematica ﬁnding them non user the study concluded that additional classes are required to prepare students to use software in their numerical computing in mathematics curriculum mathematics lies at the foundation of science and the importance of mathematics courses in engineering education cannot be these courses equip dents with the fundamental skills and knowledge to study the more specialized engineering student success in engineering studies depends directly on the mathematics and sciences given the signiﬁcance of the mathematics courses in the engineering it is paramount to ensure their currency with respect to the industry the technological advances over the last decade have created demand for more computationally proﬁcient to meet this numerical computing must become a core part of engineering mathematics courses offer a natural and convenient avenue for introducing numerical computing to engineering there are two main tors that make mathematics courses particularly amenable to numerical in many cases mathematical problems have numerical for ﬁnding the root of a polynomial or the minimum value of a function can be done it is both logical and appropriate to apply numerical computing to mathematical mathematics courses are usually taken at the beginning of the study students become acquainted with numerical computing at an early the computing and programming skills acquired in this manner will have a positive effect in the more downstream engineering the key idea for the proposed curriculum update is the addition of computing tutorials to mathematics in we propose adding weekly computing tutorials related to the main lecture for in the week in which students cover ﬁnding the extreme values of a there will be a computing tutorial where students learn and implement the gradient descent the suggested length of each tutorial is it is enough time to implement most of the numerical algorithms at the undergraduate at the same extra hour per week will not overburden the the exact details of numerical computing content is left for individual universities and depending on the syllabus and course learning the numerical puting labs will be different for each university and the general ideas will be broadly similar across different to illustrate the proposed numerical puting we will focus on the three main concept in and limits limit is a fundamental concept in students are usually taught to calculate limits using analytical although analytical approaches work there is no single universal rule for calculating on the other in most limits can be calculated numerically using essentially the same to suppose we want to calculate then we can loop for k to n and calculate as k approaches so in most approach the limit we can deduce the limit by observing the values of or determine that the limit does not exist if there is no pattern of the value of n can be chosen manually or using a stopping for the algorithm may continue to iterate until the difference between consecutive values of is below a certain the value of the limit can also be deduced automatically based on the values of using various another common limit problem is in this we can loop for k to n and calculate as k approaches so in most approach the limit then the limit can be determined based on the values of various extensions and tomizations of this basic approach can be for to avoid issues with periodic functions where ǫk are randomly can be other values than can also be used as long as the sequence approaches a degree of automization can be introduced using different derivative derivative is arguably the most important concept in there exist several rules such as the power the product the chain and others to ﬁnd the derivative of a function by manual differentiation may be cumbersome when dealing with complex on the other calculating the derivative at a point numerically is relatively to suppose that we want to calculate f recall that f lim h to calculate f numerically we use the same approach as with the in we can loop for k to n and calculate then the and by extension the can be deduced based on the calculated the accuracy of the approximation depends in large part on the value of one of the most important applications of the derivative is ﬁnding the extreme values of a this is done by ﬁrst ﬁnding the critical points of the function and then applying the second derivative ﬁnding the critical points is not always so numerical approaches can be used in such the most popular numerical approach for ﬁnding the extreme values is based on the gradient descent in gradient the optimal value of x is iteratively updated based on the in for k to the updated optimal value of x is given by xk where is the gradient and α is the step in the case of a the gradient equals simply to the derivative f the step size α can be either ﬁxed or while a large value of α accelerates the convergence at the it may hurt the convergence in the region near the optimal there exist several extensions of the basic gradient descent one such extension is gradient descent with mentum which uses the second derivative to anticipate the location of the next optimal point and thus accelerates the integrals integration is an important concept in engineering although there exist a number of rules for ﬁnding the it is signiﬁcantly more challenging than in many the indeﬁnite integral does not even numerical approaches are particularly useful for to illustrate the application of numerical pose that we want to calculate b a there exist several numerical methods for calculating the one simple method is based on the riemann the interval is divided into n equal subintervals with endpoints let δ be the length of each then the right riemann sum is deﬁned as δ the riemann sum provides an approximation of the b a dx lim δ n the riemann sums can be quickly calculated on a computer providing a yet effective approach to calculating integrals other popular integral approximation methods include the trapezoid rule and the additional considerations the above discussion about numerical methods for culating and integrals is easily extended to multivariate for to ﬁnd the partial derivative we can loop for k to n and calculate many problems related to sequences and series can similarly be solved using numerical in the convergence of a series can be deduced from its partial by calculating the partial sums on the computer and observing the we can intuit the nature of the vectorization is an important aspect of numerical since the modern computer chips are optimized for matrix it is more efﬁcient to employ vector in some algorithms based on can be converted into vector operations resulting in higher efﬁciency and for the riemann sum can be calculated with a single vector δ n δs where x is the vector of is a vectorized function and s is the vector tion which returns the sum of all the limit calculations can be vectorized and made more vectorization is also useful in where operations can be performed on a vector of the choice of the programming language for numerical computing requires careful there are several suitable candidates for this purpose including and based on our experience with different programming we recommend the use of python is currently the most popular programming language on the it has a simple and intuitive syntax making it easy to learn and python has libraries to ﬁt any purpose including an extensive collection of libraries related to numerical the basic python libraries related to computing are and more advanced packages such as are also available for optimization since python is a universal programming it can be used for almost any students who learn python in their mathematics courses can employ it in their other in numerical computing implemented in python can be connected to other conclusion although the classical approach to teaching mathematics is still relevant for certain student it is outdated for engineering modern engineering is increasingly liant on computing universities must equip the student with appropriate computing in mathematics courses must be revised to include numerical computing given the efﬁciency of ical computing provides a convenient approach to problem solving in engineering it can be integrated into the existing curriculum with little hassle and in this we proposed a framework for integrating numerical computing into the existing mathematics we demonstrated how numerical approaches can be used some of the most common problems encountered in the proposed framework can be customized by individual universities to ﬁt their special	['[1] Abdul Majid, M., Huneiti, Z., Balachandran, W., & Al-Naafa, M. A. (2012) A study of the effects of using MATLAB as a pedagogical tool for engineering mathematics students. 15th International Conference on Interactive Collaborative Learning (ICL), 10.1109/ICL.2012.6402183, Villach, Austria. ', '[2] Abdul Majid, M., Huneiti, Z. A., Balachandran, W., & Balarabe, Y. (2013) MATLAB as a teaching and learning tool for Mathematics: A literature review. International Journal of Arts and Sciences, 6(3), 23-44. ', '[3] Brake, M. L. (2007) MATLAB as a Tool to Increase the Math Self- Conﬁdence and the Math Ability of First-Year Engineering Technology Students. The Scholarship of Teaching and Learning at EMU: Vol. 1, Article 5. ', '[4] Chen, J., Kolmos, A., & Du, X. (2021). Forms of implementation and challenges of PBL in engineering education: a review of literature. European Journal of Engineering Education, 46(1), 90-115. ', '[5] Cretchley, P., Harman, C., Ellerton, N., & Fogarty, G. (2000) MATLAB in Early Undergraduate Mathematics: An investigation into the Effects of Scientiﬁc Software on Learning. Mathematics Education Research Journal, 12(3), 219-233. ', '[6] Hadgraft, R. G., & Kolmos, A. (2020). Emerging learning environments in engineering education. Australasian Journal of Engineering Educa- tion, 25(1), 3-16. ', '[7] Hernandez-de-Menendez, M., & Morales-Menendez, R. (2019). Tech- nological innovations and practices in engineering education: a review. International Journal on Interactive Design and Manufacturing (IJIDeM), 13(2), 713-728. ', '[8] Hern´andez-de-Men´endez, M., Guevara, A. V., Mart´ınez, J. C. T., Alc´antara, D. H., & Morales-Menendez, R. (2019). Active learning in engineering education. A review of fundamentals, best practices and ex- periences. International Journal on Interactive Design and Manufacturing (IJIDeM), 13(3), 909-922. ', '[9] Kamalov, F., Moussa, S., Zgheib, R., & Mashaal, O. (2020, December). Feature selection for intrusion detection systems. In 2020 13th Interna- tional Symposium on Computational Intelligence and Design (ISCID) (pp. 265-269). IEEE. ', '[10] Kamalov, F., Sulieman, H., & Santandreu Calonge, D. (2021). Machine learning based approach to exam cheating detection. Plos one, 16(8), e0254340. ', '[11] Kilicman, A., Hassan, M. A., & Said Husain, S. K. (2010) Teaching and Learning using Mathematics Software The New Challenge. Procedia Social and Behavioral Sciences, 8, 613-619. ', '[12] Lorenz, M., R¨ußmann, M., Strack, R., Lueth, K. L., & Bolle, M. (2015). Man and machine in industry 4.0: How will technology transform the industrial workforce through 2025. The Boston Consulting Group, 2. ', '[13] Maur´ıcio, R. D. A., Veado, L., Moreira, R. T., Figueiredo, E., & Costa, H. (2018). A systematic mapping study on game-related methods for software engineering education. Information and software technology, 95, 201-218. ', '[14] Mezhennaya, N. M. & Pugachev, O. V. (2019) On perception of computer algebra systems and microsoft excel by engineering students. Problems on Education in the 21st Century, 77(3), 379-395. ', '[15] Miranda, J., Navarrete, C., Noguez, J., Molina-Espinosa, J. M., Ram´ırez- Montoya, M. S., Navarro-Tuch, S. A., ... & Molina, A. (2021). The core components of education 4.0 in higher education: Three case studies in engineering education. Computers & Electrical Engineering, 93, 107278. ', '[16] Moore, K., & Frazier, R. S. (2017). Engineering education for generation Z. American Journal of Engineering Education (AJEE), 8(2), 111-126. ', '[17] Ortiz-Rojas, M., Chiluiza, K., & Valcke, M. (2019). Gamiﬁcation through leaderboards: An empirical study in engineering education. Computer Applications in Engineering Education, 27(4), 777-788. ', '[18] Puhak, R. I. (2011). Teaching applied Calculus utilizing MATLAB, Proceedings of the Twenty-Third Annual International Conference on Technology in Collegiate Mathematics, ISBN 0-321-68984-4, Copyright (C) 2012 by Pearson Education, Inc. ', '[19] Ramirez-Mendoza, R. A., Morales-Menendez, R., Iqbal, H., & Parra- Saldivar, R. (2018, April). Engineering Education 4.0:proposal for a new Curricula. In 2018 IEEE Global Engineering Education Conference (EDUCON) (pp. 1273-1282). IEEE. ', '[20] Salah, B., Abidi, M. H., Mian, S. H., Krid, M., Alkhalefah, H., & Abdo, A. (2019). Virtual reality-based engineering education to enhance manufacturing sustainability in industry 4.0. Sustainability, 11(5), 1477. ', '[21] Strayhorn, T. L. (2006). College in the information age: Gains associated with students use of technology. Journal of Interactive Online Learning, 5(2), 143-155. ', '[22] Thabtah, F., Kamalov, F., & Rajab, K. (2018). A new computational intelligence approach to detect autistic features for autism screening. International journal of medical informatics, 117, 112-124. ', '[23] Van den Beemt, A., MacLeod, M., Van der Veen, J., Van de Ven, A., van Baalen, S., Klaassen, R., & Boon, M. (2020). Interdisciplinary engineering education: A review of vision, teaching, and support. Journal of engineering education, 109(3), 508-555.']
5	https://drive.google.com/file/d/1r_XmqnEt8OrfQyeB-y49-PE3IeWZsRKc/view?usp=drive_link	2023-12-07	SMT 2.0: A Surrogate Modeling Toolbox with a focus on hierarchical and mixed variables Gaussian processes	['Paul Saves', 'Rémi Lafage', 'Nathalie Bartoli', 'Youssef Diouane', 'Jasper Bussemaker', 'Thierry Lefebvre', 'John T. Hwang', 'Joseph Morlier', 'Joaquim R.R.A. Martins']	['ONERA/DTIS, Université de Toulouse, Toulouse, France', 'ISAE-SUPAERO, Université de Toulouse, Toulouse, France', 'Polytechnique Montréal, Montreal, QC, Canada', 'German Aerospace Center (DLR), Institute of System Architectures in Aeronautics, Hamburg, Germany', 'University of California San Diego, Department of Mechanical and Aerospace Engineering, La Jolla, CA, USA', 'ICA, Université de Toulouse, ISAE–SUPAERO, INSA, CNRS, MINES ALBI, UPS, Toulouse, France', 'University of Michigan, Department of Aerospace Engineering, Ann Arbor, MI, USA']	['Surrogate modeling', 'Gaussian process', 'Kriging', 'Hierarchical problems', 'Hierarchical and mixed-categorical inputs', 'Meta variables']	The Surrogate Modeling Toolbox (SMT) is an open-source Python package that offers a collection of surrogate modeling methods, sampling techniques, and a set of sample problems. This paper presents SMT 2.0, a major new release of SMT that introduces significant upgrades and new features to the toolbox. This release adds the capability to handle mixed-variable surrogate models and hierarchical variables. These types of variables are becoming increasingly important in several surrogate modeling applications. SMT 2.0 also improves SMT by extending sampling methods, adding new surrogate models, and computing variance and kernel derivatives for Kriging. This release also includes new functions to handle noisy and use multi-fidelity data. To the best of our knowledge, SMT 2.0 is the first open-source surrogate library to propose surrogate models for hierarchical and mixed inputs. This open-source software is distributed under the New BSD license.	motivation and significance with the increasing complexity and accuracy of numerical it has become more challenging to run complex simulations and computer codes as a surrogate models have been recognized as a key tool for engineering tasks such as design space uncertainty and optimization in surrogate models are used to reduce the computational effort of these tasks by replacing expensive numerical simulations with approximations to build such a we start by evaluating the original expensive simulation at a set of points through a design of experiments the corresponding evaluations are used to build the surrogate model according to the chosen such as quadratic or least squares the surrogate modeling toolbox is an work that provides functions to efficiently build surrogate models corresponding author université de all authors contributed to this research and kriging models known as gaussian that take advantage of derivative information are one of smts key features numerical experiments have shown that smt achieved lower prediction error and computational cost than and uqlab for a fixed number of points smt has been applied to rocket engine optimization aircraft engine consumption eling numerical integration sensitivity sis robust finite elements methods planning for photovoltaic solar energy wind turbines design tion porous material optimization for a high pressure turbine vane chemical process design and many other in systems choices significantly fluence the final system and it is desirable to consider such choices in the early design phases architectural choices are parameterized with discrete design examples clude the selection of component received august received in revised form october accepted november advances in engineering software saves et table comparison of software packages for hierarchical and mixed kriging package botorch dakota dicekriging kergp lvgp parmoo spearmint smt reference this paper license mit epl gpl gpl gpl bsd gnu bsd language python c r r r python python python mixed gd kernel cr kernel hh kernel ehh kernel hierarchical and number of instantiated when design problems include both discrete variables and continuous they are said to have mixed when architectural choices lead to different sets of design we have hierarchical variables for consider ent aircraft propulsion architectures a conventional gas turbine would not require a variable to represent a choice in the electrical power while hybrid or pure electric propulsion would require such a the relationship between the choices and the sets of variables can be represented by a handling hierarchical and mixed variables requires specialized rogate modeling techniques to address these smt is offering researchers and practitioners a collection of tools to build surrogate models with mixed and hierarchical the main objective of this paper is to detail the new ments that have been added in this release compared to the original smt release there are two new major capabilities in smt the ability to build surrogate models involving mixed variables and the support for hierarchical variables within kriging to handle mixed variables in kriging existing libraries such as botorch dakota dicekriging lvgp parmoo and spearmint implement simple mixed models by using either continuous ation also known as encoding or a gower distance based correlation kernel kergp in ments more general kernels but there is no python toolbox that implements more general kernels to deal with mixed such as the homoscedastic hypersphere and exponential homoscedastic hypersphere such kernels require the tuning of a large number of hyperparameters but lead to more accurate kriging surrogates than simpler mixed kernels smt implements all these kernels and through a unified framework and to handle hierarchical no library in the literature can build peculiar surrogate models except smt which implements two kriging methods for these most softwares are compatible with a naïve strategy called the imputation method but this method lacks depth and depends on arbitrary this is why hutter and osborne proposed a first called which in turn was generalized by horn et with a new kernel called the kernel none of these kernels are available in any modeling thanks to the framework introduced in audet et our proposed kernels are sufficiently general so that all existing hierarchical kernels are included within section describes the two kernels implemented in smt that are referred as smt and smt in kernel is a novel hierarchical kernel introduced in this table outlines the main features of the modeling software that can handle hierarchical and mixed smt introduces other such as additional pling new surrogate new kriging kernels their kriging variance and an adaptive criterion for smt adds applications of bayesian optimization with hierarchical and mixed variables or noisy kriging that have been successfully applied to aircraft design data fusion and structural design the smt interface is more and offers an improved and more detailed documentation for users and smt is hosted and can be directly imported within python it is released under the new bsd license and runs on and windows operating regression tests are run automatically for each operating system whenever a change is committed to the in smt builds on the strengths of the original smt package while adding new on one the emphasis on derivatives training and output is maintained and improved in smt on the other this new release includes support for hierarchical and mixed variables kriging based for the sake of an notebook is available that gathers all the methods and results presented on this the remainder of the paper is organized as we troduce the organization and the main implemented features of the release in section we describe the kriging model with an example in section we describe and provide an example for a kriging model in section the bayesian optimization models and applications are described in section we describe the other relevant contributions in section and conclude in section smt an improved surrogate modeling toolbox from a software point of smt maintains and improves the modularity and generality of the original smt version in this we describe the software as section describes the legacy of smt section describes the organization of the section shows the new capabilities implemented in the smt background on smt former smt smt is an collaborative work originally developed by nasa and the university of both polytechnique montréal and the university of california san diego are also smt updates and tends the original smt repository capabilities among which the original publication focuses on different types of derivatives for surrogate models detailed advances in engineering software saves et table impact of using numba on training time of the hierarchical goldstein speedup is calculated excluding the jit compilation as this step is only needed once after smt training set without numba numba speedup jit overhead points s s s points s s s a python surrogate modeling framework with one of the original main motivations for smt was derivative in none of the existing packages for surrogate modeling such as in python sumo in matlab or gpml in matlab and octave focuses on three types of derivatives are prediction training and output smt also includes new models with derivatives such as kriging with partial least squares and regularized spline these developed derivatives were even used in a novel algorithm called kriging with partial least squares to use with adjoint for example software and automatic smt is nized along three main that implement a set of sampling techniques benchmarking functions and surrogate modeling techniques the toolbox is created using restructuredtext and a umentation generation package for with custom code snippets in the documentation pages are taken directly from actual tests in the source code and are automatically the output from these code snippets and tables of options are generated dynamically by custom sphinx this leads to documentation with minimal along with user developer documentation is also provided to explain how to contribute to this includes a list of api methods for the and problem that must be implemented to create a new surrogate modeling sampling or benchmarking when a developer submits a pull it is merged only after passing the automated tests and receiving approval from at least one the repository on is linked to continuous integration tests for linux and to a coverage test on and to a dependency version check for python with various parts of the source code have been accelerated using numba an compiler for python numba is applied to ventional python code using function thereby minimizing its impact on the development process and not requiring an additional build for a mixed kriging surrogate with training a speedup of up to is see table the jit compilation step only needs to be done once when installing or upgrading smt and adds an overhead of approximately s on a typical workstation in this all results are obtained using an cpu ghz core and gb of memory with a generation processor and a compute node of a peak power of organization of smt the main features of the repository smt are described in more sampling problems and surrogate models are kept from smt and two new sections models applications and interactive notebooks have been added to the architecture of the these sections are highlighted in blue and detailed on the new major features implemented in smt are highlighted in lavender whereas the legacy features that were already in present in the original publication for smt are in new features within smt the main objective of this new release is to enable kriging surrogate models for use with both hierarchical and mixed for each of these five described in section several improvements have been made between the original version and the smt hierarchical and mixed design a new design space definition class designspace has been added that implements hierarchical and mixed design variables can either be ous ordered or categorical the integer type resents a special case of the ordered specified by bounds rather than a list of possible the hierarchical ture of the design space can be defined using this function declares that a variable is a decreed variable that is activated when the associated meta variable takes one of a set of specified see section for the designspace class also implements mechanisms for sampling valid design vectors design vectors that adhere to the hierarchical structure of the design using any of the for recting and imputing design and for requesting which design variables are acting in a given design correction ensures that variables have valid values integers for discrete and imputation replaces variables by some default value for discrete between the bounds for continuous variables in smt smt implements three methods for the first one is a naïve called random that draws uniformly points along every the second sampling method is called full torial and draws a point for every cross combination of to have an design of the last one is the latin hypercube sampling that draws a point in every latin square parameterized by a certain for a new criterion to manage the randomness has been implemented and the sampling method was adapted for and mixed or hierarchical more details about the new sampling techniques are given in section smt implements two new engineering a mixed variant of a cantilever beam described in section and a hierarchical neural network described in section surrogate in order to keep up with several leases done from the original version developed new options for the already existing in compared to the original publication smt adds neural networks and marginal gaussian process models to the list of available more details about the new models are given in section several applications have been added to the toolbox to demonstrate the surrogate models the most relevant plication is efficient global optimization a bayesian tion algorithm ego optimizes problems with a chosen surrogate model and a chosen optimization criterion the usage of ego with hierarchical and mixed variables is described in section advances in engineering software saves et functionalities of smt the new major features implemented in smt compared to smt are highlighted with the lavender interactive these tutorials introduce and explain how to use the toolbox for different surrogate models and every tutorial is available both as a file and directly on google in a hierarchical and mixed variables dedicated notebook is available to reproduce the results presented on this in the section details the kriging based surrogate models for mixed and section presents our new kriging surrogate for hierarchical section details the ego tion and the other new relevant features aforementioned are described succinctly in section surrogate models with mixed variables in smt as mentioned in section design variables can be either of ous or discrete and a problem with both types is a discrete variables can be ordinal or a discrete variable is ordinal if there is an order relation within the set of possible an example of an ordinal design variable is the number of engines in an a possible set of values in this case could be a discrete variable is categorical if no order relation is known between the possible choices the variable can one example of a categorical variable is the color of a a possible example of a set of choices could be the possible choices are called the levels of the several methods have been proposed to address the recent increase interest in mixed kriging based models the main difference from a continuous kriging model is in the estimation of advances in engineering software saves et table categorical kernels implemented in smt name of smt gd 𝜃𝑖 smt cr 𝐿𝑖 smt ehh log 𝜖 smt hh 𝜙 the categorical correlation which is critical to determine the mean and variance as mentioned in section approaches such as cr continuous latent variables and gd use a method to estimate the correlation other methods estimate the correlation matrix by modeling the correlation entries directly such as hh and ehh the hh correlation kernel is of particular interest because it generalizes simpler kernels such as cr and gd in smt the correlation kernel is an option that can be set to either cr gd hh or ehh mixed gaussian processes the continuous and ordinal variables are both treated similarly in smt with a continuous where the ordinal values are converted to continuous through for categorical four models ehh and can be used in smt if specified by the this is why we developed a unified mathematical formulation that allows a unique implementation for any denote 𝑙 the number of categorical for a given 𝑖 the 𝑖th categorical variable is denoted 𝑐𝑖 and its number of levels is denoted the hyperparameter matrix peculiar to this variable 𝑐𝑖 is 𝛩𝑖 and the categorical parameters are defined as 𝜃𝑐𝑎𝑡 for two given inputs in the for the 𝑟th and 𝑠th let 𝑐𝑟 𝑖 and 𝑐𝑠 𝑖 be the associated categorical variables taking respectively the 𝓁𝑖 𝑟 and the 𝓁𝑖 𝑠 level on the categorical variable the categorical correlation kernel is defined by 𝑖 𝑖 𝑖 𝑖 𝑖 𝑖 𝑖 𝑖 where 𝜅 is either a positive definite kernel or identity and is a symmetric positive definite function such that the matrix is spd if 𝛩𝑖 is for an exponential table gives the parameterizations of 𝛷 and 𝜅 that correspond to and ehh the complexity of these different kernels depends on the number of hyperparameters that characterizes as defined by saves et for every categorical variable 𝑖 the matrix is lower triangular and built using a hypersphere decomposition from the symmetric matrix 𝛩𝑖 of the variable 𝜖 is a small positive constant and the variable 𝜃𝑖 denotes the only positive hyperparameter that is used for the gower distance another kriging based model that can use mixed variables is kriging with partial least squares kpls adapts kriging to high dimensional problems by using a reduced number of hyperparameters thanks to a projection into a smaller for a general not necessarily smt uses continuous relaxation to allow whatever model to handle mixed for we can use mixed variables with least squares or quadratic polynomial we now illustrate the abilities of the toolbox in terms of mixed modeling over an engineering test table results of the cantilever beam models table categorical kernel displacement error likelihood of smt gd smt cr smt ehh smt hh an engineering design a classic engineering problem commonly used for model validation is the beam bending problem this problem is illustrated on and consists of a cantilever beam in its linear range loaded at its free end with a force as in cheng et the young modulus is 𝐸 gpa and the chosen load is 𝐹 as in roustant et possible can be these sections consist of possible shapes that can be either thick or full as illustrated in to compare the mixed kriging models of smt we draw a point lhs as training set and the validation set is a grid of for the four implemented displacement error with a error number of hyperparameters and computational time for every model are shown in table for the continuous we use the square exponential more details are found in as the complex ehh and hh models lead to a lower displacement error and a higher likelihood but use more hyperparameters and increase the computational cost compared to gd and on this test the kernel ehh is easier to optimize than hh but in they are similar in terms of by default smt uses cr as it is known to be a good between complexity and performance surrogate models with hierarchical variables in smt to introduce the newly developed kriging model for hierarchical variables implemented in smt we present the general matical framework for hierarchical and mixed variables established by audet et in smt two variants of our new method are namely smt and smt in the smt is a novel correlation kernel introduced in this the hierarchical variables framework a problem structure is classified as hierarchical when the sets of active variables depend on architectural this occurs frequently in industrial design in hierarchical we can classify variables as meta known as or decreed known as conditionally as detailed in audet et neutral variables are the variables that are not affected by the hierarchy whereas the value assigned to meta variables determines which decreed variables are for a meta variable could be the number of if the number of engines the number of decreed bypass ratios that every engine should specify also advances in engineering software saves et cantilever beam problem figure variables classification as used in smt the wing aspect ratio being it is not affected by this problems involving hierarchical variables are generally dependant on discrete architectures and as such involve mixed in addition to their role meta or each variable also has a variable type amongst ordinal or for the sake of simplicity and because both continuous and ordinal variables are treated similarly we chose to regroup them as quantitative for the neutral variables 𝑥neu may be partitioned into different variable such that 𝑥neu 𝑥qnt where 𝑥cat neu represents the categorical variables and 𝑥qnt neu are the quantitative the variable classification scheme in smt is detailed in to explain the framework and the new kriging we illustrate the inputs variables of the model using a classical machine ing problem related to the hyperparameters optimization of a connected perceptron on in table we detail the input variables of the model related to the mlp problem the hyperparameters of the neural together with their types and to keep things clear and the chosen problem is a simplification of the original problem developed by audet et regarding the mlp problem of and following the fication scheme of we start by separating the input variables according to their in changing the number of hidden layers modifies the number of inputs of hidden is a meta the number of neurons in the hidden layer number 𝑘 is either included or for the of neurons in the would be excluded for an input that only has hidden of neurons hidden layer are decreed the and are not affected by the hierarchy they are neutral according to their the mlp input variables can be classified as the meta variable of hidden is an integer as is represented by the component 𝑥qnt the decreed variables of neurons hidden layer are integers as are represented by the component 𝑥qnt the and for the first two ery value between two categorical between three and integer between the and the are represented by the component 𝑥cat the and the are represented by the component 𝑥qnt to model hierarchical as proposed in we separate the input space as where advances in engineering software saves et the perceptron figure adapted from figure table a detailed description of the variables in the mlp mlp hyperparameters variable domain type role learning rate 𝑟 float neutral momentum 𝛼 float neutral activation function 𝑎 𝑇 enum neutral batch size 𝑏 ord neutral of hidden layers 𝑙 ord meta of neurons hidden layer 𝑘 𝑛𝑘 ord decreed for a given point 𝑥 one has 𝑥 where 𝑥neu 𝑥met and are defined as the components 𝑥neu gather all neutral variables that are not impacted by the meta variables but for in the mlp gathers the possible learning activation functions and batch from table the components 𝑥met gather the meta known as variables that determine the inclusion or exclusion of other for in the mlp represents the possible numbers of layers in the from table the components contain the decreed variables whose inclusion or exclusion is determined by the values of the meta components for in the mlp represents the number of neurons in the decreed from table and a kriging model for hierarchical variables in this a new method to build a kriging model with chical variables is introduced based on the framework the proposed methods are included in smt motivation and assuming that the decreed variables are hutter and osborne proposed several kernels for the hierarchical a classic called the imputation method leads to an efficient paradigm in practice that can be easily integrated into a more general framework as proposed by bussemaker et this kernel lacks depth and depends on arbitrary hutter and osborne also proposed a more general called and horn et generalized this kernel even more and proposed a new formulation called the kernel the drawbacks of these two methods are that they add some extra hyperparameters for every decreed dimension one extra hyperparameter for the and two eters for the and that they need a normalization according to the more pelamatti et developed a hierarchical kernel for bayesian our work is also more general thanks to the framework introduced earlier that considers formulation and is more flexible as we are allowing to be in the we describe our new method to build a correlation kernel for hierarchical in we introduce a new braic kernel called that behaves like the whilst correcting most of its in our kernel does not add any and the normalization is handled in a natural a new hierarchical correlation kernel for modeling we assume that the decreed space is let 𝑢 be an input point partitioned as advances in engineering software saves et 𝑢 𝑣 is another input such that 𝑣 the new kernel 𝑘 that we propose for hierarchical variables is given by where 𝑘met and are as 𝑘neu represents the neutral kernel that encompasses both ical and quantitative neutral 𝑘neu can be posed into two parts 𝑣cat 𝑣qnt the categorical denoted could be any symmetric positive definite mixed kernel section for the quantitative or a based kernel is the chosen quantitative kernel always depends on a given distance for the exponential kernel gives 𝑛 𝑖 𝑣qnt 𝑖 𝑘met is the meta variables related it is also separated into two 𝑣cat 𝑣qnt where the quantitative kernel is ordered and not continuous because meta variables take value in a finite is an spd kernel that models the correlations between the meta levels the possible and the decreed in what comes we detailed this towards an algebraic kernel kernels like the imputation kernel or the were first proposed in and the kernels such as or were proven to be to guarantee this spd the same hyperparameters are used to model the correlations between the meta levels and between the decreed variables for this the includes additional continuous hyperparameters which makes the training of the gp models more expensive and introduces more numerical stability in this we are proposing a new algebraic kernel as that enjoys similar properties as but without using additional continuous hyperparameters nor in the smt we included and a simpler version of that do not relies on additional our proposed kernel is given by 𝑘alg 𝑘alg 𝑘alg we could consider that there is only one meta variable whose levels correspond to every possible included let 𝐼sub denotes the components indices of possible the subspaces parameterized by the meta component 𝑢met are defined as 𝑙 it follows that the fully extended continuous decreed space writes as and 𝐼dec is the set of the associated let 𝐼𝑖𝑛𝑡𝑒𝑟 denotes the set of components related to the space containing the variables in both and since the decreed variables are one has 𝑘alg the construction of the quantitative kernel 𝑘qnt depends on a given distance denoted the kernel 𝑘alg met is an induced meta kernel that depends on the same distance 𝑑alg to preserve the spd property of 𝑘alg for every 𝑖 if 𝑖 𝐼𝑖𝑛𝑡𝑒𝑟 the new algebraic distance is given by where 𝜃𝑖 is a continuous if 𝑖 𝐼dec but 𝑖 𝐼𝑖𝑛𝑡𝑒𝑟 there should be a residual distance between the two different subspaces and to ensure the kernel spd to have a residual not depending on the decreed our model considers that there is a unit distance 𝐼dec 𝐼𝑖𝑛𝑡𝑒𝑟 the induced meta kernel 𝑘alg to preserve the spd property of 𝑘alg is defined 𝑘alg not only our kernel of uses less hyperparameters than the kernel we cut off its extra but it is also a more flexible kernel as it allows different kernels for meta and decreed another advantage of our kernel is that it is numerically more stable thanks to the new algebraic distance defined in our proposed distance also does not need any rescaling by the bounds to have values between and in what comes we will refer to the implementation of the kernels and by smt and smt we note also that the implementation of smt differs slightly from the original as we fixed some hyperparameters to in order to avoid adding extra perparameters and use the formulation of and rescaling of the illustration on the mlp problem in this we illustrate the hierarchical on the mlp for that we consider two design variables 𝑢 and 𝑣 such that 𝑢 and 𝑣 since the value of 𝑢met the number of hidden differs from one point to another for 𝑢 and for the associated variables have either or variables for the number of neurons in each layer and for and and for the point in our ters will have to be optimized where 𝑘 is given by these hyperparameters can be described using our proposed framework as for the neutral we have 𝑢neu and 𝑣neu for a categorical matrix kernel and a square exponential quantitative 𝑣cat 𝑣qnt exp exp exp the values and need to be is the correlation between and for the meta we have 𝑢met and 𝑣met for a square exponential quantitative 𝑣cat 𝑣qnt exp the value needs to be advances in engineering software saves et for the we have and which gives 𝑘alg 𝑘alg 𝑘alg the distance in for surrogate and in particular in smt the input data are with a unit normalization from to we would have we between and for a square exponential quantitative one gets 𝑘alg exp exp exp where the meta induced component is 𝑘alg exp because the decreed value in 𝑣 has nothing to be compared with in 𝑢 as in the values and need to be mized which complete the description of the we note that for the mlp models use hyperparameters whereas the would require hyperparameters without the meta kernel but with extra decreed hyperparameters and the would require for deep learning a more complex perceptron with up to hidden layers would require hyperparameters with smt models against for and for the next section illustrates the interest of our method to build a surrogate model for this neural network engineering a neural network using smt in this we apply our models to the hyperparameters mization of a mlp problem aforementioned of within smt an example illustrates this mlp for the sake of showing the kriging surrogate we implemented a dummy function with no significance to replace the real that would require training a whole neural network with big this function requires a number of variables that depends on the value of the meta the number of hidden to we have chosen only or hidden layers and we have decreed variables but deep neural networks could also be investigated as our model can tackle a few dozen a test case shows that our model smt interpolates the data checks that the data dimension is correct and also asserts that the inactive decreed variables have no influence over the in we illustrate the usage of kriging surrogates with hierarchical and mixed variables based on the implementation of smt for to compare the hierarchical models of smt and smt with the imputation method previously used on industrial application we draw a point lhs points by meta as a training set and the validation set is a lhs of for the the values are replaced by because the mean value is not an integer smt rounds to the floor for the three the precision with a square error rmse the likelihood and the computational time are shown in table for this we can see that smt kernel gives better performance than the imputation method or smt as all methods use the same number of they have similar time a direct application of table results on the neural network hierarchical method prediction error likelihood of smt smt our modeling method is bayesian optimization to perform quickly the hyperparameter optimization of a neural network bayesian optimization within smt efficient global optimization is a sequential bayesian timization algorithm designed to find the optimum of a function that may be expensive to evaluate ego starts by fitting a kriging model to an initial and then uses an acquisition function to select the next point to the most used acquisition function is the expected once a new point has been the kriging model is successive updates increase the model racy over this enrichment process repeats until a stopping criterion is because smt implements kriging models that handle mixed and hierarchical we can use ego to solve problems volving such design other bayesian optimization algorithms often adopt approaches based on solving subproblems with uous or this subproblem approach is less efficient and scales but it can only solve simple several bayesian optimization software packages can handle mixed or hierarchical variables with such a subproblem the ages include botorch smac trieste hebo openbox and dragonfly a mixed optimization problem compares the four ego methods implemented in smt smt smt smt ehh and smt the mixed test case that illustrates bayesian optimization is a toy test case detailed in pendix this test case has two one continuous and one categorical with to assess the performance of our we performed runs with different initial doe sampled by every doe consists of points and we chose a budget of infill plots the convergence curves for the four in the median is the solid and the first and third quantiles are plotted in dotted to visualize better the data the boxplots of the best solutions after evaluations are plotted in as the more a method is the better the both smt hh and smt ehh converged in around evaluations whereas smt cr and smt gd take around iterations as shown on the more complex the the closer the optimum is to the real value as shown on in we illustrate how to use ego with mixed variables based on the implementation of smt the illustrated problem is a mixed variant of the branin function note that a dedicated notebook is available to reproduce the results presented in this paper and the mixed integer notebook also includes an extra mechanical application with composite materials advances in engineering software saves et example of usage of hierarchical and mixed kriging advances in engineering software saves et optimization results for the toy function example of usage of mixed surrogates for bayesian advances in engineering software saves et optimization results for the hierarchical goldstein a hierarchical optimization problem the hierarchical test case considered in this paper to illustrate bayesian optimization is a modified goldstein function detailed in appendix the resulting optimization problem involves are are integer and are these variables consist in neutral dimensional variable and decreed depending on the meta variable different can be the optimization problem is given min 𝑥qnt 𝑥cat 𝑚 𝑥qnt 𝑥cat neu 𝑥qnt neu 𝑥cat 𝑚 𝑥qnt dec compared to the model choice of pelamatti et we chose to model and as neutral variables even if 𝑓 does not depend on when other modeling choices are for is a and not a categorical one we also keep the formulation of as a categorical variable but a better model would be to model it as a the resulting problem is described in appendix to assess the performance of our we performed runs with different initial doe sampled by every doe consists of 𝑛 points and we chose a budget of infill to compare our method with a we also tested the random search method thanks to the new method described in section and we also optimized the goldstein function using ego with a classic kriging model based on imputation method this method replaces the excluded variables by their mean or respectively for and plots the convergence curves for the four in the median is the solid line and the first and third quantiles are plotted in dotted to visualize better the ing data the boxplots of the best solutions are plotted in the results in show that the hierarchical kriging models of smt lead to better results than the imputation method or the random search both in terms of final objective value and variance over the runs and in term of convergence more smt and smt kriging model gave the best ego results and managed to converge correctly as shown in more the sampled does led to similar performance and from one the method smt managed to find the true this result has not been reproduced in other runs and is therefore not statistically the variance between the runs is of similar magnitude regardless of the considered other relevant contributions in smt the new release smt introduces several improvements sides kriging for hierarchical and mixed this section details the most important new recall from section that five are present in the surrogate applications and contributions to sampling the latin hypercube sampling is a stochastic sampling technique to generate sampling it is among the most popular sampling method in computer experiments thanks to its simplicity and projection properties with the lhs method uses the pydoe package of experiments for five criteria for the construction of lhs are implemented in the first four criteria are the same as in the last criterion is implemented by the authors of smt in smt a new lhs method was developed for the nested design of experiments to use with fidelity a new mathematical method was developed in smt to increase the size of a design of iments while maintaining the ese we proposed a sampling method for mixed and the aforementioned lhs method was applied to hierarchical variables in contributions to surrogate models new kernels and their derivatives for kriging surrogates are based on hyperparameters and on a correlation four tion kernels are now implemented in smt in these correlation functions are absolute exponential gaussian matern and matern in the implementation of gradient and hessian for each kernel makes it possible to calculate both the first and second derivatives of the gp likelihood with respect to the hyperparameters variance derivatives for to perform uncertainty quantification for system analysis it could be interesting to know more about the variance derivatives of a model for that purpose and also to pursue the original publication about derivatives smt extends the derivative support to kriging variances and advances in engineering software saves et noisy in engineering and in big data contexts with real surrogate models for noisy data are of significant in there is a growing need for techniques like noisy kriging and noisy kriging for data fusion for that smt has been designed to accommodate kriging and mfk to noisy data including the option to incorporate heteroscedastic noise the and to account for different noise levels for each data source kriging with partial least beside for the toolbox implements kriging with partial least squares and its extension kplsk the pls information is computed by projecting the data into a smaller space spanned by the principal by integrating this pls information into the kriging correlation the number of inputs can be scaled thereby reducing the number of hyperparameters the ing number of hyperparameters 𝑑𝑒 is indeed much smaller than the original problem dimension in smt we extended the kpls method for kriging and we also proposed an automatic criterion to choose automatically the reduced dimension 𝑑𝑒 based on r criterion this criterion has been applied to aircraft optimization with ego where the number 𝑑𝑒 in the for the model is automatically selected at every iteration special efforts have been made to accommodate kpls for and mixed integer data marginal gaussian smt implements marginal gaussian process surrogate models for high dimensional problems mgp are gaussian processes taking into account hyperparameters certainty defined as a density probability especially we pose that the function to model 𝑓 𝛺 where 𝛺 r𝑑 and 𝑑 is the number of design lies in a linear embedding such as 𝑥 𝐴 and with r and 𝑑𝑒 we must use a kernel whose each component of the transfer matrix 𝐴 is an thus we have 𝑑𝑒 𝑑 hyperparameters to note that 𝑑𝑒 is defined as in the code neural the new release smt ments neural network models neural networks are fully connected layer perceptrons whose training process was modified to account for gradient the model is trained to minimize not only the prediction error of the response but also the prediction error of the partial the chief benefit of gradient enhancement is better accuracy with fewer training note that genn applies to regression or but not classification since there is no gradient in that the implementation is fully vectorized and uses adam and for genn can be used to learn airfoil geometries from a this usage is documented in smt contributions to applications kriging trajectory and sampling a gp with high resolution is usually expensive due to the large dimension of the associated covariance several methods are proposed to draw samples of a gp on a given set of to sample a conditioned the classic method consists in using a cholesky decomposition of the conditioned covariance matrix of the process but some numerical computational errors can lead to non spd a more recent approach based on decomposition of the covariance kernel with the nyström method has been proposed in where the paths can be sampled by generating independent standard normal distributed the different methods are documented in the tutorial gaussian process trajectory sampling parallel bayesian due to the recent progress made in hardware it has been of high interest to perform parallel a parallel criterion called qei was developed to perform efficient global optimization the goal is to be able to run batch at each iteration of the multiple new sampling points are extracted from the known these new sampling points are then evaluated using a parallel computing five criteria are implemented in smt kriging believer kriging believer upper bound kriging believer lower bound kriging believer random bound and constant liar conclusion smt introduces significant upgrades to the surrogate modeling this new release adds support for hierarchical and mixed variables and improves the surrogate models with a particular focus on kriging smt is distributed through an license and is freely available we provide documentation that caters to both users and potential smt enables users and developers collaborating on the same project to have a common surrogate modeling tool that facilitates the exchange of methods and reproducibility of smt has been widely used in aerospace and mechanical modeling the toolbox is general and can be useful for anyone who needs to use or develop surrogate modeling regardless of the targeted smt is currently the only source toolbox that can build hierarchical and mixed surrogate declaration of competing interest the authors declare that they have no known competing cial interests or personal relationships that could have appeared to influence the work reported in this data availability data will be made available on results can be reproduced freely online at acknowledgments we want to thank all those who contribute to this carreira conde roux and this work is part of the activities of onera isae enac joint research we also acknowledge the partners nasa institut clément ader the university of polytechnique montréal and the university of california san the research presented in this paper has been performed in the framework of the agile project rative aircraft funded by the european union horizon research and innovation framework programme under grant agreement and in the colossus project system of systems exploration of aviation services and advances in engineering software saves et business funded by the european union horizon europe search and innovation framework programme under grant agreement we also are grateful to from polytechnique tréal for the hierarchical variables appendix toy test function this appendix gives the detail of the toy function of section we recall the optimization min 𝑥cat 𝑥qnt the toy function 𝑓 is defined as 𝑥 𝑥 𝑥 𝑥 𝑥 𝑥 𝑥 𝑥 appendix hierarchical goldstein test function this appendix gives the detail of the hierarchical goldstein problem of section we recall the optimization min 𝑥qnt 𝑥cat 𝑚 𝑥qnt 𝑥cat neu 𝑥qnt neu 𝑥cat 𝑚 𝑥qnt dec the hierarchical and mixed function 𝑓 is defined as a hierarchical function that depends on and 𝐺𝑜𝑙𝑑cont as describes in the the functions and are defined as mixed variants of 𝐺𝑜𝑙𝑑cont as such to finish the function 𝐺𝑜𝑙𝑑cont is given by cos appendix supplementary data more at supplementary material related to this article can be found online at	['[1] Mader CA, Martins JRRA, Alonso JJ, van der Weide E. ADjoint: An approach for the rapid development of discrete adjoint solvers. AIAA J 2008;46:863–73. ', '[2] Kennedy M, OHagan A. Bayesian calibration of computer models. J R Stat Soc Ser B Stat Methodol 2001;63:425–64. ', '[3] Hwang JT, Martins JRRA. A fast-prediction surrogate model for large datasets. Aerosp Sci Technol 2018;75:74–87. ', '[4] Martins JRRA, Ning A. Engineering design optimization. Cambridge University Press; 2021. ', '[5] Bouhlel MA, Hwang JT, Bartoli N, Lafage R, Morlier J, Martins JRA. A Python surrogate modeling framework with derivatives. Adv Eng Softw 2019;135:102662. ', '[6] Bouhlel MA, Martins J. Gradient-enhanced kriging for high-dimensional problems. Eng Comput 2019;35:157–73. ', '[7] Pedregosa F, Varoquaux G, Gramfort A, Thirion VMB, Grisel O, et al. Scikit-learn: Machine learning in Python. J Mach Learn Res 2011;12:2825–30.', '[8] Lataniotis C, Marelli S, Sudret B. Uqlab 2.0 and uqcloud: open-source vs. cloud-based uncertainty quantification. In: SIAM conference on uncertainty quantification. 2022. ', '[9] Faraci A, Beaurepaire P, Gayton N. Review on Python toolboxes for Kriging surrogate modelling. In: ESREL. 2022. ', '[10] Krügener M, Zapata Usandivaras J, Bauerheim M, Urbano A. Coaxial-injector surrogate modeling based on Reynolds-averaged Navier–Stokes simulations using deep learning. J Propuls Power 2022;38:783–98. ', '[11] Ming D, Williamson D, Guillas S. Deep Gaussian process emulation using stochastic imputation. Technometrics 2022;1–12. ', '[12] Eliáš J, Vořechovsk`y M, Sadílekv V. Periodic version of the minimax distance criterion for Monte Carlo integration. Adv Eng Softw 2020;149:102900. ', '[13] Drouet V, Balesdent M, Brevault L, Dubreuil S, Morio J. Multi-fidelity algo- rithm for the sensitivity analysis of multidisciplinary problems. J Mech Des 2023;145:1–22. ', '[14] Karban P, Pánek D, Orosz T, Petrášová I, Doležel I. FEM based robust design optimization with Agros and ¯Artap. Comput Math Appl 2021;81:618–33. ', '[15] Kudela J, Matousek R. Recent advances and applications of surrogate models for finite element method computations: a review. Soft Comput 2022;26:13709–33. ', '[16] Chen Y, Dababneh F, Zhang B, Kassaee S, Smith BT, Liu K, et al. Surrogate mod- eling for capacity planning of charging station equipped with photovoltaic panel and hydropneumatic energy storage. J Energy Res Technol 2020;142:050907. ', '[17] Jasa J, Bortolotti P, Zalkind D, Barter G. Effectively using multifidelity optimization for wind turbine design. Wind Energy Sci 2022;7:991–1006. ', '[18] Wang W, Tao G, Ke D, Luo J, Cui J. Transpiration cooling of high pres- sure turbine vane with optimized porosity distribution. Appl Therm Eng 2023;223:119831. ', '[19] Savage T, Almeida-Trasvina HF, del Río-Chanona EA, Smith R, Zhang D. An adaptive data-driven modelling and optimization framework for complex chemical process design. Comput Aided Chem Eng 2020;48:73–8. ', '[20] Chan A, Pires AF, Polacsek T. Trying to elicit and assign goals to the right actors. In: Conceptual modeling: 41st international conference. 2022. ', '[21] Hutter F, Osborne MA. A kernel for hierarchical parameter spaces. 2013, arXiv. ', '[22] Bussemaker JH, Ciampa PD, Nagel B. System architecture design space explo- ration: An approach to modeling and optimization. In: AIAA aviation 2020 forum. 2020. ', '[23] Fouda MEA, Adler EJ, Bussemaker J, Martins JRRA, Kurtulus DF, Boggero L, et al. Automated hybrid propulsion model construction for conceptual aircraft design and optimization. In: 33rd congress of the international council of the aeronautical sciences. 2022. ', '[24] Bussemaker JH, Bartoli N, Lefebvre T, Ciampa PD, Nagel B. Effectiveness of surrogate-based optimization algorithms for system architecture optimization. In: AIAA aviation 2021 forum. 2021. ', '[25] Balandat M, Karrer B, Jiang D, Daulton S, Letham B, Wilson A, et al. BoTorch: A framework for efficient Monte-Carlo Bayesian optimization. Adv Neural Inf Process Syst 2020;33:21524–38. ', '[26] Adams B, Bohnhoff W, Dalbey K, Ebeida M, Eddy J, Eldred M, et al. Dakota, a multilevel parallel object-oriented framework for design optimization, pa- rameter estimation, uncertainty quantification, and sensitivity analysis: Version 6.13 users manual. Technical report, Albuquerque, NM (United States: Sandia National Lab.(SNL-NM); 2020. ', '[27] Roustant O, Ginsbourger D, Deville Y. DiceKriging, DiceOptim: Two R packages for the analysis of computer experiments by Kriging-based metamodeling and optimization. J Stat Softw 2012;51:1–55. ', '[28] Zhang Y, Tao S, Chen W, Apley D. A latent variable approach to Gaus- sian process modeling with qualitative and quantitative factors. Technometrics 2020;62:291–302. ', '[29] Chang TH, Wild SM. ParMOO: A Python library for parallel multiobjective simulation optimization. J Open Source Softw 2023;8:4468. ', '[30] Garrido-Merchán EC, Hernández-Lobato D. Dealing with categorical and integer-valued variables in Bayesian optimization with Gaussian processes. Neurocomputing 2020;380:20–35. ', '[31] Halstrup M. Black-box optimization of mixed discrete-continuous optimization problems (Ph.D. thesis), TU Dortmund; 2016. ', '[32] Roustant O, Padonou E, Deville Y, Clément A, Perrin G, Giorla J, et al. Group kernels for gaussian process metamodels with categorical inputs. SIAM J Uncertain Quant 2020;8:775–806. ', '[33] Zhou Q, Qian PZG, Zhou S. A simple approach to emulation for computer models with qualitative and quantitative factors. Technometrics 2011;53:266–73. ', '[34] Saves P, Diouane Y, Bartoli N, Lefebvre T, Morlier J. A mixed-categorical correlation kernel for Gaussian process. Neurocomputing 2023;550:126472. ', '[35] Pelamatti J, Brevault L, Balesdent M, Talbi E-G, Guerin Y. Efficient global optimization of constrained mixed variable problems. J Global Optim 2019;73:583–613. ', '[36] Horn D, Stork J, ler N-JS, Zaefferer M. Surrogates for hierarchical search spaces: The Wedge-Kernel and an automated analysis. In: Proceedings of the genetic and evolutionary computation conference. 2019. ', '[37] Hung Y, Joseph VR, Melkote SN. Design and analysis of computer experiments with branching and nested factors. Technometrics 2009;51:354–65. ', '[38] Audet C, Hallé-Hannan E, Le Digabel S. A general mathematical framework for constrained mixed-variable blackbox optimization problems with meta and categorical variables. Oper Res Forum 2023;4:1–37. ', '[39] Saves P, Nguyen Van E, Bartoli N, Diouane Y, Lefebvre T, David C, Defoort S, Morlier J. Bayesian optimization for mixed variables using an adaptive dimension reduction process: applications to aircraft design. In: AIAA scitech 2022. 2022. ', '[40] Conde Arenzana R, López-Lopera A, Mouton S, Bartoli N, Lefebvre T. Multi- fidelity Gaussian process model for CFD and wind tunnel data fusion. In: ECCOMAS aerobest. 2021. ', '[41] Rufato RC, Diouane Y, Henry J, Ahlfeld R, Morlier J. A mixed-categorical data-driven approach for prediction and optimization of hybrid discontinuous composites performance. In: AIAA aviation 2022 forum. 2022. ', '[42] Gorissen D, Crombecq K, Couckuyt I, Dhaene T, Demeester P. A surrogate modeling and adaptive sampling toolbox for computer based design. J Mach Learn Res 2010;11:2051–5. ', '[43] Williams CK, Rasmussen CE. Gaussian processes for machine learning. MA: MIT press Cambridge; 2006. ', '[44] Bouhlel MA, Bartoli N, Regis R, Otsmane A, Morlier J. Efficient Global Opti- mization for high-dimensional constrained problems by using the Kriging models combined with the Partial Least Squares method. Eng Optim 2018;50:2038–53. ', '[45] Bouhlel MA, He S, Martins J. Scalable gradient-enhanced artificial neural networks for airfoil shape design in the subsonic and transonic regimes. Struct Multidiscip Optim 2020;61:1363–76. ', '[46] Kwan LS, Pitrou A, Seibert S. Numba: A LLVM-based python JIT compiler. In: Proceedings of the second workshop on the LLVM compiler infrastructure in HPC. 2015. ', '[47] Zaefferer M, Horn D. A first analysis of kernels for Kriging-based optimization in hierarchical search spaces. 2018, arXiv. ', '[48] Jin R, Chen W, Sudjianto A. An efficient algorithm for constructing optimal design of computer experiments. J Statist Plann Inference 2005;2:545–54. ', '[49] Garnett R, Osborne M, Hennig P. Active learning of linear embeddings for Gaussian processes. In: Uncertainty in artificial intelligence - Proceedings of the 30th conference. 2013. ', '[50] Jones D. A taxonomy of global optimization methods based on response surfaces. J Global Optim 2001;21:345–83. ', '[51] Lafage R. egobox, a Rust toolbox for efficient global optimization. J Open Source Softw 2022;7:4737. ', '[52] Jones DR, Schonlau M, Welch WJ. Efficient global optimization of expensive black-box functions. J Global Optim 1998;13:455–92. ', '[53] Deng X, Lin CD, Liu K, Rowe RK. Additive Gaussian process for computer models with qualitative and quantitative factors. Technometrics 2017;59:283–92. ', '[54] Cuesta-Ramirez J, Le Riche R, Roustant O, Perrin G, Durantin C, Gliere A. A comparison of mixed-variables Bayesian optimization approaches. Adv Model Simul Eng Sci 2021;9:1–29. ', '[55] Rebonato R, Jaeckel P. The most general methodology to create a valid correlation matrix for risk management and option pricing purposes. J Risk 2001;2:17–27. ', '[56] Rapisarda F, Brigo D, Mercurio F. Parameterizing correlations: a geometric interpretation. IMA J Manag Math 2007;18:55–73. ', '[57] Bouhlel MA, Bartoli N, Regis R, Otsmane A, Morlier J. An improved approach for estimating the hyperparameters of the Kriging model for high- dimensional problems through the Partial Least Squares method. Math Probl Eng 2016;2016:6723410. ', '[58] Cheng GH, Younis A, Hajikolaei KH, Wang GG. Trust region based mode pursuing sampling method for global optimization of high dimensional design problems. J Mech Des 2015;137:021407. ', '[59] Karlsson R, Bliek L, Verwer S, de Weerdt M. Continuous surrogate-based optimization algorithms are well-suited for expensive discrete problems. In: Artificial intelligence and machine learning. 2021. ', '[60] Pelamatti J, Brevault L, Balesdent M, Talbi E-G, Guerin Y. Bayesian optimization of variable-size design space problems. Opt Eng 2021;22:387–447. ', '[61] Hebbal A, Brevault L, Balesdent M, Talbi E-G, Melab N. Bayesian optimization using deep Gaussian processes with applications to aerospace system design. Opt Eng 2021;22:321–61. ', '[62] Wildberger N. A rational approach to trigonometry. Math Horiz 2007;15:16–20. ', '[63] Cho H, Kim Y, Lee E, Choi D, Lee Y, Rhee W. Basic enhancement strategies when using bayesian optimization for hyperparameter tuning of deep neural networks. IEEE Access 2020;8:52588–608. ', '[64] Zuniga MM, Sinoquet D. Global optimization for mixed categorical-continuous variables based on Gaussian process models with a randomized categorical space exploration step. INFOR Inf Syst Oper Res 2020;58:310–41. ', '[65] Lindauer M, Eggensperger K, Feurer M, AB, Deng D, Benjamins C, et al. SMAC3: A versatile Bayesian optimization package for hyperparameter optimization. J Mach Learn Res 2022;23:1–9. ', '[66] Picheny V, Berkeley J, Moss H, Stojic H, Granta U, Ober S, et al. Trieste: Efficiently exploring the depths of black-box functions with TensorFlow. 2023, arXiv. ', '[67] Cowen-Rivers AI, Ly W, Wang Z, Tutunov R, Jianye H, Wang J, et al. HEBO: Heteroscedastic evolutionary Bayesian optimisation. 2020, arXiv. ', '[68] Jiang H, Shen Y, Li Y, Zhang W, Zhang C, Cui B. OpenBox: A Python toolkit for generalized black-box optimization. 2023, arXiv.', '[69] Kandasamy K, Vysyaraju KR, Neiswanger W, Paria B, Collins C, Schneider J, et al. Tuning hyperparameters without grad students: Scalable and robust bayesian optimisation with dragonfly. J Mach Learn Res 2020;21:3098–124. ', '[70] Roy S, Crossley WA, Stanford BK, Moore KT, Gray JS. A mixed integer efficient global optimization algorithm with multiple infill strategy - Applied to a wing topology optimization problem. In: AIAA scitech 2019 forum. 2019. ', '[71] Müller J, Shoemaker CA, Piché R. SO-MI: A surrogate model algorithm for computationally expensive nonlinear mixed-integer black-box global optimization problems. Comput Oper Res 2013;40:1383–400. ', '[72] Tran T, Sinoquet D, Da Veiga S, Mongeau M. Derivative-free mixed binary necklace optimization for cyclic-symmetry optimal design problems. Opt Eng 2021. ', '[73] Meliani M, Bartoli N, Lefebvre T, Bouhlel MA, Martins JRRA, Morlier J. Multi- fidelity efficient global optimization: Methodology and application to airfoil shape design. In: AIAA aviation 2019 forum. 2019. ', '[74] Lee H. Gaussian processes. Springer Berlin Heidelberg; 2011, p. 575–7. ', '[75] López-Lopera AF, Idier D, Rohmer J, Bachoc F. Multioutput Gaussian processes with functional data: A study on coastal flood hazard assessment. Reliab Eng Syst Saf 2022;218:108139. ', '[76] Berthelin G, Dubreuil S, Salaün M, Bartoli N, Gogu C. Disciplinary proper orthogonal decomposition and interpolation for the resolution of parameterized multidisciplinary analysis. Internat J Numer Methods Engrg 2022;123:3594–626. ', '[77] Cardoso I, Dubreuil S, Bartoli N, Gogu C, Salaün M, Lafage R. Disciplinary surrogates for gradient-based optimization of multidisciplinary systems. In: ECCOMAS Aerobest. 2023. ', '[78] Platt J, Penny S, Smith T, Chen T, Abarbanel H. A systematic exploration of reservoir computing for forecasting complex spatiotemporal dynamics. Neural Netw 2022;153:530–52. ', '[79] Charayron R, Lefebvre T, Bartoli N, Morlier J. Multi-fidelity Bayesian optimiza- tion strategy applied to overall drone design. In: AIAA scitech 2023 forum. 2023. ', '[80] Charayron R, Lefebvre T, Bartoli N, Morlier J. Towards a multi-fidelity and multi-objective Bayesian optimization efficient algorithm. Aerosp Sci Technol 2023;142:108673. ', '[81] Wold H. Soft modelling by latent variables: The non-linear iterative partial least squares (NIPALS) approach. J Appl Probab 1975;12:117–42. ', '[82] Priem R, Diouane Y, Bartoli N, Dubreuil S, Saves P. High-dimensional efficient global optimization using both random and supervised embeddings. In: AIAA aviation 2023 forum. 2023. ', '[83] Betz W, Papaioannou I, Straub D. Numerical methods for the discretization of random fields by means of the Karhunen–Loève expansion. Comput Methods Appl Mech Engrg 2014;271:109–29. ', '[84] Menz M, Dubreuil S, Morio J, Gogu C, Bartoli N, Chiron M. Variance based sen- sitivity analysis for Monte Carlo and importance sampling reliability assessment with Gaussian processes. Struct Saf 2021;93:102116. ', '[85] Ginsbourger D, Le Riche R, Carraro L. Kriging is well-suited to parallelize optimization. Springer Berlin Heidelberg; 2010, p. 131–62. ', '[86] Roux E, Tillier Y, Kraria S, Bouchard P-O. An efficient parallel global opti- mization strategy based on Kriging properties suitable for material parameters identification. Arch Mech Eng 2020;67.']
6	https://drive.google.com/file/d/1WSqn2vndHdBdE_7qOwOoxcRB6deMhayG/view?usp=drive_link	2023-12-12	Improved stochastic subset optimization method for structural design optimization	['Mohd Aman Khalid', 'Sahil Bansal']	['Department of Civil Engineering, Indian Institute of Technology Delhi, New Delhi 110016, India']	['Stochastic subset optimization', 'Voronoi tessellation', 'Stochastic simulation', 'Stochastic optimization', 'Optimization under uncertainty']	The Stochastic Subset Optimization (SSO) algorithm was proposed for optimal reliability problems that minimizes the probability of system failure over the admissible space for the design parameters. It is based on the simulation of samples of the design parameters from an auxiliary Probability Density Function (PDF) and exploiting the information contained in these samples to identify subregions for the optimal design parameters within the original design space. This paper presents an improved version of SSO, named iSSO to overcome the shortcomings in the SSO. In the improved version, the Voronoi tessellation is implemented to partition the design space into non-overlapping subregions using the pool of samples distributed according to the auxiliary PDF. A double-sort approach is then used to identify the subregions for the optimal design. The iSSO is presented as a generalized design optimization approach primarily tailored for the stochastic structural systems but also adaptable to deterministic systems. Several optimization problems are considered to illustrate the effectiveness and efficiency of the proposed iSSO.	introduction structural optimization may be defined as the rational establishment of an economical structural design with the available resources while satisfying specific performance in general the economy may be characterized by minimum minimum maximum or even minimum probability of structural optimization can be categorized into deterministic and stochastic optimization the classical statement of unconstraint deterministic optimization is mathematically expressed minimize φφ φ φrnφ is a set of deterministic adjustable parameters that define the structural referred to herein as design rnφr is the objective function to be and φ denotes the bounded admissible design the deterministic constraints can be considered by the appropriate definition of the admissible design space φ for deterministic design parameters as mentioned in in the deterministic structural optimization the uncertainties in parameters are and fixed values are assumed for all the there are numerous optimizations approaches available in the but its worth noting that no optimization approach is ideal for all sorts of problems the choice of optimization method is often determined by the specific characteristics of the such as its and the nature of the objective as a there is always a scope for new approaches to be developed or the adaptation of existing methods to better suit specific problem a detailed discussion of deterministic optimization approaches can be found in the literature in any practical several such as structural geometric operation are either not known at the design stage or are subjected to random fluctuations that give rise to performance variability and affect the performance of a system these parameters are characterized as uncertain deterministic structural optimization discards the impact of uncertainty and can result in improper it is desirable to account for the uncertainty in the parameters during optimization by using the rational methods of probabilistic structural analysis such structural optimization that accounts for uncertainties is called stochastic optimization although stochastic optimization refers to any method that employs randomness within some in this we will only consider settings where corresponding contents lists available at sciencedirect advances in engineering software journal received june received in revised form october accepted november advances in engineering software the objective function is stochastic optimization or optimal design under uncertainty has been widely applied in many practical engineering including civil engineering structures composite structures and vehicles consider an engineering system that involves deterministic design parameters and uncertain variables θ following a joint pdf where θ denotes the parameter space of the tain the classical statement of stochastic optimization is mathematically expressed minimize is the structural performance and denotes expectation with respect to the pdf for note that the objective function in the optimization problem in is the expectation which is a deterministic worth mentioning that stochastic optimization may also involve other stochastic measures such as variance or quantile these stochastic measures can rarely be evaluated several methods have been proposed for solving stochastic optimization these ized methods for sample average stochastic stochastic subset and proaches based on the use of taylor series expansion response and metamodels specific to structural there are two broad categories of problems involving design optimization under uncertainty design optimization and robust design optimization the objective of rbdo is to find an optimal solution that minimizes some objective function under observance of probabilistic constraints instead of conventional deterministic constraints on the other rdo aims to find an optimal solution that is sitive less to input it improves the design quality by minimizing performance variation without eliminating certainty taflanidis and beck introduced a novel algorithm for optimal reliability the sso involves formulating an augmented problem where the design parameters are artificially considered uncertain and defining an auxiliary pdf that includes the structural performance function and the pdf of the uncertain sso involves generating a pool of samples distributed according to this auxiliary pdf and identifying a subregion in the original design on improves the value of the objective by repeating this procedure several it is possible to determine at each step a smaller subregion in the design which in turn proves the value of the objective this subregion will be sufficiently small to directly identify the optimal solution or provide sufficient information to launch another optimization such as the sample average approximation or stochastic the implementation of the sso method closely resembles the subset simulation algorithm for reliability since sso is based on it can deal with linear or nonlinear problems at least an unbounded number of design the numerical effort for solving a given optimization problem is dent of the number of uncertain and it grows linearly with the number of design since the introduction of several extensions of sso have been an extension of sso termed which adopts kernel density estimation to approximate the objective is presented in in efficient integration of the moving least squares approximation within sso is introduced to reduce the tational effort in in an augmented formulation is presented for the rdo of structures using sso or its variants have also been applied to solve structural optimization sso has been used for reliability optimization and sensitivity analysis in system design in a framework for rdo of tuned mass dampers by sso is cussed in even though sso has proved to be efficient for meeting various challenging optimization it has two the effectiveness of sso is dependent on the correct selection of the geometrical shape of the admissible it is pertinent to mention that choosing a geometrical shape that effectively investigates the sensitivity of the objective function to each design variable is the such as and are suggested in the literature for the admissible as shown later via the illustrative these shapes fail to include the optimal solution in cases with complex design spaces or problems with multiple optimal and identifying the optimal subset that tains the smallest volume density involves a optimization problem which is quite in this an improved version of sso is developed to overcome the shortcomings of the original this new version of the as mentioned is named isso voronoi tion is implemented to partition the design space into subregions set of voronoi using the pool of samples uted according to the auxiliary the admissible set set of all admissible is then defined as a set containing all subsets of the set of voronoi this approach is able to capture the regions with lower objective function values even if they are disjointed or when the design space is the details of the voronoi tessellation are presented in appendix a algorithm is then implemented to identify the optimal subset containing the smallest volume in the next the original sso is section presents the general theoretical and computational framework for the isso section considers several optimization problems to illustrate the effectiveness and efficiency of the proposed isso original stochastic subset optimization in say at the i the design space is represented by a subset where following the augmented formulation concept initially discussed in for the design parameters are artificially considered uncertain variables with a prescribed pdf over the design space for is where is the volume of in this setting of the augmented stochastic design the auxiliary pdf is defined π θ θ θ note that if it must be suitably transformed to ensure that one way to do this is to define since that the two expected values differ only by a and the optimization of the expected value of is in terms of the optimal design to optimization for the expected value for in the above the denominator is a normalizing constant given φ θ θ although this expected value is not explicitly it can be determined using any stochastic simulation the objective function in this context of the auxiliary pdf is expressed π φ p φ the marginal is given π φ in since is a normalizing minimization of khalid and bansal advances in engineering software is equivalent to minimization of which is equal j φ π φ p φ the estimation of the marginal in is necessary to mize analytical approximations of based on kernel density approaches or the maximum entropy method might be arduous in case of complex such as when design parameters nφ are or the sensitivity for some design parameters is complex in the sso such approximation of is in samples distributed as are and the information in these samples is exploited to identify a smaller subset of the design space with a high likelihood of containing the optimal design samples distributed as are obtained using any appropriate stochastic sampling such as markov chain monte carlo sampling the φ component of these samples then responds to samples from the marginal distribution the sensitivity of objective function to φ is determined by evaluating the average value equivalently volume of over any subset i in which is denoted by and defined vi i j dφ vi i π p dφ vi i π dφ vi is the volume of subset based on the samples distributed according to belonging to an estimate of is provided is the number of samples distributed as belonging to and ni denotes the number of samples from belonging to the i say ni a smaller value of ρ sults in a faster decrease in the size of the identified subsets but with poorer the use of ρ equal to is suggested in the literature a deterministic based on the estimate of is next performed to identify the subset i ρ where ρ is a set of admissible subsets in that contains the smallest volume density that argmin arg min ρ ni vi ρ ρ ni the effectiveness of sso is dependent on the correct selection of the geometrical shape and size of the admissible choosing a geometrical shape that effectively investigates the sensitivity of the objective function to each design variable is the optimization in determines the subset with the smallest average value of equivalently within the admissible set ρ is a subset of the design space with a high likelihood of containing the optimal design the above steps are repeated until the stopping criterion is this sso adaptively converges to a relatively small subregion within the original design the mentation of sso is demonstrated in the reader may refer to the original publication for a detailed explanation of sso expresses the average relative sensitivity of to a low value of indicates that is more sensitive to and vice a high value of close to corresponds to a sample density in design space that approximates a uniform distribution and suggests that the identified subset has a low likelihood of containing the sso is stopped when exceeds a threshold a threshold value of has been found to give satisfactory results proposed approach in the proposed the voronoi tessellation is implemented to partition the design space into subregions set of voronoi using the pool of samples distributed according to this auxiliary voronoi tessellation involves partitioning a space into convex called voronoi such that each cell contains exactly one called a every sample in a given polygon is closer to its generating sample compared to any in the proposed the admissible set set of all admissible is defined as a set containing all subsets of the set of voronoi an alternative approach to identify the optimal subset without performing any deterministic optimization is also the general theoretical and computational framework for the isso algorithm is presented in the following and the illustration of the original sso khalid and bansal advances in engineering software algorithm is demonstrated in partitioning of design space in the proposed at the i say is the number of samples distributed as belonging to the design space let nv γ be the number of unique if sampling techniques such as accept importance are then γ and each sample in the design space will be if mcmc sampling techniques are the resulting samples will be that is γ and we will have repeated assume that the design space is divided into k k voronoi cells using nv unique and say the voronoi cell k contains k repeated an estimate of is provided π k k φ k k is the volume of the kth voronoi dφ similar to the original the sensitivity of the objective function j to φ is determined by evaluating the average value of over any subspace i of the design space subset i is any subset of nvvoronoi cells cells may be since the design space is partitioned into nv subspaces or voronoi the number of admissible subsets is given by based on the estimate provided in an estimate of is provided vi i π dφ vi i vi ni vi is the volume of the subset i and ni is the number of samples belonging to let i where s is the number of onoi cells defining the subset note that the parentheses are used in the subscript to differentiate between the voronoi cell number defined in the previous section from the voronoi cell index describing the subset an estimate of is then provided identification of an optimal subset a deterministic optimization needs to be performed to identify a subset i that contains the smallest volume density in the case of unique since the solution to the minimization problem in is a set of voronoi cells with the largest for the case with repeated the optimization can be performed using methods appropriate for optimization such as bundle gradient sampling in this we propose an alternative approach to identify the optimal subset without performing any deterministic a algorithm is which involves sorting the voronoi cells in ascending order of the sample counts and then in groups of cells with the same sample count in descending order of cell the top cells containing are selected as an approximate optimal solution from the sorted one may argue that the optimal subset can be obtained by first sorting the voronoi cells in ascending order of the cell defined as k k and then by selecting the top cells containing samples from the sorted this argument is erroneous because the objective is to minimize and not the effectiveness of the proposed algorithm is demonstrated in section with the help of simulation of conditional samples at the i samples distributed as are available from the previous using these samples as additional are the proposed method to simulate additional samples involves two randomly selecting a voronoi cell within the subset based on the estimate and applying the algorithm within the selected voronoi a voronoi cell is selected according to the following weights in the first k k k k k k illustration of the proposed isso khalid and bansal advances in engineering software to simulate a new sample within a selected voronoi the sample that generated the selected voronoi cell or the last simulated sample in the selected voronoi cell is used as the seed and the hastings algorithm is a candidate sample is simulated using the proposal and is accepted with the probability is given in the present the proposed pdf is equal to the uniform pdf for design parameters and the initial pdf for uncertain q on simplifying is given stopping criteria a new stopping criterion is proposed in this the convergence of the expected value of the performance measure with respect to the pdf for φ and θ in consecutive iterations is used as the stopping mathematically the proposed stopping criterion is represented ε ε is a tolerance other stopping as indicated in can also be implementation issues an important issue for the effective implementation of the isso is the creation of the voronoi cells at the current iteration bounded within the voronoi cell created at the previous although it is possible to create such bounded voronoi due to the geometrical it is usually unfeasible for the higher dimensional problems an alternative approach is proposed in the present study for creating the voronoi cells at any iteration of the the proposed approach volves creating voronoi cells using the samples generated at the current and all previous iterations and then by considering voronoi cells responding to the samples from the current this is shown in where shows the n samples at the first iteration and the corresponding voronoi shows the ρn selected voronoi cells leading to the smallest volume density and the additional samples being generated using these ρn samples as shows that the voronoi cells are generated using all n samples that are generated in the two the voronoi cells corresponding to the n samples for consideration at the second iteration are also highlighted in shows a version of where it can be observed that the area covered by the n voronoi cells considered in the second iteration is not the same as the area covered by the ρn voronoi cells selected in the first on the the area covered by the voronoi cells in the second iteration is more than the area covered by the voronoi cells corresponding to the seed samples from the first this is because a new sample within the voronoi cell between an existing sample and the existing voronoi cell edge results in the relocation of the voronoi cell edge in a implementation of voronoi tessellation in khalid and bansal advances in engineering software direction away from the new the increase at each iteration troduces a bias in the estimate of in this does not affect the performance of the proposed approach as the objective is not to simulate the samples distributed as but to identify the subsets for an optimal in the increase is not as seen later in the illustrative examples in section special deterministic optimization in the isso a deterministic optimization problems can also be handled with the vector of uncertain variables θ set equal to a null vector since the determination of the subset at each isso iteration is solely dependent on the samples distributed as no modification to the isso algorithm is required to solve a deterministic optimization and the entire formulation remains illustrative examples in this typical optimization problems are considered to demonstrate the effectiveness and efficiency of the proposed deterministic optimization problems are these lems include several local and global stochastic zation problems are the second example presents an rdo problem of the in this the variance minimization of the protected displacement attached to the is in the third the mean minimization of bars truss problems is explored to demonstrate the applicability of the posed approach to a stochastic design the fourth example investigates the tion of a base isolation system for a in this after implementing the optimal design solution is identified as let j be a set of identically distributed realizations of and let be the structural mance function realization for the expected structural performance function is approximated by the average of the realizations n n h θj is evaluated for all unique φ samples obtained at the last iteration of the and the φ sample resulting in the smallest value of is taken as the optimal as the hand side of is any deterministic optimization method can also be used to solve the optimization problem with the approximate in the following both isso and sso are implemented with n ρ and the stopping criteria as stated in a value of ε is results for the griewank khalid and bansal advances in engineering software multimodal deterministic optimization problems in this three benchmark deterministic optimization problems are results are also compared with the the test functions griewank d i d cos i π holder table π the results for the griewank function are presented in shows that the function has multiple closely spaced local minima with a single global shows the sso optimization using and as shapes of admissible it is seen that these shapes fail to capture the region containing the optimal design due to the presence of multiple local the isso is where the voronoi cells selected at the first and last iteration are shown in it is observed that at the first the selected voronoi cells effectively capture both the local and global minima and in the subsequent the selected cells are more concentrated near the global the region selected at the last iteration captures the optimal global the function has a relatively complex design space compared to the griewank shows multiple local and global minimization by using sso is demonstrated in it is found that both the and are trapped around any one of the global at the same the isso is able to capture the regions that include all of the global as results for the khalid and bansal advances in engineering software seen in the holder table function has multiple local and global the global minima are placed at the boundary of the design as shown in once it is seen that both the and are trapped around any of one of the global and on the other the isso is able to capture the regions that include all of the global as seen in the results from the three examples demonstrate that the proposed isso is able to capture the regions containing the optimal solution the statistics of the results of independent both for sso and isso are presented in table it also includes the results obtained by using such as the genetic particle swarm and the gradient based optimization approach the proposed isso outperforms all other approaches as more successes in determining the optimal solution are observed in all three optimization it is also seen that both sso and isso result in a similar value of volume reduction for the same stopping with the number of iterations required to achieve this volume reduction are relatively the proposed approach outperformed the as indicated by the number of these examples demonstrate that the main advantage of implementing voronoi tessellation is an effective ration of the design the performance of the proposed sort for selecting the optimal subset is studied by using the three shows the value of for the dent simulation which is estimated by implementing the proposed double sort algorithm and by using the genetic it can be noted that for each the values obtained using the proposed double sort algorithm and genetic algorithm are well thereby confirming the adequacy of the proposed double sort at any iteration of new samples are simulated using the seed in the proposed the volume of the voronoi cells corresponding to the seed and new samples is greater than the volume of the voronoi cells corresponding only to the seed shows this change in volume due to the creation of voronoi cells at any generation of isso using the procedure mentioned in section the increase is observed to be small which further reduces with an crease in the iteration it is also observed that the increase in volume decreases with an increase in sample size at each iteration and increases with an increase in the dimension of the robust design optimization of the tuned mass damper this example considers a stochastic design problem involving a tuned mass damper attached to a single degree of freedom the problem is taken from and is shown in in this the system is excited by a white noise signal with a mean zero and unit the performance measure is the variance of the displacement of the system the mass stiffness and results for the holder table khalid and bansal advances in engineering software damping cs of the system are taken as uncertain following independent gaussian the mean value of these variables is taken to be and to account for the value for each variable taken is the frequency ratio β ωt and damping ξt of the tmd are considered design the tmd has a mass of the parameters in the mass of the the natural frequency of the tmd and the natural frequency of the structure the optimization problem is written minimize eθ φ table statistics of optimization results for multimodal deterministic optimization example sso isso griewank nf ns bv wv av fe gen vr nf ns bv wv av fe gen vr nf ns bv wv av fe gen vr ga genetic pso particle swarm gba optimization nf ns bv best wv worst av average coefficient of fe function gen vr volume reduction efficiently applicable only for deterministic comparison of double sort algorithm and genetic algorithm percentage change in volume at each isso khalid and bansal advances in engineering software β ξt φ table presents the optimal design parameter values as well as the objective function value that solve the optimization problem in results obtained using sample average approximation and isso are saa is applied with a sample size of as mentioned in the results demonstrate that isso is effective in locating the optimal sso implemented with gives an optimal solution but has a higher computational truss structure the third example involves minimizing the mean of the compliance of a linear elastic truss structure shown in under the weight constraint w because of structural design parameters corresponding to the areas of elements are divided into seven each with a minimum area of the modulus for the bar groups are assumed as uncorrelated normal random variables with mean values equal to gpa and the equal to the density of the material is the dome is subjected to concentrated vertical loads acting ward at the top normally distributed with a mean equal to kn and equal to in the mass of bars is concentrated at the the problem is taken from table presents the best of independent run results obtained with sso and once the sso and isso solutions agree thereby demonstrating the effectiveness of the proposed at the same the number of function evaluations is substantially less in the case of indicating the efficiency of the proposed design of a base isolated structure this adapted from involves the tmd attached to a sdof system table variance minimization of method admissible subset shape design parameters fe ns nf β ξt sso saa isso voronoi tessellation dome truss structure table results for the bars truss method design parameters g fe sso saa isso khalid and bansal advances in engineering software optimization of a system attached to a building as shown in this optimization problem includes maximizing the reliability of the structure which is performed by the minimization of its failure probability and mathematically expressed minimize θ is the function that indicates and it equals when the system when unacceptable performance in this problem the building is considered as a shear structure with certain stiffness and each story has a total mass of the stiffness ki of all stories are parameterized by ki i where the most probable values of the stiffness are the entity θi is a set of uncertain variables that are considered to be correlated gaussian ables with a unit mean value and a covariance matrix defined e θj the damping ratios are considered independent gaussian variables with mean values of and of for all the tajimi model is used to simulate the ground excitation modelled as a filtered white noise with the power spectral density function given g g ω πωg g ζgand σω are the resonant and rms of the acceleration input of the these are also considered uncertain variables with mean values of and a equal to the of the excitation is modeled by multiplying the filter output with the envelope function with parameters and chosen to simulate strong earthquake excitation for a duration of s with a sampling time of the system considered is a bilinear isolator with an additional viscous the base has a the design parameters φ for the base isolation structure system are the stiffness before yielding kprand after yielding the yield force is and the damping coefficient the reader may refer to for additional details regarding the base isolation structure system adopted in this failure is indicated when any of the normalized base displacements or drifts exceeds the normalization constants are m and m the design interval for each variable is specified as kpr fy kp and cd in this isso and sso are mented with six number of table shows the optimization results for the best independent simulation the comparison of the results obtained using saa a sample size of and isso shows that the optimal design obtained using the proposed approach isso is in good the failure probability of the structure is reduced from the base isolation to after installing the optimally designed base isolation conclusion this study attempts to provide an optimization approach called which is an improved version of primarily for stochastic optimization problems while it retains utility for deterministic zation problems as two novel ideas are introduced in this a better characterization of the design space is offered by tioning the design space into subregions using voronoi base isolated shear and of bilinear isolator table base isolation structure system optimization results of independent method design parameters failure probability kpr fy kp cd sso saa isso khalid and bansal advances in engineering software tessellation which improves the effectiveness and efficiency of the posed isso considerably in comparison to a novel approach is eliminating the need for optimization to identify the subregions for the optimal design at each isso several mathematical and engineering design including bars truss and are included in this study to demonstrate the efficacy of the proposed the results show that the proposed isso effectively identifies the reduced design space for complex design problems with multiple global and local this is attributable to the voronoi which eliminates the ment of the presumed admissible design space form to resemble the contour of the original voronoi tessellation enabled better design space allowing multiple global minima scattered throughout the design pace to be effectively due to the cretization of the design space via voronoi computation demand is significantly reduced as the number of function evaluations for all examples is lower the original the novel idea of the double sort approach achieves the requisite precision in identifying the subregions for optimal solutions and makes isso implementation simple and the applicability of the approach is dependent on the creation of the voronoi at present the methods available in the literation for creating the voronoi tessellation are computationally demanding when considering problems of very high future work will focus on developing a method for creating the voronoi tessellation in higher particularly those greater than credit authorship contribution statement mohd aman formal writing original sahil declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this data availability no data was used for the research described in the voronoi tessellation voronoi tessellation is a mathematical concept named after the russian mathematician georgy it is also known as the voronoi diagram or dirichlet a voronoi tessellation of a set of points p in a plane is a partition of the plane into a set of convex with each polygon including precisely one point of p and each point in a polygon being closer to its associated point in p than to any other point in each polygon is referred to as a voronoi cell or a dirichlet the boundary of each cell is constituted of points that are equidistant to two or more points in shows the voronoi diagram in a design voronoi diagram in there are several efficient algorithms for creating voronoi one such basic algorithm is to start with a set of points and then compute the voronoi cells by dividing the space into regions based on the distance to the nearest the algorithm which generates a delaunay triangulation in any number of can be applied while creating a voronoi the delaunay triangulation is a triangulation of the point in which no point falls within the circumcircle of any the polygon generated by the intersection of the defined by the edges of the delaunay triangles enclosing the point is therefore obtained as the voronoi cell of a it can be summarized that voronoi tessellation is a powerful mathematical concept that aids in dividing space into regions based on the distance to a set of voronoi tessellation finds widespread applications in areas such as image processing spatial topology analysis and microstructure study the matlab command from the computing has been used in this study to create the voronoi	['[1] Marti K. Stochastic optimization methods. Berlin: Springer; 2008. ', '[2] Tsompanakis Y, Lagaros ND, Papadrakakis M. Structural design optimization considering uncertainties. CRC Press; 2008. ', '[3] Khalid MA, Bansal S, Ramamohan V. An augmented formulation for robust design optimization of structures using stochastic simulation method. Res Eng Des 2023; 34:179–200. https://doi.org/10.1007/s00163-022-00405-z. ', '[4] Meng Z, Li G, Wang X, Sait SM, Rıza A. A comparative study of metaheuristic algorithms for reliability ‑ based design optimization problems. Arch Comput Methods Eng 2021;28:1853–69. https://doi.org/10.1007/s11831-020-09443-z. ', '[5] Abualigah L, Elaziz MA, Khasawneh AM, Alshinwan M. Meta-heuristic optimization algorithms for solving real-world mechanical engineering design problems : a comprehensive survey, applications, comparative analysis, and results. Neural Comput Appl 2022;34:4081–110. https://doi.org/10.1007/s00521- 021-06747-4. ', '[6] Katebi J, Shoaei M, Nguyen S, Trung T, Khorami M. Developed comparative analysis of metaheuristic optimization algorithms for optimal active control of M.A. Khalid and S. Bansal', '[7] Alorf A. Engineering applications of artificial intelligence a survey of recently developed metaheuristics and their comparative analysis. Eng Appl Artif Intell 2023;117:105622. https://doi.org/10.1016/j.engappai.2022.105622. ', '[8] Kirsch U. Structural optimization: fundamentals and applications. Springer-Verlag; 2012. ', '[9] Floudas CA, Pardalos PA. Encyclopedia of optimization. Springer; 2008. ', '[10] Kiureghian AD, Ditlevsen O. Aleatory or epistemic? Does it matter? Struct Saf 2009;31:105–12. https://doi.org/10.1016/j.strusafe.2008.06.020. ', '[11] Schu¨eller GI, Jensen HA. Computational methods in optimization considering uncertainties - an overview. Comput Methods Appl Mech Eng 2008;198:2–13. https://doi.org/10.1016/j.cma.2008.05.004. ', '[12] Schneider J, Kirkpatrick S. Stochastic optimization. Springer; 2007. ', '[13] Do B, Ohsaki M. A random search for discrete robust design optimization of linear- elastic steel frames under interval parametric uncertainty. Comput Struct 2021; 249:106506. https://doi.org/10.1016/j.compstruc.2021.106506. ', '[14] Asadpoure A, Tootkaboni M, Guest JK. Robust topology optimization of structures with uncertainties in stiffness - application to truss structures. Comput Struct 2011. https://doi.org/10.1016/j.compstruc.2010.11.004. ', '[15] Doltsinis I, Kang Z. Robust design of structures using optimization methods. Comput Methods Appl Mech Eng 2004;193:2221–37. https://doi.org/10.1016/j. cma.2003.12.055. ', '[16] Carneiro G, das N, Ant´onio CC. Dimensional reduction applied to the reliability- based robust design optimization of composite structures. Compos Struct 2021; 255. https://doi.org/10.1016/j.compstruct.2020.112937. ', '[17] An H, Youn BD, Kim HS. Reliability-based design optimization of laminated composite structures under delamination and material property uncertainties. Int J Mech Sci 2021. https://doi.org/10.1016/j.ijmecsci.2021.106561. ', '[18] Li Z, Duan LB, Cheng AG, Yao ZP, Chen T, Yao W. Lightweight and crashworthiness design of an electric vehicle using a six-sigma robust design optimization method. Eng Optim 2019. https://doi.org/10.1080/0305215X.2018.1521396. ', '[19] Gholinezhad H, Torabi SH. Reliability-based multidisciplinary design optimization of an underwater vehicle including cost analysis. J Mar Sci Technol 2021. https:// doi.org/10.1007/s00773-021-00804-2. ', '[20] Lee KH, Park GJ. Robust optimization considering tolerances of design variables. Comput Struct 2001;79:77–86. https://doi.org/10.1016/S0045-7949(00)00117-6. ', '[21] Anderson TV, Mattson CA. Propagating skewness and kurtosis through engineering models for low-cost, meaningful, nondeterministic design. J Mech Des Trans ASME. 2012. https://doi.org/10.1115/1.4007389. ', '[22] Zhou Q, Wang Y, Choi SK, Jiang P, Shao X, Hu J, Shu L. A robust optimization approach based on multi-fidelity metamodel. Struct Multidiscip Optim 2018. https://doi.org/10.1007/s00158-017-1783-4. ', '[23] Wang GG, Shan S. Review of metamodeling techniques in support of engineering design optimization. J Mech Des Trans ASME. 2007;129:370–80. https://doi.org/ 10.1115/1.2429697. ', '[24] Chatterjee T, Chakraborty S, Chowdhury R. A critical review of surrogate assisted robust design optimization. Arch Comput Methods Eng 2019;26:245–74. https:// doi.org/10.1007/s11831-017-9240-5. ', '[25] Chatterjee T, Friswell MI, Adhikari S, Chowdhury R. A global two-layer meta- model for response statistics in robust design optimization. Eng Optim 2021. https://doi.org/10.1080/0305215X.2020.1861262. ', '[26] Guo X, Zhao X, Zhang W, Yan J, Sun G. Multi-scale robust design and optimization considering load uncertainties. Comput Methods Appl Mech Eng 2015;283: 994–1009. https://doi.org/10.1016/j.cma.2014.10.014. ', '[27] Jerez DJ, Jensen HA, Beer M. Reliability-based design optimization of structural systems under stochastic excitation: an overview. Mech Syst Signal Process 2022. https://doi.org/10.1016/j.ymssp.2021.108397. ', '[28] Li W, Gao L, Xiao M. Multidisciplinary robust design optimization under parameter and model uncertainties. Eng Optim 2020;52:426–45. https://doi.org/10.1080/ 0305215X.2019.1590564. ', '[29] Beyer HG, Sendhoff B. Robust optimization - a comprehensive survey. Comput Methods Appl Mech Eng 2007;196:3190–218. https://doi.org/10.1016/j. cma.2007.03.003. ', '[30] Motta R, de S, Afonso SMB. An efficient procedure for structural reliability-based robust design optimization. Struct Multidiscip Optim 2016;54:511–30. https://doi. org/10.1007/s00158-016-1418-1. ', '[31] Yildiz AR. Comparison of evolutionary-based optimization algorithms for structural design optimization. Eng Appl Artif Intell 2013;26:327–33. https://doi. org/10.1016/j.engappai.2012.05.014. ', '[32] Beck AT, Gomes WJDS. A comparison of deterministic, reliability-based and risk- based structural optimization under uncertainty. Probab Eng Mech 2012;28:18–29. https://doi.org/10.1016/j.probengmech.2011.08.007. ', '[33] Acar, E., Bayrak, G., Jung, Y., Lee, I., Ramu, P., Ravichandran, S.S.: Modeling, analysis, and optimization under uncertainties: a review, (2021). 10.1007/s001 58-021-03026-7. ', '[34] Georghiou A, Kuhn D, Wiesemann W. The decision rule approach to optimization under uncertainty: methodology and applications. Comput Manag Sci 2019. https://doi.org/10.1007/s10287-018-0338-5. ', '[35] Braydi O, Lafon P, Younes R. Study of uncertainties and objective function modeling effects on probabilistic optimization results. ASCE ASME J Risk Uncertain Eng Syst Part B Mech Eng 2019. https://doi.org/10.1115/1.4044152. ', '[36] Liu WS, Cheung SH. Reliability based design optimization with approximate failure probability function in partitioned design space. Reliab Eng Syst Saf 2017;167: 602–11. https://doi.org/10.1016/j.ress.2017.07.007. ', '[37] Chiralaksanakul A, Mahadevan S. First-order approximation methods in reliability- based design optimization. J Mech Des Trans ASME 2005. https://doi.org/ 10.1115/1.1899691. ', '[38] Doltsinis I, Kang Z, Cheng G. Robust design of non-linear structures using optimization methods. Comput Methods Appl Mech Eng 2005;194:1779–95. https://doi.org/10.1016/j.cma.2004.02.027. ', '[39] Taflanidis AA, Beck JL. Stochastic Subset Optimization for optimal reliability problems. Probab Eng Mech 2008. https://doi.org/10.1016/j. probengmech.2007.12.011. ', '[40] Au SK, Beck JL. Estimation of small failure probabilities in high dimensions by subset simulation. Probab Eng Mech 2001;16:263–77. https://doi.org/10.1016/ S0266-8920(01)00019-4. ', '[41] Jia GF, Taflanidis AA. Non-parametric stochastic subset optimization for optimal- reliability design problems. Comput Struct 2013;126:86–99. https://doi.org/ 10.1016/j.compstruc.2012.12.009. ', '[42] Taflanidis AA. Stochastic subset optimization incorporating moving least squares response surface methodologies for stochastic sampling. Adv Eng Softw 2012;44: 3–14. https://doi.org/10.1016/j.advengsoft.2011.07.009. ', '[43] Khalid MA, Bansal S. Framework for robust design optimization of tuned mass dampers by stochastic subset optimization. Int J Struct Stab Dyn 2023;23. https:// doi.org/10.1142/S0219455423501559. ', '[44] Au SK. Reliability-based design sensitivity by efficient simulation. Comput Struct 2005;83:1048–61. ', '[45] Taflanidis AA, Beck JL. An efficient framework for optimal robust stochastic system design using stochastic simulation. Comput Methods Appl Mech Eng 2008. https:// doi.org/10.1016/j.cma.2008.03.029. ', '[46] Robert CP, Casella G. Monte carlo statistical methods. New York, NY: Springer; 2004. ', '[47] Li HS. Subset simulation for unconstrained global optimization. Appl Math Model 2011;35:5108–20. https://doi.org/10.1016/j.apm.2011.04.023. ', '[48] Khalid MA, Bansal S, Ramamohan V. An augmented formulation for robust design optimization of structures using stochastic simulation method. Res Eng Des 2022. https://doi.org/10.1007/s00163-022-00405-z. ', '[49] Taflanidis AA, Beck JL. An efficient framework for optimal robust stochastic system design using stochastic simulation. Comput Methods Appl Mech Eng 2008;198: 88–101. https://doi.org/10.1016/j.cma.2008.03.029. ', '[50] Kandemir EC, Mortazavi A. Optimization of seismic base isolation system using a fuzzy reinforced swarm intelligence. Adv Eng Softw 2022;174:103323. https://doi. org/10.1016/j.advengsoft.2022.103323. ', '[51] Rebay S. Efficient unstructured mesh generation by means of delaunay triangulation and Bowyer-Watson algorithm. J Comput Phys 1993;106:125–38. ', '[52] Wade N, Graham-Brady L. Estimating microstructural feature distributions from image data using a Bayesian framework. J Microsc 2023:1–16. https://doi.org/ 10.1111/jmi.13184. ', '[53] Duan X, Li L, Ge Y, Liu B. Exact Voronoi diagram for topographic spatial analysis. GIScience Remote Sens 2023;60. https://doi.org/10.1080/ 15481603.2023.2171703. ', '[54] MATLAB and parallel computing toolbox release. Natick, Massachusetts, United States: The Mathworks, Inc.; 2021. M.A. Khalid and S. Bansal']
7	https://drive.google.com/file/d/1rjGk1mEFXoavUZs1Az1RuV_61a7hRkR-/view?usp=drive_link	2023-08-03	Semantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model	['Shivangi Sachan', 'Khushbu Doulani', 'Mainak Adhikari']	['Department of CSE IIIT Lucknow', 'Vardhaman College of Engineering']	['Dataset', 'KNN', 'Gaussian Naive Bayes', 'LSTM', 'SVM', 'Bidirectional LSTM', 'GRU', 'Word-Embeddings', 'CNN']	The emergence of novel types of communication, such as email, has been brought on by the development of the internet, which radically concentrated the way in that individuals communicate socially and with one another. It is now establishing itself as a crucial aspect of the communication network which has been adopted by a variety of commercial enterprises such as retail outlets. So in this research paper, we have built a unique spam-detection methodology based on email-body sentiment analysis. The proposed hybrid model is put into practice and preprocessing the data, extracting the proper- ties, and categorizing data are all steps in the process. To examine the emotive and sequential aspects of texts, we use word embed- ding and a bi-directional LSTM network. this model frequently shortens the training period, then utilizes the Convolution Layer to extract text features at a higher level for the BiLSTM network. Our model performs better than previous versions, with an accuracy rate of 97–98%. In addition, we show that our model beats not just some well-known machine learning classifiers but also cutting-edge methods for identifying spam communications, demonstrating its superiority on its own. Suggested Ensemble models results are examined in terms of recall, accuracy, and precision	introduction over the past few a clear surge of both the amount of mers as well as spam this is likely due to a fact that the investment necessary for engaging in the spamming industry is relatively as a result of we currently have a system that identifies every email as which has caused major ditures in the investment of defense systems emails are used for online crimes like and algorithms that are based on machine learning are now the most effective and often used approach to the recognition of which is defined as a fraudulent attempt to acquire private information by masquerading as a worthy party in electronic has rapidly advanced past use of simple techniques and the tactic of casting a wide spear phishing uses a variety of sophisticated techniques to target a single other researchers used decision and svm to compare the performance of supervised ml algorithms for spam identification spam emails clog up cipients inboxes with unsolicited which frustrate them and push them into the attackers planned traps as a spam messages unquestionably pose a risk to both email users and the internet in users may occasionally read the entire text of an unsolicited message that is delivered to the target users inboxes without realizing that the message is junk and then choosing to avoid building a framework for email spam detection is the aim of this in this we combine the network with the cnn and gru cnn layers are used to speed up training time before the and more advanced textual istics are extracted with the use of this network in comparison to the straight lstm in less gated recurrent neural works are then added because they train more quickly and perform better for language to evaluate and investigate various machine learning algorithms for predicting email and develop a hybrid classification algorithm to filter email spam before employing an ensemble classification algorithm to forecast to put an innovative technique into practice and compare it to the current method in terms of various ensemble a successful machine learning combines a group of learners rather than a single learner to forecast unknown target and stacking are the four main types of ensemble learning to increase an integrated method and the combining of two or three algorithms are also extraction of features takes a long it can be challenging to extract all of the crucial information from a short over the span associated with this august india sachan et we utilize bidirectional large memories in conjunction with convolutional neural networks to come up with an innovative method to the detection of bagging and boosting approaches were widely preferred in this contribution and paper organization is as section describes literature section describe motivation for this research section sketches procedure of details section present experimental dataset description and evaluation and section summarizing outcomes of the related work email is indeed the second most frequently utilized internet cation as well as the third most common method of claims one cybercriminals exploit it in a number of including as sending obscene or abusive adding viruses to snatching the private information of and posing it to a broad spam letters made up of all email traffic in march we examine three main types of lawful emails in our first are fake which are sent to manipulate recipients to submit sensitive the ond as being use of harassing emails to threaten suspicious emails that describe illegal activities belong to the third many researchers have earlier contributed massively to this the researcher claims there is some proof that suspicious emails were sent before to the events of when it comes to data there are also convinced approaches and technologies like that are even though their efficiency of the are together is adversely a hidden which itself is essential for is the top layer of the we use oversampling methods for this minority class because of the absence of sampling techniques can help with but they have an impact on simulation oversampling causes data to be randomly which affects test data because dividing data may result in dersampling may result in the loss of some strong in order to advance email it is crucial to provide datasets on criminal garg et which revealed that spam in an email was detected in percent of business spam was established as an obstacle for email recognizing spam and getting rid of it were the primary as spam can be may lead to other internet sites being which can offer harmful and can feature those who are not lar with their content using to select the each mail transmission protocol requires precise and effective email a machine learning comparison is our study has suggested that innovative deep learning outperforms learning algorithms like svm and current studies on the classification of emails use a variety of machine learning with a few of them focusing on the study of the sentiments consisted of within email the lack of datasets is a significant obstacle to email there are few publicly accessible thus researchers must use these datasets to test their potheses or gather data on their describe supplied outlier detection models to enhance the iiot artificial neural gaussian and rf ensemble techniques were performed to forecast class and the outputs were input into a classifying unit to increase a method for phishing detection was presented by the authors in to classify phishing they employed they categorize spam and phishing they enhanced phishing email classifiers with more accurate predictions by extracting they showed some effective machine ing spam filtering when the pca method is it will lower the number of features in the the collected features go through the pca algorithm to reduce the number of the pca method is used to make a straightforward representation of the information which illustrates the amount of variability there is in the the authors of presented the fuzzy method for classifying spam to stop they implemented a membership threshold a methodology to identify beled data was put forth by the authors of and applied motive analysis to the enron data they divided the data into categories that were and they grouped the data using an unsupervised ml technique and then classified it using the supervised ml techniques svm and and colleagues implemented deep semantic analysis and categorization of data using a forensic for multiclass email sefaced employs a gated recurrent neural network based on long memory different random weight tializations affect lstms et experiments on rough set email spam ing show that it is feasible to significantly boost coverage without decreasing accuracy according to xia et sms spam has been identified using machine learning model such as naive bayes support vector machines long selective memory machines and convolutional neural networks including every instance of a method for categorizing et using adaboost and stochastic gradient descent algorithms for filtering with r and orange software spam orange software was used to create the which included adaboost and the majority of researchers focused on email spam classification ods because spam can be filtered in the early stages of there are widely used word bag which believes that documents are merely unordered collections of is the foundation for these kumaresan explains svm with a cuckoo search algorithm was used to extract textual features for spam renuka and visalakshi made use of svm spam email followed by selecting features using latent semantic indexing here we have used labeled dataset to train the hybrid we used for feature extraction and textual features for spam detection were extracted using svm and a cuckoo search for filtering out the spam combining the integrated strategy to the pure svm and nb overall accuracy is really accurate detection for spam email has been proposed using the negative selection algorithm and particle swarm pso is used in this instance to improve the effectiveness of the semantic analysis and classification of emails through informative selection of features and ensemble ai model august india motivation and novelty email is most common form of communication between people in this digital many users have been victims of spam and their personal information has been the email classification technique is employed to identify and filter junk and emails prior to reach a existing email classification methods result in irrelevant emails the loss of valuable keeping these constraints in the following contributions are made in this feature extraction is a lengthy extracting every important feature from text is in this we show how to employ gru with lutional neural networks and to find used and gated recurrent ral networks to examine the sentimental and sequential way of email applied cnn before the training time can be sped this network can also extract more advanced textual features faster than the network alone when combined with the gru we use enorn corpora datasets and compute and to assess how well the suggested technique our model outperforms several chine learning techniques as well as more contemporary methods for spam message proposed system architecture and model is a valuable tool for communicating with other email allows the sender to efficiently forward millions of advertisements at no this scheme is now being used in a variety of as a a massive amount of redundant emails is known as spam or junk many people are confused about the emails in their each learning sequence is given ward as well as backward to two different lstm networks that are attached to the same outputs layer in order for bidirectional lstms to this indicates that the has detailed sequential information about all points before and following each point in a specific in other we concatenate the outputs from both the forward and the backward lstm at each time step rather than just encoding the sequence in the forward each encoded form now comprehends the words that come before and after this is a problem for the internet the agram depicts various stages that aid in the prediction of email because data is messy and contains unnecessary mation and data preprocessing is critical in natural language processing the major preprocessing steps are picted nlp tokenization tokenization of documents into words follows predefined the tokenization step is carried out in python with spacy stop words removal stop words appear infrequently or frequently in the but they are less significant in terms of as a these are removed to improve data text normalization a lexicon form or order may they must all be changed to their root word to be correctly lemmatization and stemming are the two methods that can be used for when a final few characters are removed to create a shorter even if that form has no the procedure is known as lemmatization is a mixture of based an and it retains the context of a term while changing it back to its feature extraction feature extraction which transforms the initial text into its features so that it may be used for modeling after being cleaned up and before predicting we use a specific way to give weights to specific terms in our while it is simple for a computer to process we choose to represent individual words in such we choose word idf is the count of documents containing the term divided by the total number of and occurrence is the amount of instances a word appears in a we derive characteristics based on and we use equations to derive 𝑇 𝑓 𝐼𝑑𝑓 𝑡𝑓 𝑑𝑓 𝑇 𝑓 𝐼𝑑𝑓 𝑡𝑓 𝑇 𝑓 𝐼𝑑𝑓 𝑇 𝑓 𝑇𝐼𝑑𝑓 log 𝑁 a neural approach is the method that is utilized for this goal as the the following referred to as shows how handles word context through the use of here letter d stands for the display of a set of while the letters w and or represent paired word context that originated from a larger collection of set 𝑃 𝑃 august india sachan et helps to improve on the typical which requires a massive sparse feature vector to score every word individually to represent this same entire this perception is sparse because the vocabulary is and each word or document is defined by a massive using a word word embedding needs to be converted terms into real value feature there are two basic issues with standard feature engineering techniques for deep data is represented using sparse and the second is that some of the meanings of words are not taken into similar phrases will have values in embedding vectors that are almost the input length in our proposed study is set to for our suggested if the texts seemed to be integer encoded with value systems between and the vocabulary distance would be our data is encoded as and the input and output dimensions are both set to the embedding layer outcome will be used in successive layers and for bilstm and gru machine learning model within the scope of the we are using the subsequent chine learning to examine and compare the overall efficacy of our suggested support vector gaussian logistic k nearest and random forest convolution network the popular rnn model generally performs well but takes too long to train the model incorporating the textual sequential when a layer is added after the rnn the learning duration is considerably feature extraction is another additionally possible using the convolutional in the convolution layer looks for combinations of the various words or paragraphs in the document that involve the we use features with dimensions and a size for for this the relu activation function is after the largest pooling layers with a pooling size of are put on the data in order to obtain bilstm network with gru recurrent neural network technique of text sentiment ysis is particularly and frequently recurrent neural networks surpass conventional neural cause it can remember the information from earlier time steps thanks to its a state vector is combined with an data to create a new state the resulting state vector uses the present to recollect past the rnn is straightforward and is based on the following ℎ𝑡 tanh 𝑦𝑡 𝑊ℎ𝑦ℎ𝑡 the vanilla not very good at remembering previous in addition to rnn struggles with diminishing gradient a kind of rnn is a long recall network solves a vanishing gradient descent problem and learns lstm was actually created to address the problem of lstm has the unique ability to the cell state is the lstm central with only a small amount of linear the cell state follows the sequence essentially unmodified from beginning to gate of an lstm is also under the command of these information is safely inserted to or eliminated from the cell the following equations are used by the lstm model to update each 𝑓𝑡 𝜎 𝑊𝑓 𝑏𝑓 in this xt denotes and ht is the hidden state at the t time the following is the revised cell state 𝑖t 𝜎 𝐶𝑇 tanh 𝐶𝑡 𝑓𝑡 𝑖𝑡 𝐶𝑇 we may compute the output and hidden state at t time steps using the multiplication operator 𝑜𝑡 𝜎 ℎ𝑡 𝑜𝑡 tanh due to the reality it only considers all prior contexts from the present lstm does have a few as a result of it may accept data from preceding time steps through lstm as well as in order to avoid this further ments are carried out with the help of a bidirectional recurrent neural birnn can handle two pieces of formation from both the front and the is created by combining the and as a operating lstm has advantages such as cell state storage so that birnn have way to acknowledge from the context before and as a quence of it provides the with the advantages of an lstm with feedback for the next remembering dependencies is a significant new benefit of the which is a feature will be based on the call we forecast the probability of email content as and suspicious emails using as an input to the softmax activation which is a weighted sum of the dense to regulate the information gru employs the multiplying function and logistic sigmoid the gru has hidden states of storage memory and does not have distinct memory cells or units for state the and b which stand for and are crucial variables that must be calculated during the creation of the gru for training the word embedding known as the glove vector is they made it clear that gru is the superior model when there is a large amount of training data for textual groups and word embedding is and gru is required so as to compensate for the deletion of the and in our the embedding maximum sequence and lexicon size were used to start the lstm embedding layer in three separate lstm the input vector was modified to make it appropriate for such a prior sequences are returned by lstm the of the lstm layer must be set to false when the subsequent state is free of the gated semantic analysis and classification of emails through informative selection of features and ensemble ai model august india quantity of learning parameters must be taken into a lstm layer was set and different lstm unit combinations were more because it has more the model made with bilstm will take longer to bidirectional lstm is the name of a particular kind of recurrent neural network that is primarily used for the processing of natural it is able to use data from both in contrast to regular it enables input flow in both it is an effective instrument for demonstrating the logical relationships between words and and this involves both the forward and backward directions of the in bilstm works by adding one extra layer of causing the information flow to travel in the other it only denotes that the input sequence runs in reverse at the next lstm tiple including and are then applied to the results of the two lstm the gated design of and gru networks solves the disappearing gradient and exploding a good way to handle more long sequences is to use and gru gru works well with datasets that have in two to three the complicated model learns the long sequence of email text we have used word bidirectional lstm and gru networks as our three building blocks to separate email messages based on their sentiment and sequential we succinctly demonstrate below why these blocks help identify email we have used the sequence to sequence lstm as the current block in the networks since it can retrieve both the previous and next sequences from the more so than a straightforward lstm it can also recognize and extract text sentiment and sequential we extract the more complex and advanced teristics for network using convolutional network which is the second block after the takes a long time to extract hence one of the reasons for using this block is to reduce the overall training experimental evaluation experimental setup we divided the information into training and testing groups of we divided the remaining of the percent training data into test data for the and evaluate the efficacy of the suggested method using the pythonic packages as tensorflow and scikit dataset description email spam detection is the foundation of this research the dataset includes normal emails from the enron deceptive emails from phished email harassment emails chosen from hate and the offensive only the content of the email body is used for all header including and are and word embedding are used to extract characteristics from the email sage and classify this is publicly the presented model is implemented using and several including and are used to examine the evaluation metrics and results classifier performance is assessed using metrics such as and four terms make up a confusion matrix that is used to calculate these true positives are positive values that have been rately assigned the positive the negative values that are accurately identified as negative are known as true negatives true negative values are those that can be accurately fied as being negative positive readings that have been mistakenly labeled as tive are known as false negatives assess the efficacy of the suggested model is listed accuracy reveals how frequently the ml model was overall accuracy 𝑇𝑃 𝑇𝑃 𝐹𝑃 𝐹𝑁 the accuracy of the model gauges how effectively it can predict a specific precision 𝑇𝑃 𝑇𝑃 𝐹𝑃 recall tells us how often the model was able to ognize a specific recall 𝑇𝑃 𝑇𝑃 𝐹𝑁 model accuracy precision recall gaussian nb random forest knn svm lstm proposed ensemble table differet score on test data and recall metrics are in the given table where six different classifiers are gaussian dom and propose ensemble hybrid model have been used in this in the and gru architectures which enable sequence cnn strands for feature extraction on data input which are combined with it requires less time training and a higher expandable any bottlenecks are created by predictions and the increasing number of distinct units of this model is useful for dealing with classifications that consist of two or more than two so suggested ensemble out of these six produces more accurate august india sachan et figure performance analysis comparative analysis a ability to fit new data is measured by the validation whereas its ability to fit training data is determined by the training the two main variables that decide whether in which learning is efficient or not are validation loss and training lstm and suggested ensemble hybrid models have equivalent loss and in this we are contrasting the lstm with the proposed model and in terms of their respective validation accuracies and the accuracy was at its highest after epochs of operation when it achieved an accuracy of roughly while minimizing model figure lstm model training and validation accuracy figure lstm model training and validation loss figure ensemble model training and validation accuracy figure ensemble model and validation loss semantic analysis and classification of emails through informative selection of features and ensemble ai model august india in this proposed ensemble hybrid train accuracy is validation accuracy is and lstm has train accuracy of and validation accuracy is so based on figures and indicate the validation loss for lstm and the proposed ensemble hybrid model to be and and figures and show the validation accuracy to be and lstm and the proposed hybrid model used ensemble artificial with the proposed hybrid model outperforming the we decide on dense architecture as the final model for identifying the text messages as spam or nonspam based on and the aforementioned the loss and accuracy over epochs are more stable than and the proposed classifier has a straightforward conclusion the model is composed of four networks and we may train the model more quickly by using the convolutional layer followed by the and then the bilstm the bidirectional lstm network also has properties that we can we have used a bidirectional gru network to memorize a contextual meaning and sequential which proves the performance accuracy to roughly	['[1] Rayan Salah Hag Ali and Neamat El Gayar. 2019. Sentiment analysis using unla- beled email data. In 2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE). IEEE, 328–333. ', '[2] Ali Shafigh Aski and Navid Khalilzadeh Sourati. 2016. Proposed efficient algo- rithm to filter spam using machine learning techniques. Pacific Science Review A: Natural Science and Engineering 18, 2 (2016), 145–149. ', '[3] Huwaida T Elshoush and Esraa A Dinar. 2019. Using adaboost and stochastic gradient descent (sgd) algorithms with R and orange software for filtering e-mail spam. In 2019 11th Computer Science and Electronic Engineering (CEEC). IEEE, 41–46. ', '[4] Weimiao Feng, Jianguo Sun, Liguo Zhang, Cuiling Cao, and Qing Yang. 2016. A support vector machine based naive Bayes algorithm for spam filtering. In 2016 IEEE 35th International Performance Computing and Communications Conference (IPCCC). IEEE, 1–8. ', '[5] Pranjul Garg and Nancy Girdhar. 2021. A Systematic Review on Spam Filtering Techniques based on Natural Language Processing Framework. In 2021 11th Inter- national Conference on Cloud Computing, Data Science & Engineering (Confluence). IEEE, 30–35. ', '[6] Adam Kavon Ghazi-Tehrani and Henry N Pontell. 2021. Phishing evolves: Ana- lyzing the enduring cybercrime. Victims & Offenders 16, 3 (2021), 316–342. ', '[7] Radicati Group et al. 2015. Email Statistics Report 2015–2019. Radicati Group. Accessed August 13 (2015), 2019. ', '[8] Maryam Hina, Mohsin Ali, and Javed. 2021. Sefaced: Semantic-based forensic analysis and classification of e-mail data using deep learning. IEEE Access 9 (2021), 98398–98411. ', '[9] Maryam Hina, Mohsin Ali, Abdul Rehman Javed, Fahad Ghabban, Liaqat Ali Khan, and Zunera Jalil. 2021. Sefaced: Semantic-based forensic analysis and classification of e-mail data using deep learning. IEEE Access 9 (2021), 98398– 98411. ', '[10] Weicong Kong, Zhao Yang Dong, Youwei Jia, David J Hill, Yan Xu, and Yuan Zhang. 2017. Short-term residential load forecasting based on LSTM recurrent neural network. IEEE transactions on smart grid 10, 1 (2017), 841–851. ', '[11] T Kumaresan and C Palanisamy. 2017. E-mail spam classification using S-cuckoo search and support vector machine. International Journal of Bio-Inspired Compu- tation 9, 3 (2017), 142–156. ', '[12] Nuha H Marza, Mehdi E Manaa, and Hussein A Lafta. 2021. Classification of spam emails using deep learning. In 2021 1st Babylon International Conference on Information Technology and Science (BICITS). IEEE, 63–68. ', '[13] Tomas Mikolov and Geoffrey Zweig. 2012. Context dependent recurrent neural network language model. In 2012 IEEE Spoken Language Technology Workshop (SLT). IEEE, 234–239. ', '[14] Sarwat Nizamani, Nasrullah Memon, Mathies Glasdam, and Dong Duong Nguyen. 2014. Detection of fraudulent emails by employing advanced feature abundance. Egyptian Informatics Journal 15, 3 (2014), 169–174. ', '[15] V Priya, I Sumaiya Thaseen, Thippa Reddy Gadekallu, Mohamed K Aboudaif, and Emad Abouel Nasr. 2021. Robust attack detection approach for IIoT using ensemble classifier. arXiv preprint arXiv:2102.01515 (2021). ', '[16] Justinas Rastenis, Simona Ramanauskait˙e, Justinas Janulevičius, Antanas Čenys, Asta Slotkien˙e, and Kęstutis Pakrijauskas. 2020. E-mail-based phishing attack taxonomy. Applied Sciences 10, 7 (2020), 2363. ', '[17] Karthika D Renuka and P Visalakshi. 2014. Latent semantic indexing based SVM model for email spam classification. (2014). ', '[18] Shuvendu Roy, Sk Imran Hossain, MAH Akhand, and N Siddique. 2018. Sequence modeling for intelligent typing assistant with Bangla and English keyboard. In 2018 International Conference on Innovation in Engineering and Technology (ICIET). IEEE, 1–6. ', '[19] Tara N Sainath, Oriol Vinyals, Andrew Senior, and Haşim Sak. 2015. Convolu- tional, long short-term memory, fully connected deep neural networks. In 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP). Ieee, 4580–4584. ', '[20] Anuj Kumar Singh, Shashi Bhushan, and Sonakshi Vij. 2019. Filtering spam messages and mails using fuzzy C means algorithm. In 2019 4th International Conference on Internet of Things: Smart Innovation and Usages (IoT-SIU). IEEE, 1–5. ', '[21] Kristina Toutanova and Colin Cherry. 2009. A global model for joint lemmati- zation and part-of-speech prediction. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. 486–494. ', '[22] Tian Xia. 2020. A constant time complexity spam detection algorithm for boosting throughput on rule-based filtering systems. IEEE Access 8 (2020), 82653–82661. ', '[23] Yan Zhang, PengFei Liu, and JingTao Yao. 2019. Three-way email spam filtering with game-theoretic rough sets. In 2019 International conference on computing, networking and communications (ICNC). IEEE, 552–556. Received 15 April 2023 187']
8	https://drive.google.com/file/d/1eimqNkzhTW2T1CdCGc8zBarMmN4MjF-r/view?usp=drive_link	2021-09-27	ModelGame: A Quality Model for Gamified Software Modeling Learning	['Ed Wilson Júnior', 'Kleinner Farias']	['Universidade do Vale do Rio dos Sinos São Leopoldo, Rio Grande do Sul, Brazil', 'Universidade do Vale do Rio dos Sinos São Leopoldo, Rio Grande do Sul, Brazil']	['Model design', 'learning model', 'Gamification']	Gamification has been adopted in software development tasks in recent years. This adoption seeks, for example, to improve the engagement of developers while creating UML models or writing code. Empirical studies report that UML models suffer from incompleteness and inconsistency problems. This study conjectures that gamification mechanics can improve learner engagement while learning software modeling, mitigating such problems concerning UML models. The current literature lacks studies that explore gamification and UML model quality in the context of software modeling learning. This article, therefore, proposes ModelGame, which is a quality model to support software modeling learning in a gamified way. It serves as a reference framework so that instructors can obtain a parameterized way to evaluate UML models created by learners. The quality of UML models can be improved by applying gamified activities and providing guidelines aware of quality issues.	introduction gamification has been adopted in software development tasks in recent this adoption for to improve the engagement of developers while creating uml models or writing empirical studies report that uml models suffer from incompleteness and inconsistency lange reinforces that these defects bring potential risks that can cause misinterpretation and communication representing a risk to software finding formats that favor student learning and consequently in generating increasingly effective uml models can become one of the main challenges faced by instructors that include uml modeling as part of software modeling some studies sought to understand how to apply gamification in software modeling teaching using some elements such as emblems and instructors and researchers still find limitations when and measuring the use of this tool in the learning of software modeling students in the models developed by since in the current literature there is no frame of reference that guides this study conjectures that gamification mechanics can improve learner engagement while learning software mitigating such problems concerning uml the current literature lacks studies that explore gamification and model quality in the context of software modeling this introduces which is a quality model to support software modeling learning in a gamified it serves as a reference framework so that instructors can obtain a parameterized way to evaluate uml models created by the quality of uml models can be improved by applying gamified activities and providing guidelines aware of quality a reference framework would help to establish parameters for evaluating uml models created by provide guidelines to improve the quality of these to analyze which elements of gamification could be included in each of the phases of modeling using identify intrinsic and extrinsic aspects of students during the modeling to improve the to compare validated theories about the inclusion of gamification in software modeling taking into account the types of learning and methodologies and contributing to the identification of gamification use objectives in modeling a qualitative questionnaire was answered by instructors who teach software modeling at higher education the results show that recognize that the proposed model can improve the quality of uml indicating that they would adopt it in their learning and do not use any sbcars september brazil ed wilson júnior and kleinner farias gamification mechanics in their these results are showing the potential for applying and improving the teaching and learning of software the remainder of the paper is organized as section presents the main concepts discussed throughout the tion discusses the related highlighting research section introduces the proposed quality section presents how the quality model was section points out some threats to section presents some concluding remarks and future background this section presents the essential concepts for understanding this including gamification and software engineering teaching and software modeling and model quality gamification and software engineering teaching gamification aims to use game elements in the context of not game bringing all positive aspects they provide as a way to encourage and engage thereby broadening their werbach classifies gamification into three and dynamicsinclude all game aspects related to the emotional responses of and offer elements that promote the action of a game usually elaborated via a development so that the player can interact with such and components represent the aesthetic elements of whose goal is to present visual aspects with which players can perform the for and emblems knowing that the teaching of software engineering should volve students to experience the professional practices of the area so that they can understand which practices and techniques are useful in several different situations the challenges of teaching new software engineers are not limited to learning but also include paying attention to considering the quality of created established schedule and defined budgets in addition to understanding the technical these future professionals must be up to date with nontechnical including communication and to meet these new demands of the current the format with exhibition classes is no longer considered enough and may even become demotivating and ineffective in learning in this gamification has been increasingly used in the ing of software engineering as a way to promote behavioral and psychological changes providing an environment that favors achievement and other recurring elements that are capable of improving efficiency and engagement in educational activities and can for the learning of software software modeling and model quality software modeling encompasses the set of and practices that lead to the development of a system or the principles of this activity establish a philosophy that guides the entire software development in this uml models play a crucial role in software development for documenting project understanding development promoting better tion between and generating greater efficiency in software development these models suffer problems of consistency and incompleteness as well as end up being overlooked within the modeling as pointed out in some empirical studies in the literature class and sequence for present inconsistencies when sequence diagram objects are not found in the class consequently developers end up living with inconsistencies throughout the development a research challenge still open is how to evaluate these both in industry and in the teaching in terms of such as syntactic and for related work the selection of related works was carried out following two search in digital such as google scholar and scopus of articles related to quality and modeling and filter selected articles considering the alignment of such works with the objective of the work after selecting the they were analyzed and compared seeking to identify research analysis of related works porto et this work performed a systematic ping with the objective of characterizing how gamification has been adopted in noneducational contexts of software engineering the main results of this study show that gamification provided benefits for activities such as requirements project and support in he pointed out that the number of publications and new research initiatives has increased over the many tive results have been achieved in software engineering the study reinforced that gamification can still be explored for other tasks in this as empirical evidence is very marin it performed the application of gamification on some topics of a software engineering course to engage students and increase their motivation and argued with due students can better exercise the topics and obtain more solid there were five games related to risk bpmn scrum design and inspection of class and cosmic functional size measurement to assist in the learning process of the software engineering this study also presented the lessons learned about the application of gamification and serious games in software including limitations or jurgelaitis et this work conducted a research to investigate how gamification could be inserted into an information systems modeling which covers a range of topics on as a an implementation of the gamified system modeling course in the moodle environment was using additional a quality model for gamified software modeling learning sbcars september brazil plugins for the use of the necessary gamified the study showed good results and obtained a positive acceptance by the participating rodrigues et they investigated the use of games and game elements in software engineering through a research that had the participation of instructors of this the results showed that most instructors are aware of these educational the games were adopted by only participants and game elements were adopted only by games are most often used to cover and the most commonly used game elements are and the results also show that the main sons for not adopting the resources are the lack of information about games relevant to the engineering of teaching and the lack of time to plan and include these approaches in the cosentino et they present a proach to learning modeling in a gamified the approach cludes a new language to model the gamification process itself and an environment where it can be incorporated into current eling tools to allow instructors and students to design and use a complete modeling including gamification in the approach also had as a proposal to provide support to collect and analyze gamification thus facilitating monitoring yohannis this research presents an exploration of game design as an approach to strengthening the tery in software modeling by developing their abstraction it brought together concepts of gamification such as the lens of atoms of intrinsic skill and principles of pedagogical design of various theories and models of the research follows the design science research methodology and explores the best practices of model oriented as a a modeling game design framework and generation structure and a series of produced games are pedreira et they developed a systematic ping of gamification in software engineering based on the mapping revealed that software implementation is the area in which most studies followed by software few others in different such as project planning and software and even to a lesser extent in activities involving software the highlight of this work was to highlight that gamification in software engineering is still at a very early stage and the evidence on its impact in this field remains comparative analysis and opportunities five comparison criteria were defined selecting the most vant variables to assist in the process of identifying similarities and differences between the proposed work and the selected this comparison is crucial to make the process of identifying search opportunities using objective rather than subjective the criteria are described context works that explore the use of gamification in software modeling participant profile studies that collected data from participants for screening and profile applicability of gamification in uml studies that evaluated how gamification can contribute to uml model creation studies that have developed a model to improve factors that imply the of instructor participation studies that collected qualitative data through the participation of software eling table shows the comparison of the selected confronting this some gaps and research opportunities are only the proposed work was the only one to fully meet all ison although most of them targeted the application of gamification in software modeling they were not rected to the use of no study has developed a model to evaluate the learning and improvement of uml models developed by and most of them did not have the participation of instructors to identify the difficulties and opportunities in the application of gamification in the teaching of software the next section presents a quality model to explore these identified related work comparison criterion proposed work porto et al marin jurgelaitis et al rodrigues et al cosentino et al yohannis pedreira et al completely meets partially meets does not attend table comparative analysis of the selected related works proposed quality model this section presents the proposed quality model to support ware modeling learning in a gamified it serves as a frame of reference so that instructors can evaluate the uml models ated by students through gamified section presents a proposal of a generic analytical section details the abstract syntax of the proposed quality section plains the quality notions related to the gamified software modeling generic analytical framework figure presents the generic analytical framework for improving the quality of the models and serves as the basis for the creation of an evaluation the arrows labeled as evaluation and gamified represent the questions that the evidence must dotted lines represent rectangles resent the models or the quality states by which these bindings are ellipses represent the adverse effects that can be generated from the evaluation and use of the numbers refer to the key questions and are connected with the concepts and relationships of the abstract syntax of the quality sbcars september brazil ed wilson júnior and kleinner farias figure generic analytical framework for gamified software modeling model in section as are there tools that assist instructors in evaluating the models developed by thus reducing the poor quality and incompleteness of these what is the prevalence of characteristics that cause models to be at are there notions of quality to evaluate the models as a way to define parameters when performing their applying the use of gamification in models that need intervention would be a way to identify factors that could generate models with high quality does the application of gamification improve the quality of the how are the models without gamification evaluated in relation to those with are there reasons to expect that gamification models can have better quality results than those that are ated without is the output model really effective when associated with reducing the poor quality of the does the absence of evaluation result in adverse is the evaluation acceptable for the what are the potential and how often do they does gamification result in adverse effects on fact is that it is not enough just to include this in the uml learning it is necessary to provide the instructor with a model that can serve as a reference to evaluate the quality of diagrams elaborated through gamified for the instructor could create models predefining inconsistencies by making use of these questions raised to evaluate the models created by the the set of questions serves as the starting point for this knowing that the adaptation of the gamification approach requires a significant effort in this study we present the modelgame as a way to identify factors that contribute to the quality of these artifacts to the abstract syntax following the specification pattern of the uml figure presents the abstract syntax of the proposed quality model for gamified software modeling learning it identifies the main concepts and the numbers represent the notions of quality that are discussed in section the following are detailed each of these concepts and the first concept presented in this study is the which corresponds to a specific context of the application to be developed to solve the in this the design template represents the solution given to the association each contextualise refers to the domain that will serve as the basis for the challenges this concept represents the phase in which the problem is contextualized as well as what will be the and other elements presented to the in this case the who must use the principles of software engineering to perform the modeling and reach the final association design each influence represents that the proposed challenge interfered in aspects of the design causing the user to seek to make a continuous modeling software modeling is an important step for development to happen in a way that adheres to the ments established by the for there is the modeling which offers a standardized way to document and design through the use of modeling it is possible to achieve a high level of understanding about the software in improving the communication between all those involved in the thus avoiding implementation it points out that software engineers use these languages to communicate design decisions and verify the feasibility of implementing the intended the uml was consolidated as the modeling language in the paradigm of object in which it is possible through visual notation generated from the presented later in this study as design to perform the representation of various perspectives of the association a quality model for gamified software modeling learning sbcars september brazil figure abstract quality model design performs the representation of the intended design in which the modeling language should be applicable to the domain this concept corresponds to the individual who performs the interpretation of the developed design whose objective is to be able to understand the domain in in the gamified the user has the role of player and it is he who performs the whole being able to perform the interpretation of isting models or even creating new the user can also identify and resolve inconsistencies that arise from compositions between association design represents the process in which the user creates a design which can be one or design in this the user performs the interpretation of the design when interpreting the paths for the resolution of inconsistencies can be inconsistency represents the discovery of design model for those that are generated from identifying whether a class is abstract or inconsistency each resolves equates to the resolution representation of the sistencies by the user that happens after he analyzes and determines the best alternative to perform this modeling tools determines that the user can use modeling tools to design association without a directed modeling this concept represents the applications that are used to carry out the construction of design there are several tools online and and it is up to the user to choose the one that will best meet their needs and adapt to the context in that they work in any domain that is being design the design model refers to a visual notation to represent static and dynamic these models are built according to a specific objective or task and tend to facilitate the logical interpretation of the software in several the most popular diagrams are use cases and the first being static and representing a set of actions generated from functional requirements and presenting the interactions generated with external users the second is a static diagram and makes the representation of the logical structure of the software involving the their and relationships between them association each describes makes the representation of a specific domain and means that every design model must describe it corresponds to the defects found in the models developed by they may occur because of the cation and correction of possible conflicts and even an erroneous association design this association indicates that with each occurrence of the a problem is presented harming the quality of the design sbcars september brazil ed wilson júnior and kleinner farias this concept represents one of the most used game chanics in software engineering and functions as a quantitative reward for each action in which it is possible to regulate the number of rewarded points of the defined here as based on the importance of each through this it is possible to stimulate and creativity among stimulating points appear as a derivation of the association since when each inconsistency error is identified or the user will receive a score and the association because the points will also be applied when making connections between the model and the the concept of progress emerges as a factor that makes the user able to perceive its evolution in the in this software progress emerges as a derivation of the tion making the user know when they have performed a correct interpretation of the proposed design model or what still needs to be feedback has the role of making the user realize that the proposed goal can be achieved and follow its ing analyzing how to change or creating new strategies to achieve the this concept emerges as a derivation between the tions it causing the user to receive a return to the model creation quality notions as discussed in section gamification can bring important ments for learning software modeling the objective of this section is to produce the notions of quality of the model of this the modelgame is composed of ten four of which are proposed in this study motivational and gagement extracted from the main benefits that the gamification elements presented in figure can bring to the the others are adaptations of previous works they detection and scope quality it seeks to determine how much the proposed challenge is contextualized with the design as well as the inition of the behaviors and attitudes that will be developed throughout the syntactic quality this notion makes the representation of the process of correction of the design models that are produced by the modeling because if it is not used sistencies will it is important to insert this notion of quality into our since during the process of developing the users may come across the composition of two class for semantic quality it is necessary to verify that the design model and the problem domain so this notion performs this type of communication problems may occur between users if the semantic elements of the model are social quality design models are used to communicate between members of a team to inform all established decisions about software development if divergent interpretations this communication will be greatly quality of effort this notion refers to the production lenges of the model that will be including factors such as time and quality of use to produce design users can use unusual tools such as and most of the time they choose to use formal tools and can be online or this notion corresponds to the level of ease and applicability of the models elaborated when making use of these it is also important to contribute to communication between users through detection quality this notion is referenced to the process of locating since when users they should perform traceability of them if the detection is it could hinder the process of correcting the resolution quality it corresponds to the level of quality related to the effort that users take to look for alternatives to solve the identified motivational quality this notion refers to the tional factors involved during the learning and development of design which can be intrinsic and elements of gamification such as feedback and progress bring the user a degree of satisfaction in continuing their discovery and mations throughout the quality of engagement the user in tracking their progress can feel committed to the objective in and this notion represents the measurement of the level of commitment of them during the development of design evaluation this section describes the methodology followed to evaluate the proposed quality this methodology follows empirical guidelines section details the objective and search questions section presents the questionnaire lated to evaluate the proposed quality section explains the context and selection of section describes the presentation of the section presents the analysis of the collected objective and research questions the objective of this study is introduce game as a tool for teaching software and analyze the applicability of the quality model regarding the improvement of uml to analyze the different facets of the two research questions have been how do instructors evaluate the use of gamification in software what is the acceptance of modelgame by software modeling questionnaire data was collected through an online questionnaire created through google following guidelines described in this strategy was chosen because the questionnaire could be applied quickly and easily collect data from individuals in graphically diverse the questions of the questionnaire a quality model for gamified software modeling learning sbcars september brazil were concerned with examining the research gaps of previous ies and apprehending the structures of the previously developed part participant the first part of the questionnaire consisted of collecting data that are related to the characteristics and opinions of the the creation of the participant profile through this data is important to make the selection of possible users of without this participants with an inadequate profile may generate inconsistent participants were asked to provide more general such as education academic information about the time of experience in teaching was also including teaching software modeling and level of knowledge about uml part tam the second part addressed tions about the usability and acceptance of the aiming to explore to this this part of our questionnaire is based on the technology acceptance model this part contained nine which were answered through the likert cluding totally partially partially and totally the questions formulated dealt with eral including perceived ease of use perceived utility attitude towards use and behavioral intention to use selection of participants the participants were selected based on the following structors professionals working in the teaching of software modeling in higher education institutions in using this we sought to select participants with academic training and practical experience in this finite set of all possible participants represents the target population this tion represents those people who are in a position to answer the questions formulated and to whom the results of the survey apply in people answered the the pants were invited via to participate in the study and each of them previously received the about the model proposed through the researcher and there was no they could leave for the next step that consisted of completing the tam we discussed the experimental process in the next experimental process figure presents the experimental process used in this which is composed of three phases discussed phase it has an in which the researcher explained to the participants through a video detail about the quality this process took place individually and in a standard where space was also made available for ticipants to answer possible doubts about the proposed study and lasting an average of phase application of the tam it has two the first being collect demographic the participants answered a list of questions so that we could collect their characteristics and opinions about the the graphic data collected became the result of this the second activity apply tam questionnaire participants received a list of questions about the perception of ease of ceived and intention of in relation to the qualitative data were regarding the usability and acceptance of the model under the perspective of professionals who teach software this questionnaire followed the guidelines of the tam phase analysis and result it has two the analyze data sought to perform a thorough analysis of the data collected through the questionnaire and the perception regarding the doubts during the presentation for the collected data were analyzed as well as aiming to perform a triangulation of there was an evaluation as a way to understand in a more depth the the perceptions of the participants in relation to the proposed model as well as its figure the experimental result analysis profile data of the table describes the profile reporting the characteristics and opinions of the these data were collected from may to june in we had our participants are between and years most of them have a degree in computer science information systems or systems analysis and are specialists masters and doctors about the working time in the majority they have been ing for more than years and teach disciplines related to software including software systems analysis and software a total of have a full level of knowledge about uml and almost half of them has not yet used cation in the teaching of software we consider sbcars september brazil ed wilson júnior and kleinner farias totally agree partially agree neutral partially disagree totally disagree perceived ease of use i found the quality model easy to use i found the quality model easy to learn i found the quality model easy to master perceived usefulness the model would make it easier to understand which elements of gamification can be used in modeling using the quality model would help increase the model would provide an understanding of how to mitigate the incompleteness of uml the model would help compare theories about gamification in software modeling attitude towards use using the quality model for gamified software modeling learning is a good behavioral intention to use i would use the quality model in software modeling table collected data related to tam that although our sample is adequate to carry out an initial evaluation of the proposed characteristic and opinion answer age years years years years years education others undergraduate course information systems computer science computer engineering system analysis others time of experience in teaching years years years years years experience in teaching years software modeling years years years years level of knowledge beginner about uml models junior full senior used gamification in teaching yes no maybe gamification can contribute to the quality totally agree of the models of uml diagrams generated partially agree by students neutral partially disagree totally disagree table the profile data of the how do instructors evaluate the use of gamification in software table presents the collected data related to the rq we begin the analysis by verifying how instructors visualize gamification in software modeling although most of them have not yet used gamification elements among in their most totally agree and partially agree that the use of these can contribute to the quality of the models developed by the we consider the percentage of instructors who have not yet used gamification in their classes to be high and this may be tied to factors such as lack of information about the and even time to plan and include these approaches although they were based on software modeling teaching previous studies they did not count on the participation of instructors and we understand that this participation is fundamental to understand the perceptions of these professionals since they will be at the forefront of the use of the modelgame proposed in this study could help them insert gamification into their according to the software modeling learning design based on the assumption that for it is necessary to develop a better understanding of the skills and operations that the different elements of gamification can offer and how they can correspond to the desired learning outcomes by developing a more concrete and motivating presentation that can involve students and facilitate deep learning with what is the acceptance of the modelgame by software modeling using the tam we tried to evaluate the ease of perceived and ioral intention to use the quality table shows the data our data obtained show that no one disagreed that the modelgame is easy to and on the most of participants find the model easy to use totally agree and partially agrees and learn a quality model for gamified software modeling learning sbcars september brazil fully agree and partially and master fully partially agree and partially the results are also favorable considering the perception of most participants realized that the modelgame would make it easier to understand which elements of gamification can be used in each of the phases of modeling using totally partially agree and increase productivity fully partially agree and and the use of the quality model would provide an understanding of how to mitigate the incompleteness of uml diagrams agree totalmen partially neutral and partially still in the useful we tried to know if the quality model would help to compare validated theories about the inclusion of gamification in software modeling teaching totally partially agree and considering the attitude towards participants believe that using the modelgame is a good idea totally partially agree and just as they are confident and would use the model in software modeling classes totally partially agree and these findings show the potential for acceptance by people with profiles similar to those of the results are encouraging and show the potential to use the proposed approach in the educational threats to validity this section discusses the possible threats to the validity of the internal the main point affecting the internal validity of our study concerns the total time used for the exploratory to mitigate this we performed the video recording of a pilot explaining the operating details and objectives of the in relation to the methods the threats related to internal validity relate to how we extract the perceptions of the discussions and whether they represent the perceptions of teachers about the use of the we try to reduce this threat by applying the tam external we identified threats related to external such as the number of participants who never applied the use of this study was limited to participants from various educational of which never used any element of gamification in their this factor can interfere in the since the model intends to evaluate the quality of uml diagrams from gamified conclusion threats related to the validity of the clusion are related to treatment and we try to make the reduction by combining quantitative and qualitative data through different these data were obtained through audio and we analyze this data to answer the research conclusions and future work this study proposed an initial quality model that serves as a reference framework for instructors for qualitative uations of uml models developed from gamified the application of an empirical study with participants was carried out to understand their vision in relation to gamification and the acceptance of the proposed it was identified that most have not yet used gamification in their but agree that their use can contribute to the quality of the models developed by the dents and were open to using the our findings can enhance the adoption of new teaching practices through ing in the improvement of software modeling learning using and consequently the creation of models developed by these approaches can stimulate immersion in the design of systems as future professionals during we hope to carry out in the future a series of experimental studies to analyze each stage of application of the modelgame and that this work represents a first step to better support the application of empirical studies on models of evaluation of the use of gamification in software we also hope that the questions described throughout the article will encourage other researchers to extend our study to different modeling languages and teaching	['[1] Rick Adcock, Edward Alef, Bruce Amato, Mark Ardis, Larry Bernstein, Barry Boehm, Pierre Bourque, John Brackett, Murray Cantor, Lillian Cassel, et al. 2009. Curriculum guidelines for graduate degree programs in software engineering. ACM. ', '[2] Mark Ardis, David Budgen, Gregory W Hislop, Jeff Offutt, Mark Sebern, and Willem Visser. 2015. SE 2014: Curriculum guidelines for undergraduate degree programs in software engineering. Computer 48, 11 (2015), 106–109. ', '[3] Valerio Cosentino, Sébastien Gérard, and Jordi Cabot Sagrera. 2017. A model- based approach to gamify the learning of modeling. CEUR Workshop Proceed- ings. ', '[4] Daniel de Paula Porto, Gabriela Martins de Jesus, Fabiano Cutigi Ferrari, and Sandra Camargo Pinto Ferraz Fabbri. 2021. Initiatives and challenges of using gamification in software engineering: A Systematic Mapping. Journal of Systems and Software 173 (2021), 110870. ', '[5] Sebastian Deterding, Miguel Sicart, Lennart Nacke, Kenton OHara, and Dan Dixon. 2011. Gamification. using game-design elements in non-gaming contexts. In CHI11 extended abstracts on human factors in computing systems. 2425–2428. ', '[6] Ana Fernández-Saez et al. 2012. A systematic literature review on the quality of UML models. J. Data. Manage 22, 3 (2012), 46–70. ', '[7] Kleinner Farias et al. 2012. Evaluating the impact of aspects on inconsistency detection effort: a controlled experiment. In International Conference on Model Driven Engineering Languages and Systems. Springer, 219–234. ', '[8] Kleinner Frias et al. 2014. Towards a quality model for model composition effort. In 29th Annual ACM Symposium on Applied Computing. 1181–1183. ', '[9] Kleinner Farias et al. 2015. Evaluating the effort of composing design models: a controlled experiment. Software & Systems Modeling 14, 4 (2015), 1349–1365. ', '[10] Kleinner Farias et al. 2019. UML2Merge: a UML extension for model merging. IET Software 13, 6 (2019), 575–586. ', '[11] Juho Hamari, Jonna Koivisto, and Harri Sarsa. 2014. Does gamification work?– a literature review of empirical studies on gamification. In 2014 47th Hawaii international conference on system sciences. Ieee, 3025–3034. ', '[12] Mantas Jurgelaitis, Vaidotas Drungilas, and Lina Čeponien˙e. 2018. Gamified Moodle course for teaching UML. Baltic journal of modern computing 6, 2 (2018), 119–127. ', '[13] Barbara A Kitchenham and Shari L Pfleeger. 2008. Personal opinion surveys. In Guide to advanced empirical software engineering. Springer, 63–92. ', '[14] Christian Franz Josef Lange. 2007. Assessing and Improving the Quality of Modeling: A series of Empirical Studies about the UML. (2007). ', '[15] Odd Ivar Lindland, Guttorm Sindre, and Arne Solvberg. 1994. Understanding quality in conceptual modeling. IEEE software 11, 2 (1994), 42–49. ', '[16] Nikola Marangunić and Andrina Granić. 2015. Technology acceptance model: a literature review from 1986 to 2013. Universal access in the information society 14, 1 (2015), 81–95. 108', '[17] Beatriz Marín. 2021. Lessons Learned About Gamification in Software Engineer- ing Education. In Latin American Women and Research Contributions to the IT Field. IGI Global, 174–197. ', '[18] Kleinner Oliveira, Alessandro Garcia, and Jon Whittle. 2008. On the quantitative assessment of class model compositions: An exploratory study. 1th ESMDE at MODELS (2008). ', '[19] OMG. 2017. UML: Infrastructure specification. https://www.omg.org/spec/UML/2.5.1/PDF. ', '[20] Sofia Ouhbi and Nuno Pombo. 2020. Software Engineering Education: Challenges and Perspectives. In IEEE Global Engineering Education Conference. 202–209. ', '[21] Oscar Pedreira, Félix García, Nieves Brisaboa, and Mario Piattini. 2015. Gamifica- tion in software engineering–A systematic mapping. Information and software technology 57 (2015), 157–168. ', '[22] Pedro Rodrigues, Mauricio Souza, and Eduardo Figueiredo. 2018. Games and gamification in software engineering education: A survey with educators. In 2018 IEEE Frontiers in Education Conference (FIE). IEEE, 1–9. ', '[23] Kevin Werbach and Dan Hunter. 2012. For the win: How game thinking can revolutionize your business. Wharton digital press. ', '[24] Claes Wohlin, Per Runeson, Martin Höst, Magnus C Ohlsson, Björn Regnell, and Anders Wesslén. 2012. Experimentation in software engineering. Springer Science & Business Media. ', '[25] Alfa Yohannis. 2016. Gamification of Software Modelling Learning.. In DS@ MoDELS. 109']
9	https://drive.google.com/file/d/1XTirfueIs87YbN4f27tmRaUwMu5uoPdQ/view?usp=drive_link	2005-05-15	How to Teach Software Modeling	['Tetsuo Tamai']	['Graduate School of Arts and Sciences, The University of Tokyo, Japan']	['software modeling', 'software engineering education', 'UML']	To enhance motivation of students to study software engineering, some way of ﬁnding balance between the scientiﬁc aspect and the practical aspect of software engineering is required. In this paper, we claim that teaching multiple software modeling techniques from a uniﬁed viewpoint is a good way of obtaining the balance and attracting the students interest as well.	introduction software engineering education at universities faces a common that is regular students do not usually have experience of developing software for practical use and thus are not motivated for software engineering aiming at high quality software production by a project team or a persistent software projects conducted by students simulating real scale software development may help enhance students although it requires a lot of efforts to prepare such projects and manage another way of solving this problem is to teach those who ready have real experience in in our there are rently ﬁve students under the authors supervision who are working at companies as well as doing research in our as a interactions between the students and the other regular students stimulate each particularly ing the regular students to practical software too much emphasis on practicality may bring negligence to scienceand technology and may generate a good balance between the scientiﬁc aspect and the practical aspect of software engineering should always be in our teaching various software modeling techniques is a good way to achieve balanced software engineering it is needless to say that model is a key concept and modeling is an essential skill in software there are a variety of eling some are intuitive and quite accessibleto while some are highly sophisticated and attract theory oriented dents and in this we would like to show that it is effective to teach multiple modeling techniques from a uniﬁed it is based on our experience of teaching software engineering courses at eral universities in the author published a textbook on software speciﬁcally focused on software ing it is written in the book covers the whole area of software including testing and evolution but the modeling part has a role of attracting ests of intelligent who may not have much experience in developing real scale software it also gives a consistent viewpoint penetrating through various techniques employed in ferent stages of software modeling techniques in software models are used for various life cycle process project product quality domain requirements design object data in the we basically focus on requirements and design models but most of the discussionswill hold for other kinds of teaching modeling is almost equal to teaching els are constructed through capturing the crucial properties and structure of the abstracting away irrelevant learning how to model is a good training for mastering graph representation of models many software models are represented with wide ceptance of uml symbolizes the trend that diagrams are often ferred to textual among many types of graph structured diagrams are by far the most widely the reasons may be as a most fundamental way for human mind to understand the world is by regarding it as consisting of a set of conceptual units and a set of relations between conceptual units can be naturally illustrated with boxes or circles or whatever closed ﬁgures and relations can be illustrated with lines or rows connecting such corresponding to vertices and edges of it is easy to draw graph structured diagrams by hand or with drawing concepts and algorithms of the graph theory are available and often useful in analyzing models represented by a typical example is reasoning on transitive relations by ing along paths of the concept of subgraph is highly useful in models or ing a number of models share the same structure of table shows graph structures of some typical table graph structures of typical models model vertex edge data ﬂow process data ﬂow er entity relationship state transition state transition jsd process data stream connection state vector connection activity activity control ﬂow petri net transition ﬁre and token ﬂow commonality and difference between models it is pedagogical to let students notice the common structure shared by a number of the apparent resemblance often causes such confusion can be observed not only in software modeling graphs but in many diagrams found in daily proposals and other it is often the case that one vertex denotes a type of things and other denotes quite a different type on the same diagram or one type of edges with edges with different it is important to make students consciously aware the differences between different we often experience that when we let students draw data ﬂow diagrams who appear to have understood the data ﬂow model the diagrams turn out to be thing like control ﬂow to show the it is instructive to categorize models resented by there are two static an edge connecting vertex a and vertex b represents a tion between a and when the edge is it means and b are in some and when it means has a relation with typical examples include entity relationship class diagram and semantic dynamic an edge from vertex a to b denotes a move from a to the edge in this case is always there are two the case where a view of control moves from a to examples are control ﬂow model and state transition the case where data or objects ﬂow from a to ples are data ﬂow work ﬂow and portation ﬂow static models and dynamic models may not be easily confused but confusion betweendifferent dynamic models are often data ﬂow and control ﬂow or state transition and activity since graphs are intuitively their semantics are apt to be understood ambiguously or uml uml diagrams can also be viewed in terms of graph table shows graph structures of ﬁve uml table graph structures of uml diagrams diagram vertex edge class diagram class association state machine state transition activity diagram activity control ﬂow collaboration diagram object message ﬂow sequence diagram message message ﬂow anchor point it is usually not desirable to teach uml per uml is a lection of miscellaneous diagrams and its speciﬁcation is ously for the pedagogical uml had better be regarded as a catalogue of analysis and design collected around diagrammatic diagrams should be selected according to the policy of how to teach modeling each uml diagram contains overly rich which times blur the essential property of the for the activity diagram is essentially a control ﬂow diagram but it also cludes a notation for data ﬂow from the stance of phasizing differences between various it is not appropriate to include such ad hoc by the same the oration diagram renamed to in uml is explained to have the equivalent semantics as the sequence but if that is the signiﬁcance of the collaboration diagram is considerably the author prefers to regard it as showing collaboration relations between integrating a set of different sequence conclusion software modeling is important by itself but teaching modeling in the software engineering course has at least two additional one is to give a view to the whole software neering through the standpoint of modeling the other is to attract interest of good students who may not have much rience in developing a software but possess intelligence and will to attack complexity of modern software	['[1] T. Tamai. Foundations of Software Engineering. Iwanami Shoten, Tokyo, Japan, 2004. in Japanese. 610']
11	https://drive.google.com/file/d/1x66K3EUa-cfgjzFZNBAmv8YYTvhNdr1N/view?usp=drive_link	2013-07-02	A Prototype Implementation of an Orthographic Software Modeling Environment	['Colin Atkinson', 'Dietmar Stoll', 'Christian Tunjic', 'Jacques Robin']	['University of Mannheim, Germany', 'University of Mannheim, Germany', 'University of Mannheim, Germany', 'Universidade Federal de Pernambuco, Recife, Brasil']	['Orthographic Software Modeling', 'View-based Modeling']	Orthographic Software Modeling (OSM) is a view-centric software engineering approach that aims to leverage the orthographic projection metaphor used in the visualization of physical objects to visualize software systems. Although the general concept of OSM does not prescribe specific sets of views, a concrete OSM environment has to be specific about the particular views to be used in a particular project. At the University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views defined by the KobrA 2.0 method, a version of KobrA adapted for OSM. In this paper we provide an overview of the KobrA 2.0 metamodel underpinning nAOMi and give a small example of its use to model a software system.	introduction orthographic software modeling is based on three fundamental hypotheses that it is feasible to integrate the many different kinds of artifacts used in contemporary software engineering methods within a single coherent methodology in which they are treated as that it is feasible to create an efficient and scalable way of supporting these views by generating them from a single underlying model using transformations and that it is feasible to provide an intuitive metaphor for navigating around these many views by adapting the orthographic projection technique underpinning the cad tools used in other engineering figure orthographic as shown in figure the main advantages of using the idea of orthographic projection to define the views used to visualize and described a system are that they can be organized according to a simple and metaphor and collectively represent all the properties of a system with minimal overlap and in practice this translates into a set of each containing well defined choices so called dimension that can be used to select individuals as shown in figure the main advantage of making the artifacts used to describe a software system views of a sum is that the number of pairwise coherence relationships that have to be maintained is reduced and new views can be introduced by simply defining their relationship to the the importance of this advantage grows quickly as the size of the system and the complexity of the deployed development methodology another important advantage is that the dominance of one particular kind of view over the development process at the expense of other kinds of views graphical is reduced so that any appropriate type of views can be used to enrich the underlying description of the depending on the needs and skills of the stakeholder this makes it possible to subsume all view types under the overarching sum sum view centric environment artifact tools centric environment figure consistency dependencies in versus ing development process and methodology focusing on small development or based on transformations between abstraction although the details of how the views are created from the sum and how the sum is updated from the views are not central to the a natural implementation is to use the visualization and transformation technologies oﬀered by model driven software engineering to explore the validity of these hypotheses at the versity of mannheim we have been developing a prototype osm modeling environment based on an enhanced version of the kobra method for kobra this was chosen as a basis for the known as the orthographic modeling environment because its views were designed with the precise goals of being genuine jections of a subject containing carefully selected subsets of information about that minimalistic in the sense that they should overlap to the smallest extent possible and contain the minimum necessary models and selectable via a set of independent which reﬂect diﬀerent fundamental concerns of development abstraction composition or in other kobra already provided one of the sets of views for visualizing software systems of any rary more details about the actual views and mensions deﬁned in kobra are presented in the following more information on osm can be found in and naomi is implemented as an eclipse plugin using the eclipse modeling framework as the underlying eling platform and uml tools to generate and edit the kobra metamodel on which the current version of naomi is based is a specialization of the uml metamodel composed of three separate packages one for the one for the views and one for the transformations the uml was chosen as the base language cause of its maturity and widespread making the environment usable to the largest possible body of uml elements not needed in kobra are excluded using ocl constraints while new elements or properties are transformation sum views figure kobra top level introduced by specializing existing the unique contribution of this paper is to elaborate on the structure of the kobra metamodel and how it is used to drive the three following sections each focus on one of the three main components of the metamodel the the views and the transformations this is followed by a brief overview of the osm navigation paradigm in tion before a small example of the approach is presented in section section then concludes the paper with related and future sum package figure depicts the internal structure of the sum age which is based on the uml there are three main two containing the structural and ioral constructs and one containing the straints that ensure that the metaclasses are used according to the kobra conventions and the classes subpackage of the structure package contains some of the most fundamental elements of the kobra such as class and the internal structure of this package is illustrated in figure ponentclass represents objects with complex and reusable while class captures simple objects that have only very simple or the modeler has to decide whether it is necessary to model a speciﬁc part of the system as a componentclass and include state charts and activity or whether it is suﬃcient to use a class is limited to using ocl componentclass inherits via from munications so it also has the isactive this makes figure kobra sum it possible to model whether its instances are active or active which can be used to model threads and processes start to execute their behavior as soon as they are created and perform operations a componentclass may exhibit complex in this behavior may be speciﬁed in the form of uml state diagrams acceptable operation invocation and in the form of activities algorithms of uml interaction elements sequence can be derived from the activity elements and thus are not included in the as kobra aims to facilitate automatic checking of allowed sequences of operation protocol state machines are supported instead of general state since the latter include a large variety of elements not needed for specifying acceptable operation quences or automatic ocl constraints are used to prohibit the use of unwanted context componentclass only allow activity elements or protocolstatemachines ownedbehavior or ocliskindof protocolstatemachine for since kobra has no concept of roles for the use of role also needs to be the part association refers to owned properties of components whose attribute iscomposite is as kobra uses associations like nests and creates for required and provided are not connectors delegation and are not used in kobra either so ownedconnector is class generalizationset associationclass componentclass property usage association operation packageable element parameter acquires creates nests figure kobra classes context componentclass role ownedconnector collaborationuse representation views package the structure of the views package is illustrated in figure since most of the views deﬁned in kobra are based on uml the view metamodels have similar elements to the sum the big diﬀerence to the sum is that there are no restrictions on the use of the view metamodel for views for a particular purpose such as supporting model checkers can be supported by adding elements unrelated to the the substructure of the views package reﬂects the types and organization of the kobra views according to the view supported in naomi example in section at the top the views package is thus decomposed into the speciﬁcation and realization options of the sulation in turn are both decomposed into the behavioral and operational options of the projection with the exception of the behavioral these are also all subdivided into the service and type options of the granularity this with its two is an addition to the original version of the service view shows the publicly visible tionships of the subject componentclass to other while the type view shows the publicly ble relationships of the subject to simple as with the constraints have been deﬁned to control what can go into each view and when they are well for ery a constraint enumerates all allowed elements shown in this in the some of the other constraints for the service view are since this view is a the internals of componentclasses are not context componentclass no nested classifiers no protocol nestedclassifier classes are only allowed if they are generalizations of any of its since a nentclass may inherit from a class as shown in the straints with context the following invariants ensure that only publicly visible attributes and operations are in this for both classes and componentclasses inherit from class service type instance service type structural specification operational service type protocol behavioral componentclassdependencies operationdependencies instance service type class service type structural realization operational service type behavioral algorithm views concretesyntax subject figure kobra views package context class only allow classes that are direct or indirect generalizations of componentclasses in this view ccgeneralization generalization ocliskindof componentclass generalization oclistypeof ccgeneralization or ccgeneralization only public attributes in this view ownedattribute only public operations are allowed in the specification ownedoperation only operation signatures are shown in this so and as well as activities are which is reﬂected in the last context operation only the signature of the operation is shown not its behavior name refers to the activities of the or dependencies method precondition postcondition transformations package the package allviews provides the foundation for fying the transformations between the sum and the views in both part of the contents are shown in figure the abstraction concept is in fact a abstraction transformationexpression viewelement sumelement view ressioninocl figure transformation dependency reused from the uml but with additional plays the key role in relating elements from the sum to elements of a abstraction is actually mapped to when appearing in the equals sign links elements in the sum to the respective elements in the and vice for ity of the general of a generalization in a transformation invariant means when following there must be an element in the sum and in the view for which similar transformation expressions are in the case of kobra which has many projections that just select a subset of elements using this allows concise declarative together with the view a case tool can be implemented which uses a transformation language of the for instance the atlas transformation language or qvt the role names se and ve are short for sumelement and these roles subset the client and supplier roles from the sum elements are translated into uml elements with so that the views are easy to manage for velopers familiar with the the bidirectional mappings between stereotyped view elements and sum elements are expressed in the constraints of the a subclass of the abstraction from the allviews this is also an example of a transformation which is reused in other context associationabstraction navigableownedend navigableownedend implies hasstereotype hasstereotype implies ocliskindof implies hasstereotype nests hasstereotype implies ocliskindof ocliskindof implies hasstereotype hasstereotype implies ocliskindof figure shows the main elements involved in the formation of the black box structural view for the ﬁrst transformation constraint is on the view and declares the starting point for the it states that the subject componentclass and its tions a sum utility are in the the following transformation rules illustrate how to create the output elements from the input such as the publicly visible attributes and operations of the componentclass and the acquired the ﬁrst constraint for componentclassabstraction states that references to potential general classes of componentclasses are mirrored in the in componentclasses will be shown with the sponding the componentclass owns various types of so in this view only the acquires ciations are selected transformation rules are ered in the common transformation classes and only publicly visible attributes and operations appear in the class invariants are also classes that may appear in this view as alizations of may have a powertype name which will be the last transformation statement copies the class ences of as with all the transformation the common transformation statements also cover and the view constraints serve as a ﬁcation for the implementation of a individual case tools can use diﬀerent implementation techniques as long as they conform to the semantics of these rules and componentclassabstraction operationabstraction classabstraction figure transformation to the speciﬁcation structural service context views subject specificationstructuralclassservice ownedmember superclosure context componentclassabstraction superclass hasstereotype implies hasstereotype and ocliskindof association ocliskindof context classabstraction ownedattribute visibility ownedoperation visibility copy powertypeextent that is only allowed for class powertypeextent powertypeextent context operationabstraction for the black box type only publicly visible tributes and operations of classes opposed to used by the subject can be this is iﬁed in the ﬁrst rule which deﬁnes owned members of the view and thus serves as the starting point of the cbbtypes is a utility function deﬁned in the sum which computes the black box types by selecting the types of the public attributes and parameter types of its public class invariants and potential powertypes and connections to the classes in this view are shown as there may also be for which the enumerationliterals are the transformation rules for this view are almost the same as the realization transformation constraints from the age the diﬀerences are the statements for operations and context views subject specificationstructuralclasstype ownedmember or or ocliskindof subject context componentclassabstraction implies hasstereotype context classabstraction not componentclass implies ownedattribute visibility ownedoperation visibility powertypeextent powertypeextent superclass context componentclassabstraction implies hasstereotype context enumerationabstraction ownedliteral ownedliteral context enumerationliteralabstraction specification specification stringinsignature navigation most of tools use some combination of trees to organize the content of models as well as the views used to visualize a software system or in an any ronment incorporating a number of diﬀerent tools there is invariably a large number of diﬀerent trees storing a erogeneous mix of artifacts including model elements diagrams class state and other artifact types xml conﬁguration ﬁles to work with all the views in a traditional development engineers typically have to learn about the organization structures of all the incorporated in contrast to conventional paradigms for organizing and navigating the many views used to visualize a osm employs the metaphor of a more as illustrated in figure osm regards sion of the underlying methodology as representing a ent dimension of the and each independently variable aspect of that dimension is a selectable dimension selecting a view thus simply corresponds to selecting a single cell within the in three types of dimensions are static dimensions in which the number of figure selectable elements is dynamic mensions in which the number of elements is dynamic derived from the and mixed dimensions which have both static and dynamic to support the osm dimension based navigation metaphor for we deﬁned the seven dimensions indicated on the left hand side of figure which is a sceenshot of the abstraction dimension expanded which has three static dimension pim independent psm speciﬁc and captures the development concern of the sion dimension captures the state of the modeled system at speciﬁc points in the component which has dynamic dimension elements deﬁned by instances of the class componentclass in the captures the based development concern of the encapsulation which has two ﬁxed supports the distinction between speciﬁcation and realization views of while the projection dimension with the ﬁxed elements operational and behavioral covers the diﬀerent information the granularity dimension provides a ﬁner grained distinction between views describing the types used by ponents and views describing the required and provided interfaces the tion dimension allows a selection of individual in the ideal when all views are truly the choices that can be made in each dimensions are completely this is very diﬃcult to achieve in software the approach still works if the views are not completely but dependencies then occur between diﬀerent choices in diﬀerent so that the decisions made in one dimensions may aﬀect choices ble in another this is best handled by giving dimensions a precedence ranking determined by the order in which they appear top being the when an element in a dimension is the tool automatically makes default selections for dimensions of lower precedence dimensions lower and disables selections that would navigate to cells which are not ﬁned by the method at shopping cart example to show how a software system can be speciﬁed using this section presents a case study based on a ping cart a shoppingcart component collects and figure speciﬁcation structural manages the products selected by users and supports ment via a credit figure illustrates a structural view of the in the dimension navigator on the left hand pim was chosen for the expanded in the the second dimension is the state of the ware system at a certain point in the picture shows that the latest available version was as with every choice in a it may inﬂuence the options in lower ranked the component under consideration is the for which a black box view is selected in the next after the user selects the structural projection option and the service level the tool automatically chooses the option for all operations in the last as there is no editor registered for the other the component under development is presented with the stereotype subject and its relationship to other components and classes is shown in the which corresponds to a cell of the navigation and is generated from the sum when it is the classes product and creditcard can be used as data types in the operations of the figure illustrates the operational view in which an operation can be formalized using and the precondition corresponds to the assumes clause in and the postcondition corresponds to the result as in the the precondition of an operation must be true when the operation is invoked and the postcondition must be true when the operation is the operation addproduct in figure must be in state collectingproducts or empty when this is also visible in the behavioral figure operation since there are only two transitions with the operation both leads to the state collectingproducts which is also a postcondition of the the second condition is that the cost attribute of the component must be increased by the price of the added the and postcondition can be expressed using the the ties of the states and operation parameters can be used to formalise the constraints like as in this figure shows the publicly visible behaviour of the pingcart component with states and the tional transitions map to operations of the like every this view is also synchronized with the sum so that it is guaranteed that its states and ties are consistent with those in the structural figure speciﬁcation behavioral although the operational view seems to be similar to the behavioral view because of the overlapping information within there are signiﬁcant the focus of the erational view is on a precise formal deﬁnition of an tion of a the operations can be enriched by and postconditions which can be deﬁned using complex ocl that formalize the complete behavior of an the additional information in the ocl statements can be used for code generation and conclusion at the beginning of the paper we identiﬁed three mental hypothesis upon which the notion of osm is based that it is feasible to integrate the many diﬀerent kinds of artifacts used in contemporary software engineering ods within a single coherent methodology in which they are treated as that it is feasible to create an cient and scalable way of supporting these views by ating them from a single ing model using transformations and that it is feasible to provide an intuitive metaphor for navigating around these many views by adapting the graphic projection technique underpinning the cad tools used in other engineering the prototype described in this paper resents the ﬁrst step towards demonstrating the validity of these hypotheses and showing that osm is a viable approach to software of the three and are most convincingly demonstrated by the since it shows that it is indeed possible to support all the views of the kobra method within a single navigation the prototype tool does not demonstrate the validity of pothesis to the same extent as the others due to its small although it demonstrates the feasibility of erating views from the sum and the question of whether such an approach scales up to large environments is still although noami is the only tool developed with the ciﬁc aim of supporting several other tools and methods have similar properties or for glinz et describe a tool with a ﬁsheye zooming algorithm which lets the user view a model with varying amounts of detail depending on the it has to be investigated whether it is possible to combine the eye zooming concept with the navigation while the kobra implementation of naomi heavily uses uml diagrams for glinz et use custom diagram for structural and behavioral an approach which also emphasizes the description of mal consistency rules between views is this approach does not itly mention the notion of a sum and thus implies that consistency rules should be deﬁned in a pairwise fashion tween individual pairs of archimate which plements togaf is an enterprise architecture eling language which oﬀers two orthogonal for and layers and behavioral and aspects and also suggests two more purpose and abstraction as many of these views span multiple choices of a the intuitive navigation metaphor of osm can not be easily there are also more general approaches for modeling but they are less speciﬁc in terms of consistency rules between views and provide little guidance on how to manage and navigate for example the zachman framework regarding the practical use of osm environments in the the biggest challenge is developing appropriate sum metamodels which can accommodate all the types of views and services that software engineers are accustomed to for this ﬁrst prototypical environment porting the osm approach we had a method at our disposal that already deﬁned a full set of orthogonal based this allowed us to model the required sum and view metamodels by simply adapting the uml removing and adding model elements as in doing so we were able to manually ensure that the models fulﬁlled the two core requirements of vironments being minimalistic and redundancy if software engineering environments are to take and to be introduced into neous more sophisticated ways of integrating existing metamodels into a single uniﬁed metamodel will be	['[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties, O. Laitenberger, R. Laqua, D. Muthig, B. Paech, J. W¨ust, and J. Zettel. Component-Based Product Line Engineering with UML. Addison Wesley, Reading, Massachusetts, USA, 1st edition, November 2001. ', '[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic Software Modeling: A Practical Approach to View-Based Development. In Evaluation of Novel Approaches to Software Engineering, volume 69 of Communications in Computer and Information Science, pages 206–219. Springer Berlin Heidelberg, 2010. ', '[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic Service Modeling. In Proceedings of 15th IEEE EDOC Conference Workshops (EDOCW), Helsinki, Finland, 2011. ', '[4] Eclipse Foundation. UML2Tools. http://wiki.eclipse.org/MDT-UML2Tools, 2013. ', '[5] ISO/IEC and ITU-T. The Reference Model of Open Distributed Processing. RM-ODP, ITU-T Rec. X.901-X.904 / ISO/IEC 10746. http://standards.iso.org/ ittf/PubliclyAvailableStandards/index.html, 1998. ', '[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing Correspondences in MultiViewpoint Speciﬁcations. In Proceedings of the Thirteenth IEEE International EDOC Conference, 1 - 4 September 2009, Auckland, New Zealand, September 2009. ', '[7] M. Lankhorst. Enterprise Architecture at Work. Springer Berlin Heidelberg, 2009. ', '[8] Object Management Group (OMG). OMG Uniﬁed Modeling Language (OMG UML), Superstructure, V2.1.2. http://www.omg.org/cgi-bin/doc?formal/07-11-02, November 2007. ', '[9] Object Management Group (OMG). Meta Object Facility (MOF) 2.0 Query/View/Transformation, v1.0. http://www.omg.org/spec/QVT/1.0/PDF/, April 2008. ', '[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett. An eﬀective layout adaptation technique for a graphical modeling tool. In Proceedings of the 2003 International Conference on Software Engineering, Portland, 2003. ', '[11] The Atlas Transformation Language (ATL). Oﬃcial Website. http://www.eclipse.org/atl/, 2013. ', '[12] The Open Group. TOGAF Version 9 - The Open Group Architecture Framework. http://www.opengroup.org/architecture/ togaf9-doc/arch/index.html, Feb 2009. ', '[13] University of Mannheim - Software Engineering Group. nAOMi - opeN, Adaptable, Orthographic Modeling EnvIronment. http://eclipselabs.org/p/naomi. ', '[14] J. A. Zachman. The Zachman Framework: A Primer for Enterprise Engineering and Manufacturing. http://www.zachmaninternational.com, 2009.']
12	https://drive.google.com/file/d/1ebEJoXOv09wa6x9RIDCCF1hsMLB27odU/view?usp=drive_link	2023-09-18	Large Language Model Augmented Narrative Driven Recommendations	['Sheshera Mysore', 'Andrew McCallum', 'Hamed Zamani']	['University of Massachusetts Amherst USA', 'University of Massachusetts Amherst USA', 'University of Massachusetts Amherst USA']	['Narrative-driven recommendation', 'Information systems', 'Recommender systems', 'Users and interactive retrieval', 'Computing methodologies', 'Natural language generation']	Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context – this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with few-shot prompting and train retrieval models for NDR on synthetic queries and user-item interaction data. Our experiments demonstrate that this is an effective strategy for training small-parameter retrieval models that outperform other retrieval and LLM baselines for narrative-driven recommendation.	introduction recommender systems personalized to users are an important component of several platforms these systems function by inferring users interests from their prior interactions on the platform and making recommendations based on these inferred while recommendations based on historical interactions are users soliciting recommendations often start with a vague idea about their desired target items or may desire recommendations depending on the context of often missing in historical interaction data in these it is common for users to solicit recommendations through narrative queries describing their broad interests and information access tasks like these have been studied as recommendations for items ranging from books and movies to points of interest bogers and koolen note these narrative requests to be common on discussion forums and several there is a lack of support for these complex natural language queries in current with the emergence of conversational interfaces for information access support for complex ndr tasks is likely to become in this recent work has noted an increase in complex and subjective natural language requests compared to more conventional search interfaces the emergence of large language models with strong language understanding capabilities presents the potential for fulfilling such complex requests this work explores the potential for historical recommendation traditionally used for training collaborative filtering with llms to support given a users with items and their accompanying text documents 𝐷𝑢 selected from a interaction dataset we prompt a parameter to author a synthetic narrative query 𝑞𝑢 based on 𝐷𝑢 since we expect the query 𝑞𝑢 to be noisy and not fully representative of all the user 𝐷𝑢 is filtered to retain only a fraction of the reviews based on a assigned likelihood of 𝑞𝑢 given a user a lm based retrieval model is for retrieval on the synthetic queries and filtered our which we refer to as follows from the observation that while narrative queries and suggestions are often made in online discussion and could serve as training the number of these posts and the diversity of domains for which they are available is significantly smaller than the size and diversity of passively gathered interaction while bogers and koolen note nearly narrative requests for books on the librarything discussion a publicly available interaction dataset for goodreads contains interactions with nearly books by users we empirically evaluate mint in a publicly available test collection for point of interest pointrec to train data augmentation with interaction recsys september singapore zamani figure an example narrative query soliciting point of interest the query describes the users preferences and the context of their figure the format of the prompt used in mint for generating synthetic narrative queries from interaction with a large language our ndr we generate synthetic training data based on interaction datasets from models trained with mint significantly outperform several baseline models and match the performance of significantly larger llm baselines autoregressively generating code and synthetic datasets are related work data augmentation for information a line of recent work has explored using language models to generate synthetic queries for data augmentation to train models for information trieval tasks given a document collection of a language model is used to create synthetic queries for the document an optional filtering step cludes noisy and a or a is trained for the retrieval while earlier work of ma et train a custom query generation model on more recent work has leveraged large language models for question generation in generating synthetic this work indicates the effectiveness of smaller parameter llms to for generating synthetic queries in simpler tasks and finds larger models parameters and to be necessary for harder tasks such as argument retrieval similar to this we explore the generation of synthetic queries with llms for a retrieval like this we demonstrate a data augmentation method for creating effective training data from sets of user documents found in recommendation datasets rather than individual other work in this space has also explored training more efficient vector models from synthetic queries instead of more expensive models and generating queries with a diverse range of intents than the ones available in implicit feedback datasets to enhance item retrievability besides creating queries for retrieval concurrent work of leszczynski et has also explored the creation of thetic conversational search datasets from music recommendation datasets with the synthetic queries and user documents are then used to train retrieval models for conversational our work resembles this in creating synthetic queries from sets of user items found in recommendation interaction it differs in the task of creating tive queries for our work also builds on the recent perspective of radlinski et who make a case for natural language user profiles driving recommenders narrative requests tie closely to natural language user our work presents a step toward these while our work explores data augmentation from item interactions for a ndr prior work has also explored data augmentation of the graph for training collaborative filtering this work has often explored mentation to improve recommendation performance for minority or users and has leveraged tive models and text similarity models for augmenting the complex queries in information with the advent of performant models for text focus on complex and interactive information access tasks has seen a resurgence ndr presents an example of this ndr was first formalized in bogers and koolen for the case of book dation and subsequently studied in other domains bogers and koolen systematically examined narrative requests posted by users on discussion they defined ndr as a task ing item recommendation based on a narrative query and item while this formulation resembles personalized search and recommendation the length and complexity of requests differentiate these from other work has also demonstrated the effectiveness of initial recommendations from collaborative filtering approaches large language model augmented narrative driven recommendations recsys september singapore figure mint readily available interaction datasets commonly used to train collaborative filtering models for this is done by authoring narrative queries for sets of items liked by a user with a large language the data is filtered with a smaller language model and retrieval models are trained on the synthetic queries and user based on the narrative query more recent work of afzali et formulate the ndr task without access to the prior interactions of a user while also noting the value of contextual cues contained in the narrative in our we focus on this latter mulation of given the lack of focus on effectively using the rich narrative queries in most prior we demonstrate the usefulness of data augmentation from llms and interaction datasets lacking narrative besides a range of work has explored more and interactive query formulations for information these resemble queries in arguello et define the tip of tongue retrieval a search task where user queries describe the rich context of items while being unable to recall item metadata mysore et formulate an aspect conditional example task where results must match specific aspects of a long natural language and a vibrant body of work has explored conversational critiquing of recommenders where ural language feedback helps tune the recommendations received by users method problem setup in our we define recommendation to be a ranking where given a narrative query 𝑞 made by a user a ranking system 𝑓 must generate a ranking 𝑅 over a collection of items we assume access to a interaction dataset i consisting of user interactions with items we assume the items 𝑑𝑖 to be textual documents like reviews or item while we assume there to be any overlap in the users making narrative queries or the collection of items c and the interaction dataset we assume them to be from the same broad proposed method our proposed for a dataset of abundantly available i into training data for retrieval models by using llms as query ation models to author narrative queries d retrieval models are trained on the synthetic dataset d ure narrative queries from to author a narrative query 𝑞𝑢 for a user in we make use of the parameter model as our query generation model we include the text of interacted items in the prompt for and instruct it to author a narrative query to improve the coherence of generated queries and obtain correctly formatted we manually author narrative queries for topically diverse users based on their interacted items and include it in the prompt for the same three few shot examples are used for the whole dataset and the three users were chosen from generating narrative queries based on user interactions may also be considered a form of summarization for generating a natural language user profile filtering items for synthetic since we expect user items to capture multiple aspects of their interests and generated queries to only capture a subset of these we only retain some of the items present in before using it for training trieval for we use a language model to pute the likelihood of the query given each user 𝑃𝐿𝑀 and only retain the top 𝑀 highly scoring item for this sults in 𝑀 training samples per user for our ndr retrieval in our we use with ters for computing and follow sachan et for computing 𝑃𝐿𝑀 note that our use of 𝑃𝐿𝑀 represents a likelihood model classically used for search and recently shown to be an effective unsupervised method when used with large language models training retrieval we train and encoder models for ndr on the generated synthetic dataset monly used models in search are commonly used as scalable rankers from a large collection of on the other allow a richer interaction between query and item and are used as for both we use a transformer language model ture with a model similar to bert models embed the query and item independently into high dimensional q𝑢 d𝑖 and rank items for the user based on the minimum distance between recsys september singapore zamani q𝑢 and embeddings are obtained by averaging token embeddings from the final layer of and the same model is used for both queries and models input both the query and item and output a score to be used for ranking 𝑠 where 𝑓cr is parameterized as w𝑇 dropout w𝑇 we train our model with a margin ranking l𝐵𝑖 𝑢 d with randomly pled negatives 𝑑 and 𝛿 our are trained with a l𝐶𝑟 𝑢 𝑒𝑠 for negative example items are randomly sampled from ranks from our trained at test we retrieve the top items with our trained and them with the we evaluate both these components in experiments and refer to them as and experiments and results we evaluate mint on a publicly available test collection for ndr and present a series of experimental setup we perform evaluations on an ndr dataset for recommendation pointrec pointrec contains realistic narrative queries words obtained from discussion forums on reddit and items pooled from baseline the items are annotated on a graded relevance scale by discussion forum members and further dated by the dataset the item collection c in pointrec contains pois with metadata and noisy text snippets describing the poi obtained from the bing search for test time we only rank the candidate items in the city and request category of the query available in pointrec this follows prior practice to exclude clearly irrelevant items we use interaction datasets from yelp to generate synthetic queries for note also that we limit our evaluations to pointrec since it presents the only publicly manually and candidate pooled test collection for to our other datasets for ndr use document lections that are no longer publicly accessible contain sparse and noisy relevance judgments due to them being determined with automatic rules applied to discussion threads lack pooling to gather candidates for judging relevance or lack realistic narrative queries we leave the development of more robust test collections and evaluation methods for ndr to future implementation we describe important details for mint and leave finer details of the model and training to our code to sample user interactions for generating synthetic queries from the yelp we exclude pois and users with fewer than ten reviews to ensure that users were regular users of the site with well represented this follows common prior practice in preparing interaction datasets for use then we retain users who deliver an average rating greater than and with this desirably biases our data to users who commonly describe their likings than it also retains the users whose interests are summarizable by in the yelp this results in retained randomly selected users are chosen for generating thetic narrative for these a single randomly selected sentence from of their reviews is included in the prompt to 𝑁𝑢 after generating synthetic some items are filtered out we exclude of the items for a this results in about training samples for training and these decisions were made ally by examining the resulting datasets and the cost of authoring the expense of generating 𝑞𝑢 was about usd we compare and els against several standard and performant retrieval model these span supervised unsupervised and llm a standard unsupervised sparse retrieval baseline based on term overlap between query and with strong generalization performance across tasks and domains a model for retrieval with weakly pervised pairs a strong bert model initialized with and trained on billion supervised pairs aggregated from ous domains a on supervised pairs from a stage approach that retrieves items with a contriver and the top items with a model using a model with parameters this may be seen as an unsupervised grounded a cently proposed approach which autoregressively ates ten items using an llm prompted with the narrative query and generates tions grounded in c by retrieving the nearest neighbors for each generated item using a we include one example of a narrative query and recommended items in the prompt to the we run this baseline three times and report average performance across we report ndcg at and and recall at and our reported results should be considered lower bounds on realistic performance due to the judged documents at 𝑘 in our test collections results table presents the performance of the proposed method compared against bold numbers indicate the and superscripts indicate statistical significance computed with at 𝑝 we first note the performance of baseline we see outperformed by a transformer model trained for this mirrors prior work we see supervised models trained on similar sage and pairs form a weakly supervised model by smaller the grounded llm outperforms all dicating strong generalization and mirroring prior results examining the mint we first note that the mint sees statistically significant improvement compared to large language model augmented narrative driven recommendations recsys september singapore table performance of the proposed for recommendation on the superscripts denote statistically significant improvements compared to specific baseline pointrec model parameters map mrr llm and outperforms the best baselines by on sion measures and on recall we see a model trained for underperform indicating the challenge of the ndr trained on orders of magnitude lesser data than sees improved performance indicating the quality of data obtained from also performs at par with a llm while offering the inference efficiency of a we see outperform the baseline and grounded llm by on precision measures and on recall measures demonstrating the value of mint for training ndr ablations in table we ablate various design choices in different choices result in different training sets for the bienc and crenc note that in reporting ablation performance for we still use the performant model for obtaining tive examples for training and without quality negative we found crenc to result in much poorer no item since synthetic queries are unlikely to resent all the items of a mint excludes user items which have a low likelihood of being generated from the document without this we expect the training set for training retrieval models to be larger and in table we see that excluding this step leads to a lower performance for bienc and indicating that the quality of data obtained is important for llm for mint relies on using an expensive rameter instructgpt model for we investigate the efficacy for generating𝑞𝑢 for with a parameter gpt model we use an identical setup to the llm for in table we see that training on the synthetic narrative queries of the smaller llm results in worse models ten underperforming the baselines in table this indicates the inability of a smaller model to generate complex narrative queries while conditioning on a set of user this necessity of a larger llm for generating queries in complex retrieval tasks has been observed in prior work llm for item we find a smaller llm to result in poor quality data when used to generate narrative queries ditioned on here we simplify the text generation task using a llm to generate queries for individual items this experiment also mirrors the setup for generating synthetic queries for search tasks we use shot examples and ple one item per user for generating given the lower cost of using a smaller we use all users in our yelp dataset rather than a smaller random from table we see that this results in higher quality queries than using smaller llms for erating narrative queries from the resulting bienc model underperforms the indicating the value of generating complex queries conditioned on multiple items as in mint for we see that crenc approaches the performance of that this approach uses the performant for sampling negatives and first stage we leave further exploration of using small parameter llms for data augmentation for ndr models to future conclusions in this we present a data augmentation method for the recommendation mint historical interaction datasets for ndr by using a rameter large language model to author narrative queries while conditioning on the text of items liked by we evaluate and models trained on data from mint on the publicly available pointrec test collection for point of interest we demonstrate that the ing models outperform several strong baselines and ablated models and match or outperform a llm directly used for ndr in a mint also presents some given our use of historical interaction datasets for generating synthetic training data and the prevalence of popular interests in these datasets tailed interests are unlikely to be present in the generated thetic in causing retrieval models to likely see poorer performance on these our use of llms to generate thetic queries also causes the queries to be repetitive in likely causing novel queries to be poorly these limitations may be addressed in future recsys september singapore zamani table mint ablated for different design choices on pointrec ablation map mrr no item filtering llm for qgen llm for item queries no item filtering llm for qgen llm for item queries besides other avenues also present rich future while mint leverages a llm for generating synthetic smaller parameter llms may be explored for this purpose perhaps by training dedicated qgen mint may also be expanded to explore more active strategies for sampling items and users for whom narrative queries are authored this may allow more cient use of large parameter llms while ensuring higher quality training the generation of synthetic queries from sets of documents may be explored for a broader range of retrieval tasks beyond ndr given its promise to generate larger training sets a currently underexplored given the lack of test collections for ndr and the effectiveness of llms for authoring narrative queries from fruitful future work may also explore the creation of datasets in a setup to robustly evaluate models for acknowledgments we thank anonymous reviewers for their invaluable this work was partly supported by the center for intelligent tion nsf grants and the office of naval research contract number an amazon alexa prize and the chan zuckerberg initiative under the project scientific knowledge base any findings and conclusions or recommendations expressed here are those of the authors and do not necessarily reflect those of the	['[1] Jafar Afzali, Aleksander Mark Drzewiecki, and Krisztian Balog. 2021. POINTREC: A Test Collection for Narrative-Driven Point of Interest Recommendation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (Virtual Event, Canada) (SIGIR 21). As- sociation for Computing Machinery, New York, NY, USA, 2478–2484. https: //doi.org/10.1145/3404835.3463243 ', '[2] Jaime Arguello, Adam Ferguson, Emery Fine, Bhaskar Mitra, Hamed Zamani, and Fernando Diaz. 2021. Tip of the Tongue Known-Item Retrieval: A Case Study in Movie Identification. In Proceedings of the 6th international ACM SIGIR Conference on Human Information Interaction and Retrieval. ACM. https://dlnext.acm.org/ doi/10.1145/3406522.3446021 ', '[3] Toine Bogers, Maria Gäde, Marijn Koolen, Vivien Petras, and Mette Skov. 2018. What was this Movie About this Chick? A Comparative Study of Relevance Aspects in Book and Movie Discovery. In Transforming Digital Worlds: 13th Inter- national Conference, iConference 2018, Sheffield, UK, March 25-28, 2018, Proceedings 13. Springer, 323–334. ', '[4] Toine Bogers, Maria Gäde, Marijn Koolen, Vivien Petras, and Mette Skov. 2019. Looking for an amazing game I can relax and sink hours into...: A Study of Relevance Aspects in Video Game Discovery. In Information in Contemporary Society: 14th International Conference, iConference 2019, Washington, DC, USA, March 31–April 3, 2019, Proceedings 14. Springer, 503–515. ', '[5] Toine Bogers and Marijn Koolen. 2017. Defining and Supporting Narrative-Driven Recommendation. In Proceedings of the Eleventh ACM Conference on Recommender Systems (Como, Italy) (RecSys 17). Association for Computing Machinery, New York, NY, USA, 238–242. https://doi.org/10.1145/3109859.3109893 ', '[6] Toine Bogers and Marijn Koolen. 2018. Im looking for something like...: Combining Narratives and Example Items for Narrative-driven Book Recommen- dation. In Knowledge-aware and Conversational Recommender Systems Workshop. CEUR Workshop Proceedings. ', '[7] Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, and Rodrigo Nogueira. 2022. InPars: Unsupervised Dataset Generation for Information Retrieval. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (Madrid, Spain) (SIGIR 22). Association for Computing Machinery, New York, NY, USA, 2387–2392. https://doi.org/10.1145/3477495. 3531863 ', '[8] Leonid Boytsov, Preksha Patel, Vivek Sourabh, Riddhi Nisar, Sayani Kundu, Ramya Ramanathan, and Eric Nyberg. 2023. InPars-Light: Cost-Effective Unsu- pervised Training of Efficient Rankers. arXiv:2301.02998 ', '[9] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems, H. Larochelle, M. Ran- zato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 1877–1901. https://proceedings.neurips.cc/paper_files/paper/2020/file/ 1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf ', '[10] Chris Buckley and Ellen M. Voorhees. 2004. Retrieval Evaluation with Incomplete Information. In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Sheffield, United Kingdom) (SIGIR 04). Association for Computing Machinery, New York, NY, USA, 25–32. https://doi.org/10.1145/1008992.1009000 ', '[11] Dong-Kyu Chae, Jihoo Kim, Duen Horng Chau, and Sang-Wook Kim. 2020. AR- CF: Augmenting Virtual Users and Items in Collaborative Filtering for Addressing Cold-Start Problems. In Proceedings of the 43rd International ACM SIGIR Con- ference on Research and Development in Information Retrieval (Virtual Event, China) (SIGIR 20). Association for Computing Machinery, New York, NY, USA, 1251–1260. https://doi.org/10.1145/3397271.3401038 ', '[12] Lei Chen, Le Wu, Kun Zhang, Richang Hong, Defu Lian, Zhiqiang Zhang, Jun Zhou, and Meng Wang. 2023. Improving Recommendation Fairness via Data Augmentation. In Proceedings of the ACM Web Conference 2023 (Austin, TX, USA) (WWW 23). Association for Computing Machinery, New York, NY, USA, 1012–1020. https://doi.org/10.1145/3543507.3583341 ', '[13] Li Chen, Zhirun Zhang, Xinzhi Zhang, and Lehong Zhao. 2022. A Pilot Study for Understanding Users Attitudes Towards a Conversational Agent for News Recommendation. In Proceedings of the 4th Conference on Conversational User Interfaces (Glasgow, United Kingdom) (CUI 22). Association for Computing Machinery, New York, NY, USA, Article 36, 6 pages. https://doi.org/10.1145/ 3543829.3544530 ', '[14] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416 (2022). ', '[15] Zhuyun Dai, Vincent Y Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith Hall, and Ming-Wei Chang. 2023. Promptagator: Few-shot 782', '[16] Abhinandan S. Das, Mayur Datar, Ashutosh Garg, and Shyam Rajaram. 2007. Google News Personalization: Scalable Online Collaborative Filtering. In Pro- ceedings of the 16th International Conference on World Wide Web (Banff, Alberta, Canada) (WWW 07). Association for Computing Machinery, New York, NY, USA, 271–280. https://doi.org/10.1145/1242572.1242610 ', '[17] James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, and Dasarathi Sampath. 2010. The YouTube Video Recommendation System. In Proceedings of the Fourth ACM Conference on Recommender Systems (Barcelona, Spain) (RecSys 10). Association for Computing Machinery, New York, NY, USA, 293–296. https: //doi.org/10.1145/1864708.1864770 ', '[18] Lukas Eberhard, Simon Walk, Lisa Posch, and Denis Helic. 2019. Evaluating Narrative-Driven Movie Recommendations on Reddit. In Proceedings of the 24th International Conference on Intelligent User Interfaces (Marina del Ray, California) (IUI 19). Association for Computing Machinery, New York, NY, USA, 1–11. https: //doi.org/10.1145/3301275.3302287 ', '[19] Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan. 2022. Precise Zero-Shot Dense Retrieval without Relevance Labels. arXiv preprint arXiv:2212.10496 (2022). ', '[20] Negar Hariri, Bamshad Mobasher, and Robin Burke. 2013. Query-Driven Context Aware Recommendation. In Proceedings of the 7th ACM Conference on Recom- mender Systems (Hong Kong, China) (RecSys 13). Association for Computing Machinery, New York, NY, USA, 9–16. https://doi.org/10.1145/2507157.2507187 ', '[21] Seyyed Hadi Hashemi, Jaap Kamps, Julia Kiseleva, Charles LA Clarke, and Ellen M Voorhees. 2016. Overview of the TREC 2016 Contextual Suggestion Track.. In TREC. ', '[22] Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bo- janowski, Armand Joulin, and Edouard Grave. 2022. Unsupervised Dense Infor- mation Retrieval with Contrastive Learning. Transactions on Machine Learning Research (2022). https://openreview.net/forum?id=jKN1pXi7b0 ', '[23] Vitor Jeronymo, Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Roberto Lotufo, Jakub Zavrel, and Rodrigo Nogueira. 2023. InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval. arXiv:2301.01820 ', '[24] Marijn Koolen, Toine Bogers, Maria Gäde, Mark Hall, Iris Hendrickx, Hugo Huurdeman, Jaap Kamps, Mette Skov, Suzan Verberne, and David Walsh. 2016. Overview of the CLEF 2016 Social Book Search Lab. In Experimental IR Meets Mul- tilinguality, Multimodality, and Interaction, Norbert Fuhr, Paulo Quaresma, Teresa Gonçalves, Birger Larsen, Krisztian Balog, Craig Macdonald, Linda Cappellato, and Nicola Ferro (Eds.). Springer International Publishing, Cham, 351–370. ', '[25] Megan Leszczynski, Ravi Ganti, Shu Zhang, Krisztian Balog, Filip Radlinski, Fernando Pereira, and Arun Tejasvi Chaganty. 2023. Generating Synthetic Data for Conversational Music Recommendation Using Random Walks and Language Models. arXiv:2301.11489 ', '[26] Xin Liu, Yong Liu, Karl Aberer, and Chunyan Miao. 2013. Personalized Point-of- Interest Recommendation by Mining Users Preference Transition. In Proceedings of the 22nd ACM International Conference on Information & Knowledge Manage- ment (San Francisco, California, USA) (CIKM 13). Association for Computing Ma- chinery, New York, NY, USA, 733–738. https://doi.org/10.1145/2505515.2505639 ', '[27] Yiding Liu, Tuan-Anh Nguyen Pham, Gao Cong, and Quan Yuan. 2017. An Experimental Evaluation of Point-of-Interest Recommendation in Location-Based Social Networks. Proc. VLDB Endow. 10, 10 (jun 2017), 1010–1021. https://doi. org/10.14778/3115404.3115407 ', '[28] Federico López, Martin Scholz, Jessica Yung, Marie Pellat, Michael Strube, and Lucas Dixon. 2021. Augmenting the user-item graph with textual similarity models. arXiv preprint arXiv:2109.09358 (2021). ', '[29] Xing Han Lu, Siva Reddy, and Harm de Vries. 2023. The StatCan Dialogue Dataset: Retrieving Data Tables through Conversations with Genuine Intents. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics, Dubrovnik, Croatia, 2799–2829. https://aclanthology.org/2023.eacl-main.206 ', '[30] Kai Luo, Scott Sanner, Ga Wu, Hanze Li, and Hojin Yang. 2020. Latent Linear Critiquing for Conversational Recommender Systems. In The Web Conference. ', '[31] Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, and Ryan McDonald. 2021. Zero-shot Neural Passage Retrieval via Domain-targeted Synthetic Question Generation. In Proceedings of the 16th Conference of the European Chapter of the Associa- tion for Computational Linguistics: Main Volume. Association for Computational Linguistics, Online, 1075–1088. https://doi.org/10.18653/v1/2021.eacl-main.92 ', '[32] Sheshera Mysore, Tim OGorman, Andrew McCallum, and Hamed Zamani. 2021. CSFCube - A Test Collection of Computer Science Research Articles for Faceted Query by Example. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2). https://doi.org/10.48550/arXiv. 2103.12906 ', '[33] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. In Advances in Neural Information Processing Systems, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (Eds.), Vol. 35. Curran Associates, Inc., 27730–27744. https://proceedings.neurips.cc/paper_files/paper/2022/file/ b1efde53be364a73914f58805a001731-Paper-Conference.pdf ', '[34] Andrea Papenmeier, Dagmar Kern, Daniel Hienert, Alfred Sliwa, Ahmet Aker, and Norbert Fuhr. 2021. Starting Conversations with Search Engines - Interfaces That Elicit Natural Language Queries. In Proceedings of the 2021 Conference on Human Information Interaction and Retrieval (Canberra ACT, Australia) (CHIIR 21). Association for Computing Machinery, New York, NY, USA, 261–265. https: //doi.org/10.1145/3406522.3446035 ', '[35] Gustavo Penha, Enrico Palumbo, Maryam Aziz, Alice Wang, and Hugues Bouchard. 2023. Improving Content Retrievability in Search with Controllable Query Generation. In Proceedings of the ACM Web Conference 2023 (Austin, TX, USA) (WWW 23). Association for Computing Machinery, New York, NY, USA, 3182–3192. https://doi.org/10.1145/3543507.3583261 ', '[36] Filip Radlinski, Krisztian Balog, Fernando Diaz, Lucas Dixon, and Ben Wedin. 2022. On Natural Language User Profiles for Transparent and Scrutable Rec- ommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (Madrid, Spain) (SIGIR 22). Association for Computing Machinery, New York, NY, USA, 2863–2874. https://doi.org/10.1145/3477495.3531873 ', '[37] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Proceedings of the 2019 Conference on Em- pirical Methods in Natural Language Processing. Association for Computational Linguistics. https://arxiv.org/abs/1908.10084 ', '[38] Stephen Robertson and Hugo Zaragoza. 2009. The Probabilistic Relevance Framework: BM25 and Beyond. Found. Trends Inf. Retr. 3, 4 (apr 2009), 333–389. https://doi.org/10.1561/1500000019 ', '[39] Jon Saad-Falcon, Omar Khattab, Keshav Santhanam, Radu Florian, Martin Franz, Salim Roukos, Avirup Sil, Md Arafat Sultan, and Christopher Potts. 2023. UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers. arXiv:2303.00807 [cs.IR] ', '[40] Devendra Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-tau Yih, Joelle Pineau, and Luke Zettlemoyer. 2022. Improving Passage Retrieval with Zero-Shot Question Generation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, 3781–3797. https://aclanthology. org/2022.emnlp-main.249 ', '[41] Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2020. MPNet: Masked and Permuted Pre-training for Language Understanding. In Advances in Neural Information Processing Systems, Vol. 33. https://proceedings.neurips.cc/paper_ files/paper/2020/file/c3a690be93aa602ee2dc0ccab5b7b67e-Paper.pdf ', '[42] Jaime Teevan, Susan T. Dumais, and Eric Horvitz. 2005. Personalizing Search via Automated Analysis of Interests and Activities. In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Salvador, Brazil) (SIGIR 05). Association for Computing Machinery, New York, NY, USA, 449–456. https://doi.org/10.1145/1076034.1076111 ', '[43] Mengting Wan and Julian McAuley. 2018. Item Recommendation on Monotonic Behavior Chains. In Proceedings of the 12th ACM Conference on Recommender Systems (Vancouver, British Columbia, Canada) (RecSys 18). Association for Computing Machinery, New York, NY, USA, 86–94. https://doi.org/10.1145/ 3240323.3240369 ', '[44] Haonan Wang, Chang Zhou, Carl Yang, Hongxia Yang, and Jingrui He. 2021. Controllable Gradient Item Retrieval. In Web Conference. ', '[45] Qinyong Wang, Hongzhi Yin, Hao Wang, Quoc Viet Hung Nguyen, Zi Huang, and Lizhen Cui. 2019. Enhancing Collaborative Filtering with Generative Aug- mentation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (Anchorage, AK, USA) (KDD 19). As- sociation for Computing Machinery, New York, NY, USA, 548–556. https: //doi.org/10.1145/3292500.3330873 ', '[46] Jiajing Xu, Andrew Zhai, and Charles Rosenberg. 2022. Rethinking Personalized Ranking at Pinterest: An End-to-End Approach. In Proceedings of the 16th ACM Conference on Recommender Systems (Seattle, WA, USA) (RecSys 22). Association for Computing Machinery, New York, NY, USA, 502–505. https://doi.org/10. 1145/3523227.3547394 ', '[47] Yuxin Ying, Fuzhen Zhuang, Yongchun Zhu, Deqing Wang, and Hongwei Zheng. 2023. CAMUS: Attribute-Aware Counterfactual Augmentation for Minority Users in Recommendation. In Proceedings of the ACM Web Conference 2023 (Austin, TX, USA) (WWW 23). Association for Computing Machinery, New York, NY, USA, 1396–1404. https://doi.org/10.1145/3543507.3583538 ', '[48] Hamed Zamani, Johanne R Trippas, Jeff Dalton, and Filip Radlinski. 2022. Con- versational information seeking. arXiv preprint arXiv:2201.08808 (2022). ', '[49] Jie Zou, Yifan Chen, and Evangelos Kanoulas. 2020. Towards Question-Based Recommender Systems. In Proceedings of the 43rd International ACM SIGIR Confer- ence on Research and Development in Information Retrieval (Virtual Event, China) (SIGIR 20). Association for Computing Machinery, New York, NY, USA, 881–890. https://doi.org/10.1145/3397271.3401180 783']
10	https://drive.google.com/file/d/1v71vlSEajXH2QZEkCNM_QEXHj7AiSEF6/view?usp=drive_link	2020-05-23	Towards a Quantum Software Modeling Language	['Carlos A. Pérez-Delgado', 'Hector G. Perez-Gonzalez']	['University of Kent Canterbury, Kent, United Kingdom', 'Universidad Autónoma de San Luis Potosí San Luis Potosí, SLP, México']	['quantum computing', 'software engineering', 'UML']	We set down the principles behind a modeling language for quantum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effectively model quantum software. These extensions are separate and independent of UML as a whole. As such they can be used to extend any other software modeling language, or as a basis for a completely new language. We argue that these extensions are both necessary and sufficient to model, abstractly, any piece of quantum software. Finally, we provide a small set of examples that showcase the effectiveness of the extension set.	introduction quantum computation rose to prominence after the discovery of quantum that can efficiently perform tasks that are intractable these discoveries propelled research and interest in quantum there exists prototype quantum hardware with computational capabilities beyond that of any classical further applications of quantum theory to computation have also been made in several areas of theory of such as models of data and both authors contributed equally to this permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first copyrights for components of this work owned by others than the must be abstracting with credit is to copy or to post on servers or to redistribute to requires prior specific permission a request permissions from may republic of korea copyright held by the publication rights licensed to acm isbn quantum computation until been studied almost exclusively in the a general understanding of quantum quantum programming in the large is yet to be here we aim to set the foundations of a general framework for and conveying quantum we aim to do so by developing a universal modeling language for quantum rather than develop such a language from we have decided to start from the unified modeling language and introduce a minimum set of extensions that allow it to effectively model quantum assuming uml to be a shared upon which we can allows us to convey our original extensions much more our extension set be applied with little or no modification to any other modeling before discussing in depth the extensions we are we make a few fundamental observations on which we base the guiding principles for our extension our first observation is about the nature of quantum the central difference between quantum and classical computation is in how it achieves its quantum computers have access to quantum and quantum that are unavailable to classical computers hence their performance algorithms and implementation algorithms are an essential design choice while programming in the they are more often than not completely ignored in software architectural for uml diagrams seldom portray algorithms and beyond a very design it would seem then that quantum computation introduces nothing to computation that needs to be captured in a software design this is not the and the reason for this is our second quantum computation changes the very nature of information quantum information is much richer than classical it is also much more challenging to and if a module needs to transmit or receive quantum then this is an important design consideration which needs to be included in any effective software a third observation here is that the classical quantum nature of the information used by a module is an important consideration both when discussing its internal implementation and its these two are separate and independent a classical implementing some classical would have no or to communicate quantum a quantum module may or may not have a quantum behavior may be completely part of its internal and not appear as part of its for take a module implementing algorithm uses quantum effects to efficiently factor a large integer into its prime the implementation of this module must necessarily be both the input large and the output prime consist of classical and the interface of such a module can be strictly more we can conceive of quantum software modules that have all classical inputs and outputs the above all quantum inputs and or a mix of a quantum ware design must for each individual interface whether it is classical or if it is in whether a module communicates classically or via quantum and whether its internal implementation requires quantum hardware are important considerations that need to be captured in a design the importance of such labelling should be quantum data can only be stored and transmitted with special hardware designed to do more from an strictly software quantum and classical information are not classical information is and admits fanout while quantum information does on the other quantum information has a much larger it is true that quantum information is strictly a of classical hence a quantum module can nicate any classical information it desires using a quantum interface we that using a quantum interface ment and messaging when classical would suffice is bad quantum software for the reasons stated in the guiding principles behind any quantum software modeling language must include the whenever a software module makes use of quantum either as part of its internal or as part of its this must be clearly established in a design each module interface element public public and internal state variables can be either classical or and must be labelled each variable should be labelled as classical or if the model represents data the variables should also specify the classical or quantum qubit quantum graph data for each both the put and output should be clearly labelled as either classical or whether the operation internally operates quantumly should also be a module that has at least one quantum element is to be considered a quantum software otherwise it is a classical quantum and classical modules should be clearly labelled as any module that is composed of one or more quantum modules will itself be considered a quantum and must be labelled as quantum and classical ules can communicate with each other as long as their faces are the quantum module has classical inputs outputs that can interface with the classical we will argue in how these extensions are not only but also sufficient in order to design and represent quantum in the following two sections we put these principles into practice as a set of concrete extensions to class diagram extensions uml is a very graphical meant to convey a lot of meaning in a very small amount of as it makes sense to use a graphical way to represent quantum software we chose to do this by use of bold text to denote quantum and double lines to denote a quantum relationship or quantum figure class diagram of tum classes and interface elements are presented in bold and quantum relationships use for the name will be bold if it is represented using quantum for we use the following if any of the inputs are these are if the output or datatype of the method is then the datatype should also be for backwards compatibility with regular whenever the input or output datatypes of a method are these will be assumed to be classical in if a has any quantum attributes or methods then it itself is considered and its name shall also be relationships between classes will use whenever the relationship is quantum in for if the superclass is quantum then the and the inheritance will also be converse is not necessarily true in the case of aggregation and if a being is then the to which it is as well as that relationship will also be association relationships do not have any special beyond the need of a quantum to have a classical interface if it is to associate with classical showcases a diagram that exemplifies the above sequence diagram extensions sequence diagrams in uml allow us to portray the dynamic tionship between modules in a software as we did before for static we extend the existing language in order to allow us to differentiate between classical and quantum as previously this is essential quantum information behaves differently from classical it can different it admits different it requires different hardware to and figure sequence diagram of quantum classes are presented in bold and quantum messages use like we make use of bold text to markup quantum and double lines to portray quantum shows a sequence note how even though the relationship between shorfactor and shororder is the messaging between them is this illustrates an important a module is marked as quantum if it uses quantum resources in any either directly as part of its internal implementation or as part of an aggregated if a uml a composed class or is then the encompassing module must also be marked as in a static the quantum composition relationships inform in the case of a seemingly classical module that does not in itself use quantum composed modules are using quantum note the communication between the objects shororder and the module operates on a quantum both messages are the return sages ρ and are quantum the request to perform a quantum fourier transform or a qft inverse operation can therefore be communicated this gram showcases the level of granularity available to us using these diagrams with the proposed discussion we have proposed a minimal series of extensions to existing ware modeling we exemplify our additions in but these extensions are easily applicable to any other modeling or be used as the basis for a new modeling argued the necessity of each of the extensions in previous we can argue as that these extensions are not only but also sufficient to fully model quantum to make this we appeal to the fact that all quantum computation is simulable using classical computation albeit with an efficiency other than their use of quantum information and quantum computers are indistinct from classical from a design the only information element that needs to be considered when developing quantum software is when quantum than information is being the one remaining information element we have not discussed is algorithm if quantum computation is to be it will most likely be due to the efficient algorithms at its that algorithm efficiency is not a solely quantum uml itself does not inherently have language elements for algorithm efficiency it have several extensions used and proposed for this other modeling languages may also have definite algorithm efficiency we argue that it is best to use existing language elements when they are acknowledgments would like to acknowledge funding through the epsrc tum communications hub the authors would also like to thank joanna ziembicka for useful comments during the preparation on this	['[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon- ducting processor. Nature 574, 7779 (2019), 505–510. https://doi.org/10.1038/ s41586-019-1666-5 ', '[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7–11. ', '[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan- guage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series). Addison-Wesley Professional. ', '[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance modelling with the Unified Modelling Language and stochastic process algebras. IEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107–120. https://doi.org/10.1049/ip-cdt:20030084 ', '[5] Lov K. Grover. 1996. A Fast Quantum Mechanical Algorithm for Database Search. In Proceedings of the Twenty-eighth Annual ACM Symposium on The- ory of Computing (STOC 96). ACM, New York, NY, USA, 212–219. https: //doi.org/10.1145/237814.237866 ', '[6] Carlos A. Pérez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular automata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/ PhysRevA.76.032320 ', '[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms and factoring. In Proceedings 35th annual symposium on foundations of computer science. Ieee, 124–134. ', '[8] Liming Zhao, Carlos A. Pérez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph operations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3. https://doi.org/10.1103/PhysRevA.93.032314 444']
13	https://drive.google.com/file/d/19PiYNgBN2BDzqBRSrob1X1s6kcNKp4Jb/view?usp=drive_link	2023-06-12	Framing the News: From Human Perception to Large Language Model Inferences	['David Alonso del Barrio', 'Daniel Gatica-Perez']	['Idiap Research Institute Switzerland', 'Idiap Research Institute and EPFL Switzerland']	['Covid-19 no-vax', 'news framing', 'GPT-3', 'prompt-engineering', 'transformers', 'large language models']	Identifying the frames of news is important to understand the articles vision, intention, message to be conveyed, and which aspects of the news are emphasized. Framing is a widely studied concept in journalism, and has emerged as a new topic in computing, with the potential to automate processes and facilitate the work of journalism professionals. In this paper, we study this issue with articles related to the Covid-19 anti-vaccine movement. First, to understand the perspectives used to treat this theme, we developed a protocol for human labeling of frames for 1786 headlines of No-Vax movement articles of European newspapers from 5 countries. Headlines are key units in the written press, and worth of analysis as many people only read headlines (or use them to guide their decision for further reading.) Second, considering advances in Natural Language Processing (NLP) with large language models, we investigated two approaches for frame inference of news headlines: first with a GPT-3.5 fine-tuning approach, and second with GPT-3.5 prompt-engineering. Our work contributes to the study and analysis of the performance that these models have to facilitate journalistic tasks like classification of frames, while understanding whether the models are able to replicate human perception in the identification of these frames.	introduction in recent there has been a proliferation in the use of concepts such as data computational and reporting which all share the vision of bridging journalism and the progress made in nlp has been gradually integrated into the journalistic field more machine learning models based on transformers have been integrated in the media sector in different tasks such as the creation of headlines with generative languages models summarization of news articles false news detection and topic modeling and sentiment analysis the development of large language models such as bloom or chatgpt show a clear trend towards interaction becoming easier and more opening up a wide range of research at the same the use of these models is also associated with a lack of transparency regarding how these models but efforts are being made to bring some transparency to these and to analyze use cases where they can be useful and where they cannot based on the premises that these models open up a wide range of research directions and that at the same time needless to they are not the solution to all we are interested in identifying use cases and tasks where they can be potentially while acknowledging and systematically documenting their limitations more the aim of this work is to analyze the performance of for a specific use namely the analysis of frames in from an empirical point of with the objective of shedding light on a potential use of generative models in journalistic frame analysis is a concept from which consists of studying the way in which news stories are presented on an and what aspects are is a merely informative vision given in an or is it intended to leave a moral is a news article being presented from an economic point of or from a more emotional the examples above correspond to different frames with which an article can be the concept of news framing has been studied in computing as a step beyond topic modeling and sentiment and for this in recent language models have been used for the classification process of these frames but the emergence of generative models opens the possibility of doing of these classification instead of the approach investigated so our work aims to address this research gap by posing the following research what are the main frames in the news headlines about the as reported in newspapers across european icmr june greece david alonso del barrio and daniel can prompt engineering be used for classification of lines according to by addressing the above research our work makes the following contribution we implemented a process to do human notation of the main frame of headlines of articles about the as reported in newspapers from european countries switzerland and united at the headline we found that the predominant frame was human where this frame corresponds to a sonification of an either through a statement by a or the explanation of a specific event that happened to a we found a large number of headlines annotated as containing no as they simply present information without entering into we also found that for all the countries the distribution of frame types was very man interest and no frame are the two predominant the generated annotations allowed to subsequently study the formance of a large language contribution we studied the performance of on the task of frame classification of in addition to using the approach from previous we propose an alternative approach for frame classification that requires no labeled data for namely using the results show that with produces accuracy higher than other smaller and that the engineering approach results in lower performance our analysis also shows that the subjectivity of the human labeling task has an effect on the obtained the paper is organized as in section we discuss related in section we describe the news in section we describe the methodology for both human labeling and machine classification of news we present and discuss results for and in sections and we provide conclusions in section related work framing has been a concept widely studied in with a definition that is rooted in the study of this domain frame is to select some aspects of a perceived reality and make them more salient in a communicating in such a way as to promote a ticular problem causal moral treatment recommendation for the item for frame there are two main the tive approach where one can extract the frames after reading the and the deductive approach where a predefined list of frames exists and the goal is to interpret if any of them pears in the in the deductive there are generic frames and and the way to detect them typically involves reading and identifying one frame at a or through answers to questions that represent the semetko et used types of generic frames of human and economic based on previous and they defined a list of questions to detect frames in for the questions about morality are the the story contain any moral does the story make reference to and other religious does the story offer specific social prescriptions about how to and so on for each of the frame this categorization of frames has been used in various topics such as climate change vaccine hesitance or immigration we now compare the two approaches on a common such as ebrahim et followed an inductive approach in which the frames were not predefined but emerged from the text deadly stay what the cost of using headlines as the unit of in the deductive approach has studied very different et followed the method of but in addition to the generic frames presented they also used blame frame and fear adiprasetio et and rodelo used the generic frames with while et used the frames and read the headline and subheadline to decide the main table summarizes some of the the existing this previous work showed how frame labels can be and also that frame analysis has been done at both headline and article these two approaches and that originated in journalism have since been replicated in the computing we decided to follow the deductive approach because a fined list of frames allows to compare among previous and also because they represent a fixed list of labels for machine classification the tive approach tends to be more specific to a and from the computing past work has tried to justify topic modeling as a technique to extract frames from et proposed topic modeling as a frame traction they argued that topics can be interpreted as frames if three requirements are frames are operationalized as connections between data is and topics are adequately validated as for which they suggested a practical this approach was based on the choice of a specific topic climate and the use of latent dirichlet allocation as a technique to extract a number of in a second a qualitative study of the top words of each subtopic was and the different subtopics were nated or reducing the number and establishing a tentative in a third the top articles belonging to that were and if the description of the topic fitted at least of the that the frames found in this article green emission negotiations and environmental cost of carbon chinese economics of energy climate vironmental burden state leaders and citizen from definition of frame it seems that the tive approach is more refined than the inductive approach seems to resemble the detection of for with regard to climate there are stories on how people have been affected by climate change from an emotional point of thus personalizing the in this we could categorize the corresponding frame as human as the writer of the article is selecting aspects of a perceived reality and make them framing the from human perception to large language model inferences icmr june greece more the language subtleties with which news articles are presented cannot be captured with basic topic isoaho et held the position that while the benefits of scale and scope in topic modeling were there were also a number of namely that topic outputs do not correspond to the methodological definition of and thus topic modeling remained an incomplete method for frame topic in the practice of journalistic is a useful technique to deal with the large datasets that are yet is often not enough to do more thorough analyses in our we clearly notice that frame analysis is not topic for two documents could be about the same say but one article could emphasize the number of deaths after while the other emphasized the role of the vaccine as a solution to the we also consider that the larger the number of possible frame the more likely it is to end up doing topic modeling instead of frame using a deductive dallas et created a dataset with articles about polemic topics such as same sex or and they defined types of capacity and fairness and constitutionality and policy prescription and crime and security and health and quality of cultural external regulation and in this they authors did not use a list of for each annotators were asked to identify any of the framing dimensions present in the article and to label text blurbs that cued them on the definitions of each of the frame and decide the main frame of each in our we followed the idea of detecting the main frame by reading the text instead of answering but instead of using the frames proposed in we used the generic frames proposed in a final decision in our work was the type of text to whether headlines or whole for this the chosen classification method was also going to be for khanehzar et used traditional approaches such as svms as and demonstrated the improvement in frame tion with the use of languages models such as roberta and following a setting as input text a maximum of tokens the maximum number of input tokens in these models is liu et classified news headlines about the gun problem in the united arguing for the choice of headlines as a unit of analysis based on previous journalism literature that advocated for the importance and influence of headlines on readers and the subsequent perception of from a computational using headlines is also an since you avoid the token limitation in we decided to work with headlines about a controversial namely the continuing with the question of the methods used for much work has been developed in prompt especially since the release of liu et presented a good overview of the work done on this new nlp not only explaining the concept of prompt but also the ent strategies that can be followed both in the design of table summary of deductive approaches for frame analysis ref frames goal technique number of samples generic ity and ness and tionality and prescription and and and and of regulation and to label frames of full articles reading the full the annotator defines the main frame articles generic frames classification bert based models articles generic of and to label frames of full articles articles and tv news stories specific and space and to label frames of full classification reading the full the annotator defines the main bert based models headlines generic frames blame frame and fear frame to label frames of full articles articles generic frames to label frames of full articles reading the full the annotator defines the main articles generic frames pandemic frames to label frames of full articles articles generic journalistic role and pandemic frames to label frames of full articles reading the headline and the annotator defines the main headlines subheadlines the potential and the challenges to face when using this prompt engineering applications include knowledge probing information extraction nlp reasoning tion answering text generation learning and text classification the latter being the use case in our puri et presented a very interesting idea that we apply to our classification this consists of viding the language model with natural language descriptions of classification tasks as and training it to generate the correct answer in natural language via a language modeling it is a learning in which no examples are used to explain the task to the radford et demonstrated that language models can learn tasks without any explicit we have followed this approach to find an alternative way to do frame as mentioned the emergence of giant models like and chatgpt are a very active research to the best of our on one hand our work extends the computational analysis of news related to the which illustrates the influence of the press on the ways societies think about relevant issues and on the other hand it adds to the literature of regarding the design of prompts for classification tasks european news dataset we used part of the european news dataset collected in our recent work this dataset contains articles on vaccination from newspapers from different icmr june greece david alonso del barrio and daniel switzerland and the articles cover a time period of from january to october all content was translated into english to be able to work in a common the dataset was used for various such as name entity sentiment and subtopic to stand how vaccination was reported in europe through the print media digital the subtopic modeling analysis revealed a subsample of articles on the which is the one we have used in this we took the headlines of the articles associated with the selecting all articles containing any of the keywords in table in the headline or in the main this corresponds to a total of table keywords used to identify articles keywords no vax topic in table we show the number of headlines per country and france is the country with the most articles in the with followed by italy with note that there are newspapers from while only from corriere della sera is the newspaper that dealt most frequently with the subject while the telegraph is the second one the total number of articles normalized by the number of newspapers per country is also shown in the last column of the using these normalized the ranking is and table number of headlines by newspaper and country country newspaper headlines total france la croix le monde les echos liberation lyon capitale ouest france italy corriere della sera il sole ore spain minutos abc el diario el mundo el español la vanguardia switzerland heures la liberté le temps united kingdom the irish news the telegraph methodology human labeling of news frames to carry out the labeling of the frames in our corpus of we first designed a which contained the definitions of each of the frame types and a couple of examples of each as well as a definition of the corpus subject matter and definitions of the concept of frame so that the annotators could understand the task to be the codebook follows the proposed by with generic frames of human and economic plus one additional two researchers were engaged to annotate a sample of the collected newspaper articles following a training in the first annotators had to read the codebook and get familiar with the in the second they were asked to identify the main frame in the same subset of at the end of the second the intercoder reliability was between the we analyzed those cases where there were and observed that in some there was not a unique main because both annotators had valid arguments to select one of the in other the discrepancies were due to slight misunderstanding of the in the third the annotators coded again and the icr increased to was we realized that the possibility of having two frames they discussed the cases in which they had and if the other arguments were considered it could be said that there were two after this training annotators were ready to annotate the dataset we divided the dataset into two equal and each person annotated and models with the annotated we investigated two nlp the first one involves a the second one is prompt language models have been figure prompt trained with large text strings based on two unsupervised next sentence prediction and masked language figure summarizes these in the first a model with a fixed architecture is trained as a language model predicting the likelihood of the observed textual this can be done due to the availability of raw text data needed to train this learning process can produce general purpose features of the modeled the learning process produces features of the language being the above lm is then adapted to different downstream by introducing additional parameters and adjusting them using objective in this the focus was primarily on goal designing the training targets used in both the and the stages framing the from human perception to large language model inferences icmr june greece we present an example to illustrate the imagine that the task is sentiment and we have a dataset with sentences and their associated and a which is a saved neural network trained with a much larger for that model to address the target we unfreeze a few of the top layers of the saved model base and jointly train both the classifier layers and the last layers of the base this allows to the feature representations in the base model to make them more relevant for the sentiment analysis in this instead of having to obtain a very large dataset with target labels to train a we can reuse the trained model and use a much smaller train we use a part of our dataset as examples for the model to learn the while the other part of the dataset is used to evaluate model previous works related to frame classification in the computing literature have used in our we have done the same as a but we aimed to go one step further and also produce results using of with model has been widely but with the emergence of generative models such as another way to approach classification tasks has the idea is to use the model directly and convert the task to be performed into a format as close as possible to the tasks for which it has been that if the model has been from next word prediction as in the case of classification can be done by defining a where the input to the model is an incomplete and the model must complete it with a word or several just as it has been this avoids having to use part of the already labeled dataset to teach the task to be performed to the and a previous labeling is not needed in this instead of adapting lms to stream tasks via objective downstream tasks are formulated to look more like those solved during the original lm training with the help of a textual for when nizing the emotion of a social media missed the bus we may continue with a prompt felt so and ask the lm to fill the blank with an or if we choose the prompt i missed the bus an lm may be able to fill in the blank with a french in this by selecting the appropriate we can influence the model behavior so that the lm itself can be used to predict the desired even without any additional training we use this emerging nlp approach to classify frames at headline we are not aware of previous uses of this strategy to classify frames as we propose the idea is the prompt neering consists of giving a prompt to the and understands that prompt as an incomplete to do prompt ing with our we needed to define an appropriate prompt that would produce the headline frames as we defined eral experiments with the playground of in order to find the best prompt for our in our initial we lowed existing approaches in prompt engineering to do sentiment where the individual answer was an and this adjective was matched with a in a similar we decided to build a thesaurus of adjectives that define each of the for the human interest frame could be the conflict frame could after the list of adjectives was we needed to define the prompt in order to as an one of the adjectives in our thesaurus to match them with the we used the playground using the headline as input and asking for the frame as but the strategy did not in our final instead of giving the headline as we gave the definitions of each type of frame plus the and we asked the model to choose between the different types of frames as in this the output of the model was directly one of the and we avoided the step of matching adjectives with an example is shown in figure figure for frame input and output for the configuration there are main temperature this parameter controls lowering it results in less random this parameter controls diversity via nucleus this parameter indicates the mum number of tokens to offer four main models with different levels of suitable for different davinci is the most capable and ada is the after testing with the playground and varying different to assess we set the temperature to since the higher the temperature the more random the the parameter was set to as it would likely get a set of the most likely words for the model to choose the maximum number of tokens was set to in this the model is asked to choose between one of the as a we used the one with the best performance at the time of experimental which was recognized as gpt human labeling of frames in news headlines in this we present and discuss the results of the analysis related to our first figure shows the distribution of frames per country at headline with human interest and being the predominant icmr june greece david alonso del barrio and daniel attribution of responsibility is the third one except in where the corresponding frame is morality and economic are the least represented in the dataset for every figure distribution of frames per country the monthly distribution of frames aggregated for all countries is shown in we can see two big the first one in january and the second one in august in all the cination process started at the end of december so it makes sense that the movement started to be more predominant in the news in january human interest is the most predominant manual inspection shows that this is because the headlines are about personal cases of people who are or attribution of responsibility is also manual inspection dicates that local politicians and health authorities had to make decisions about who could be vaccinated at the beginning of the the second peak at the end of summer coincided with the health pass called covid passport in some and we can observe a peak in the curve corresponding to the flict reflecting the demonstrations against the measure of mandatory health passes taken by country in figure we compare the sentiment per frame and per to understand if there were any major the sentiment analysis labels were obtained using from the hugging face package used in our previous work refer to our original analysis in for we normalized the results tween and to compare frames between we see that the sentiment is predominantly neutral examining in more figure monthly distribution of detail the negative and positive sentiment of each frame we observed a few attribution of negative sentiment represents of the while positive tone is only found in residual form in and the united negative sentiment represents of the predominantly with only negative tone in italy and uk the latter all headlines with this frame were considered human negative sentiment represents of the while positive tone is only found in residual form in and predominantly with negative tone in and the united no of negative figure sentiment of headline by frame and by country framing the from human perception to large language model inferences icmr june greece regarding the results of the annotation the fact that the distribution of the frame types is relatively similar between tries suggests that the movement issue was treated in a similar way in these the fact that human interest is the most dominant frame indicates that this issue was treated from a more human and emotional with headlines about personal celebrities giving their opinion about and politicians defending vaccine the reason for many headlines being classified as is partly due to how data was we chose articles that contained words related to either in the headline or in the this resulted in many headlines not containing anything specific related to while the content was actually included in the main text of the corresponding it is worth mentioning that prior to obtaining the we had expected that attribution of responsibility would be among the most prominent since governments took many measures such as mandatory health pass requirements to access certain we had also expected that the conflict frame would be since there were many demonstrations in in these frames categories were not reflected as frequently at the headline regarding the analysis at the temporal it is clear that certain events were captured by the such as the start of vaccination or the mandatory vaccination the sentiment analysis of the different frames shows that the predominant tone in all of them is neutral or with very similar trends between this association between ment analysis and frames has been discussed in previous literature for frame classification of headlines we present and discuss the results related to our second table shows the results of the classification task using three models were and two based we observe on performs better than the this is somehow expected as is a much larger in the case of the best performance for the frame classification task is which is with an improvement over previous models based on it should be noted that the performance differences are modest improvement between and table classification results for frame tion and cross validation accuracy average bert roberta on the other bert is while has an economic cost as the use of the model is not which monetarily limits the number of experiments that can be performed with as well as the different configurations one can explore to improve this is important because much of the improvement in performance requires empirical explorations of model parameters more the cost of an experiment for each of the folds has a cost of dollars the time of writing this this represents a limitation in has a significant carbon for prompt engineering in the next choosing the right prompt the words that best define the task so that the model is able to perform is also based on trial and this also has an impact on carbon in connection with this strubell et argue that improvements in the racy of models depend on the availability of large computational which involve large economic and environmental a criticism has been made as rich get in the sense that not all research groups have sufficient infrastructure resources and access to funding needed to use these models and improve their also in relation to this the work of bender et evaluates the costs and risks of the use of large language stating that researchers should be aware of the impact that these models have on the and assess whether the benefits outweigh the the work in provides a very telling where people living in the maldives or sudan are affected by floods and pay the environmental price of training english when similar models have not been produced for languages like dhivehi or sudanese in there is a need to establish ways to use this technological development and it all starts with being aware of the risks it with for each we got the frame that the model considered the most and we compared these inferences with the frames labeled by the the agreement between model and annotator was of analyzing the and specifically looking at the cases where the annotator and we discovered that according to the frame the model in some cases proposed a frame that indeed made this together with our previous experience in the annotation where headlines could have more than one valid led us to design a second we took all the headlines where each of the two annotators had disagreed with and we asked the annotators to state whether they would agree with each label for a given it is important to emphasize that the annotators did not know the origin of that they did not know if it was the label they had originally or if it was a random in this we could quantify how worked according to valid arguments provided by the in this the model agreed in of cases with the looking at the results of the classification the racy of the approach can be considered yet we consider that it is a valid avenue for further as in the second we found that the model agrees icmr june greece david alonso del barrio and daniel with human annotators in of the framing volves aspects of subjectivity much of what we do as people has a subjective influenced by how we feel or how we express news reading is never fully and the annotators gaged in the frame classification influenced by their personal state of and may perceive information monarch affirms that simple like binary labels on objective the statistics are fairly straightforward to decide which is the label when different annotators but for subjective or even objective tasks with continuous there are no simple heuristics for deciding what the correct label should subjectivity is involved in both the generation and perception of the assumption that there is only one frame is plicated by the point of view of the in the case of the information sender has an but the receiver plays a role and is influenced by in this is known as the lens model of interpersonal where the sender has certain but the receiver can interpret or what the sender wants to with more or less accuracy following this discussion on the question arose as to what would happen instead of we used the complete article as a source of we wondered if longer text could make the frame labeling task clearer than when using yet another possible hypothesis is that having to read longer texts could lead to the same subject being presented from different please recall that in the existing literature discussed in section both headlines and full articles have been used from frame analysis table this remains as an issue for future conclusions in this we first presented an analysis of news frames on the movement in and then studied different approaches using large language models for automatic inference of we conclude by answering the two research questions we what are the main frames in the news headlines about the movement in european after annotating the we found that of the the predominant frame is human interest of which presents a news item with an emotional putting a face to a problem or we also found that a substantial proportion of headlines were annotated as not presenting any frame of the other frame types are found more can prompt engineering be used for classification of lines according to we first used of a number of language and found that produced classification curacy of on a classification this represented a modest improvement over at a significantly larger environmental we then presented a new way of fying frames using at the headline inferences made with reached of agreement with frame in many the model inferred frame types that were considered as valid choices by human and in an the agreement reached these results have opened several new directions for future acknowledgments this work was supported by the funded by the european commission under the programme we also thank the newspapers for sharing their online we thank our colleagues haeeun kim and emma for their support with and victor bros and oleksii polegkyi for	['[1] Justito Adiprasetio and Annissa Winda Larasati. 2020. Pandemic crisis in online media: Quantitative framing analysis on Detik. coms coverage of Covid-19. Jurnal Ilmu Sosial Dan Ilmu Politik 24, 2 (2020), 153–170. ', '[2] Neel Alex, Eli Lifland, Lewis Tunstall, Abhishek Thakur, Pegah Maham, C Jess Riedel, Emmie Hine, Carolyn Ashurst, Paul Sedille, Alexis Carlier, et al. 2021. RAFT: A real-world few-shot text classification benchmark. arXiv preprint arXiv:2109.14076 (2021). ', '[3] David Alonso del Barrio and Daniel Gatica-Perez. 2022. How Did Europes Press Cover Covid-19 Vaccination News? A Five-Country Analysis. (2022), 35–43. https://doi.org/10.1145/3512732.3533588 ', '[4] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? (2021), 610–623. ', '[5] Santosh Kumar Biswal and Nikhil Kumar Gouda. 2020. Artificial intelligence in journalism: A boon or bane? In Optimization in machine learning and applications. Springer, 155–167. ', '[6] Erik Bleich, Hannah Stonebraker, Hasher Nisar, and Rana Abdelhamid. 2015. Media portrayals of minorities: Muslims in British newspaper headlines, 2001– 2012. Journal of Ethnic and Migration Studies 41, 6 (2015), 942–962. ', '[7] Michael Bommarito and Daniel Martin Katz. 2022. GPT Takes the Bar Exam. https://doi.org/10.48550/ARXIV.2212.14402 ', '[8] Meredith Broussard, Nicholas Diakopoulos, Andrea L Guzman, Rediet Abebe, Michel Dupagne, and Ching-Hua Chuan. 2019. Artificial intelligence and jour- nalism. Journalism & Mass Communication Quarterly 96, 3 (2019), 673–695. ', '[9] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877–1901. ', '[10] Björn Burscher, Daan Odijk, Rens Vliegenthart, Maarten De Rijke, and Claes H De Vreese. 2014. Teaching the computer to code frames in news: Comparing two supervised machine learning approaches to frame analysis. Communication Methods and Measures 8, 3 (2014), 190–206. ', '[11] Bjorn Burscher, Rens Vliegenthart, and Claes H de Vreese. 2016. Frames beyond words: Applying cluster and sentiment analysis to news coverage of the nuclear power issue. Social Science Computer Review 34, 5 (2016), 530–545. ', '[12] Dallas Card, Amber Boydstun, Justin Gross, Philip Resnik, and Noah Smith. 2015. The Media Frames Corpus: Annotations of Frames Across Issues. 2 (01 2015), 438–444. https://doi.org/10.3115/v1/P15-2072 ', '[13] Daniel Catalan-Matamoros and Carlos Elías. 2020. Vaccine hesitancy in the age of coronavirus and fake news: analysis of journalistic sources in the Spanish quality press. International Journal of Environmental Research and Public Health 17, 21 (2020), 8136. ', '[14] Daniel Catalán-Matamoros and Carmen Peñafiel-Saiz. 2019. Media and mistrust of vaccines: a content analysis of press headlines. Revista latina de comunicación social 74 (2019), 786–802. ', '[15] Mark Coddington. 2015. Clarifying journalisms quantitative turn: A typology for evaluating data journalism, computational journalism, and computer-assisted reporting. Digital journalism 3, 3 (2015), 331–348. ', '[16] Stephen D Cooper. 2010. The oppositional framing of bloggers. In Doing News Framing Analysis. Routledge, 151–172. ', '[17] Robert Dale. 2021. GPT-3: Whats it good for? Natural Language Engineering 27, 1 (2021), 113–118. ', '[18] Astrid Dirikx and Dave Gelders. 2010. To frame is to explain: A de- ductive frame-analysis of Dutch and French climate change coverage dur- ing the annual UN Conferences of the Parties. Public Understanding of Science 19, 6 (2010), 732–742. https://doi.org/10.1177/0963662509352044 arXiv:https://doi.org/10.1177/0963662509352044 PMID: 21560546. ', '[19] Astrid Dirikx and Dave Gelders. 2010. To frame is to explain: A deductive frame- analysis of Dutch and French climate change coverage during the annual UN Conferences of the Parties. Public understanding of science 19, 6 (2010), 732–742. 634', '[20] Zi-Yi Dou, Pengfei Liu, Hiroaki Hayashi, Zhengbao Jiang, and Graham Neubig. 2020. Gsum: A general framework for guided neural abstractive summarization. arXiv preprint arXiv:2010.08014 (2020). ', '[21] Sumayya Ebrahim. 2022. The corona chronicles: Framing analysis of online news headlines of the COVID-19 pandemic in Italy, USA and South Africa. Health SA Gesondheid (Online) 27 (2022), 1–8. ', '[22] Hend Abdelgaber Ahmed El-Behary. 2021. A Feverish Spring: A Comparative Analysis of COVID-19 News Framing in Sweden, the UK, and Egypt. (2021). ', '[23] Robert M Entman. 1993. Framing: Towards clarification of a fractured paradigm. McQuails reader in mass communication theory 390 (1993), 397. ', '[24] Tianyu Gao, Adam Fisch, and Danqi Chen. 2020. Making pre-trained language models better few-shot learners. arXiv preprint arXiv:2012.15723 (2020). ', '[25] Piyush Ghasiya and Koji Okamura. 2021. Investigating COVID-19 news across four nations: a topic modeling and sentiment analysis approach. Ieee Access 9 (2021), 36645–36656. ', '[26] Robert Gifford. 1994. A Lens-Mapping Framework for Understanding the En- coding and Decoding of Interpersonal Dispositions in Nonverbal Behavior. Journal of Personality and Social Psychology 66 (02 1994), 398–412. https: //doi.org/10.1037//0022-3514.66.2.398 ', '[27] Quentin Grail, Julien Perez, and Eric Gaussier. 2021. Globalizing BERT-based transformer architectures for long document summarization. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 1792–1810. ', '[28] Anushka Gupta, Diksha Chugh, Rahul Katarya, et al. 2022. Automated news summarization using transformers. In Sustainable Advanced Computing. Springer, 249–259. ', '[29] Alfred Hermida and Mary Lynn Young. 2017. Finding the data unicorn: A hierar- chy of hybridity in data and computational journalism. Digital Journalism 5, 2 (2017), 159–176. ', '[30] Karoliina Isoaho, Daria Gritsenko, and Eetu Mäkelä. 2021. Topic modeling and text analysis for qualitative policy research. Policy Studies Journal 49, 1 (2021), 300–324. ', '[31] Carina Jacobi, Wouter Van Atteveldt, and Kasper Welbers. 2016. Quantitative analysis of large amounts of journalistic texts using topic modelling. Digital journalism 4, 1 (2016), 89–106. ', '[32] Zhengbao Jiang, Frank F Xu, Jun Araki, and Graham Neubig. 2020. How can we know what language models know? Transactions of the Association for Computa- tional Linguistics 8 (2020), 423–438. ', '[33] Shima Khanehzar, Andrew Turpin, and Gosia Mikołajczak. 2019. Modeling Political Framing Across Policy Issues and Contexts. In ALTA. ', '[34] Jeesun Kim and Wayne Wanta. 2018. News framing of the US immigration debate during election years: Focus on generic frames. The Communication Review 21, 2 (2018), 89–115. ', '[35] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michi- hiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al. 2022. Holistic evaluation of language models. arXiv preprint arXiv:2211.09110 (2022). ', '[36] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. (2021). https://doi.org/10. 48550/ARXIV.2107.13586 ', '[37] Siyi Liu, Lei Guo, Kate Mays, Margrit Betke, and Derry Tanti Wijaya. 2019. Detecting frames in news headlines and its application to analyzing news framing trends surrounding US gun violence. In Proceedings of the 23rd conference on computational natural language learning (CoNLL). ', '[38] Jörg Matthes and Matthias Kohring. 2008. The Content Analysis of Media Frames: Toward Improving Reliability and Validity. Journal of Communication 58 (06 2008). https://doi.org/10.1111/j.1460-2466.2008.00384.x ', '[39] Selina Meyer, David Elsweiler, Bernd Ludwig, Marcos Fernandez-Pichel, and David E Losada. 2022. Do We Still Need Human Assessors? Prompt-Based GPT-3 User Simulation in Conversational AI. In Proceedings of the 4th Conference on Conversational User Interfaces. 1–6. ', '[40] Stuart E Middleton, Symeon Papadopoulos, and Yiannis Kompatsiaris. 2018. Social computing for verifying social media content in breaking news. IEEE Internet Computing 22, 2 (2018), 83–89. ', '[41] Marko Milosavljević and Igor Vobič. 2021. Our task is to demystify fears: Analysing newsroom management of automation in journalism. Journalism 22, 9 (2021), 2203–2221. ', '[42] R. Monarch. 2021. Human-in-the-Loop Machine Learning: Active Learning and Annotation for Human-centered AI. Manning. https://books.google.ch/books? id=LCh0zQEACAAJ ', '[43] Tom Nicholls and Pepper D Culpepper. 2021. Computational identification of media frames: Strengths, weaknesses, and opportunities. Political Communication 38, 1-2 (2021), 159–181. ', '[44] Zhongdang Pan and Gerald M Kosicki. 1993. Framing analysis: An approach to news discourse. Political communication 10, 1 (1993), 55–75. ', '[45] Raul Puri and Bryan Catanzaro. 2019. Zero-shot text classification with generative language models. arXiv preprint arXiv:1912.10165 (2019). ', '[46] Guanghui Qin and Jason Eisner. 2021. Learning how to ask: Querying lms with mixtures of soft prompts. arXiv preprint arXiv:2104.06599 (2021). ', '[47] Rabindra Lamsal. 2021. Sentiment Analysis of English Tweets with BERTsent. https://huggingface.co/rabindralamsal/finetuned-bertweet-sentiment-analysis. ', '[48] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog 1, 8 (2019), 9. ', '[49] Nishant Rai, Deepika Kumar, Naman Kaushik, Chandan Raj, and Ahad Ali. 2022. Fake News Classification using transformer based enhanced LSTM and BERT. International Journal of Cognitive Computing in Engineering 3 (2022), 98–105. https://doi.org/10.1016/j.ijcce.2022.03.003 ', '[50] Frida V Rodelo. 2021. Framing of the Covid-19 pandemic and its organizational predictors. Cuadernos. info 50 (2021), 91–112. ', '[51] Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. 2022. Bloom: A 176b-parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100 (2022). ', '[52] Holli Semetko and Patti Valkenburg. 2000. Framing European Politics: A Content Analysis of Press and Television News. Journal of Communication 50 (06 2000), 93 – 109. https://doi.org/10.1111/j.1460-2466.2000.tb02843.x ', '[53] Richard Shin, Christopher H Lin, Sam Thomson, Charles Chen, Subhro Roy, Em- manouil Antonios Platanios, Adam Pauls, Dan Klein, Jason Eisner, and Benjamin Van Durme. 2021. Constrained language models yield few-shot semantic parsers. arXiv preprint arXiv:2104.08768 (2021). ', '[54] Efstathios Sidiropoulos and Andreas Veglis. 2017. Computer Supported Collab- orative Work trends on Media Organizations: Mixing Qualitative and Quan- titative Approaches. Studies in Media and Communication 5 (04 2017), 63. https://doi.org/10.11114/smc.v5i1.2279 ', '[55] Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019. Energy and policy considerations for deep learning in NLP. arXiv preprint arXiv:1906.02243 (2019). ', '[56] Alex Tamkin, Miles Brundage, Jack Clark, and Deep Ganguli. 2021. Understanding the capabilities, limitations, and societal impact of large language models. arXiv preprint arXiv:2102.02503 (2021). ', '[57] Trieu H Trinh and Quoc V Le. 2018. A simple method for commonsense reasoning. arXiv preprint arXiv:1806.02847 (2018). ', '[58] Maria Tsimpoukelli, Jacob L Menick, Serkan Cabi, SM Eslami, Oriol Vinyals, and Felix Hill. 2021. Multimodal few-shot learning with frozen language models. Advances in Neural Information Processing Systems 34 (2021), 200–212. ', '[59] Sandra A Vannoy and Prashant Palvia. 2010. The social influence model of technology adoption. Commun. ACM 53, 6 (2010), 149–153. ', '[60] Tuukka Ylä-Anttila, Veikko Eranti, and Anna Kukkonen. 2022. Topic modeling for frame analysis: A study of media debates on climate change in India and USA. Global Media and Communication 18, 1 (2022), 91–112. 635']
14	https://drive.google.com/file/d/1FbTuHWaX0b3riLsrkjD8qJ2Bd1_uv-pu/view?usp=drive_link	2022-08-07	Generating Diverse Code Explanations using the GPT-3 Large Language Model	['Stephen MacNeil', 'Andrew Tran', 'Dan Mogil', 'Seth Bernstein', 'Erin Ross', 'Ziheng Huang']	['Temple University Philadelphia, PA, USA', 'University of CaliforniaSan Diego La Jolla, CA, USA']	['large language models', 'natural language processing', 'code explanations', 'computer science education']	Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide high-quality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16], and providing error-specific feedback [10, 16]. However, these approaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Githubs Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs potential to support learning by explain- ing numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT-3 can generate automatically for a given code snippet. We present a subset of three use cases from our evolving design space of AI Explanations of Code.	introduction good explanations are essential to efficiently learning introductory programming concepts to provide explanations at numerous systems automate the process by tracing the execution of code defining terms giving hints and providing feedback these approaches often require manual effort to configure and only explain a single aspect of a given code large language models are also changing how students interact with code for githubs copilot can generate code for programmers leading researchers to raise concerns about cheating our work focuses on llms potential to support learning by ing numerous aspects of a given code this poster features a systematic analysis of the diverse natural language explanations that can generate automatically for a given code we present a subset of three use cases from our evolving design space of ai explanations of use cases to understand the types of explanations can we issued over prompts across numerous code an example prompt and resulting explanation is shown in figure we discovered eight explanation types and figure includes three explanation types to illustrate the explanatory power of the additional types tracing the execution of fixing bugs and explaining how they were generating analogies to real world listing relevant programming and predicting the console figure a prompt and explanation based on analyzing and explaining time complexity instructors rate time complexity as the most difficult programming topic understanding time complexity is important because it facilitates so students choose an appropriate algorithm for a given this use case shows can identify and explain time identifying common mistakes made by beginner programmers commonality exists in how students solve programming lems and the mistakes they make pedagogical such as the muddiest point highlight these common and most confusing concepts can automatically create a checklist of common mistakes students might make regarding a given code icer august lugano and virtual switzerland macneil et figure three example explanations automatically generated by for an binary search code summarizing code at multiple levels of abstraction before understanding how a code snippet it is often useful to understand the purpose of the code the summary ated by and shown in figure defines the traces the and highlights relevant cs concepts such as discussion our three use cases demonstrate the potential for to explain code for intro cs our poster presentation will feature all eight explanation types as a design space of explanations to convey the diversity of explanations that can be generated by we will highlight best practices for generating effective explanations and pitfalls that lead to less effective we are evaluating the usefulness of these explanations in a series of summer	['[1] Amjad Altadmri and Neil CC Brown. 2015. 37 million compilations: Investigating novice programming mistakes in large-scale student data. In Proceedings of the 46th ACM Technical Symposium on Computer Science Education. 522–527. ', '[2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in Neural Information Processing Systems 33 (2020), 1877–1901. ', '[3] Adam Carberry, Stephen Krause, Casey Ankeny, and Cynthia Waters. 2013. Unmuddying course content using muddiest point reflections. In 2013 IEEE Frontiers in Education Conference (FIE). IEEE, 937–942. ', '[4] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374 (2021). ', '[5] Kathryn Cunningham, Yike Qiao, Alex Feng, and Eleanor ORourke. 2022. Bring- ing "High-Level" Down to Earth: Gaining Clarity in Conversational Program- mer Learning Goals. In Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 1 (Providence, RI, USA) (SIGCSE 2022). As- sociation for Computing Machinery, New York, NY, USA, 551–557. https: //doi.org/10.1145/3478431.3499370 ', '[6] Elvina Elvina and Oscar Karnalim. 2017. Complexitor: An educational tool for learning algorithm time complexity in practical manner. ComTech: Computer, Mathematics and Engineering Applications 8, 1 (2017), 21–27. ', '[7] James Finnie-Ansley, Paul Denny, Brett A. Becker, Andrew Luxton-Reilly, and James Prather. 2022. The Robots Are Coming: Exploring the Implications of Ope- nAI Codex on Introductory Programming. In Australasian Computing Education Conference (Virtual Event, Australia) (ACE 22). ACM, New York, NY, USA, 10–19. https://doi.org/10.1145/3511861.3511863 ', '[8] Philip J Guo. 2013. Online python tutor: embeddable web-based program visual- ization for cs education. In Proceeding of the 44th ACM technical symposium on Computer science education. 579–584. ', '[9] Andrew Head, Codanda Appachu, Marti A Hearst, and Björn Hartmann. 2015. Tutorons: Generating context-relevant, on-demand explanations and demonstra- tions of online code. In 2015 IEEE Symposium on Visual Languages and Human- Centric Computing (VL/HCC). IEEE, 3–12. ', '[10] Samiha Marwan, Ge Gao, Susan Fisk, Thomas W. Price, and Tiffany Barnes. 2020. Adaptive Immediate Feedback Can Improve Novice Programming Engagement and Intention to Persist in Computer Science. In Proceedings of the 2020 ACM Conference on International Computing Education Research (Virtual Event, New Zealand) (ICER 20). Association for Computing Machinery, New York, NY, USA, 194–203. https://doi.org/10.1145/3372782.3406264 ', '[11] Davin McCall and Michael Kölling. 2014. Meaningful categorisation of novice pro- grammer errors. In 2014 IEEE Frontiers in Education Conference (FIE) Proceedings. IEEE, 1–8. ', '[12] Greg L Nelson, Benjamin Xie, and Amy J Ko. 2017. Comprehension first: eval- uating a novel pedagogy and tutoring system for program tracing in CS1. In Proceedings of the 2017 ACM conference on international computing education research. 2–11. ', '[13] Miranda Parker and Colleen Lewis. 2014. What makes big-O analysis difficult: understanding how students understand runtime analysis. Journal of Computing Sciences in Colleges 29, 4 (2014), 164–174. ', '[14] Daniel Perez, Leila Zahedi, Monique Ross, Jia Zhu, Tiffany Vinci-Cannava, Laird Kramer, and Maria Charters. 2020. WIP: An exploration into the muddiest points 38', '[15] Chris Piech, Mehran Sahami, Jonathan Huang, and Leonidas Guibas. 2015. Au- tonomously generating hints by inferring problem solving policies. In Proceedings of the second (2015) acm conference on learning@ scale. 195–204. ', '[16] Thomas W Price, Yihuan Dong, and Dragan Lipovac. 2017. iSnap: towards intelligent tutoring in novice programming environments. In Proceedings of the 2017 ACM SIGCSE Technical Symposium on computer science education. 483–488. ', '[17] Carsten Schulte and Jens Bennedsen. 2006. What do teachers teach in introductory programming?. In Proceedings of the second international workshop on Computing education research. 17–28. 39']
\.


--
-- Name: articles_id_seq; Type: SEQUENCE SET; Schema: public; Owner: iseproject
--

SELECT pg_catalog.setval('public.articles_id_seq', 14, true);


--
-- PostgreSQL database dump complete
--

